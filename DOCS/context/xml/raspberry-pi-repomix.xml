This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.env.example
audio_patch.py
config/pommai.service
debug_audio_flow.py
deploy_fixes.sh
DEPLOYMENT_GUIDE.md
fix_bluetooth_audio.sh
hardware_controller_improved.py
quick_fix.sh
raspberrypinewsetup.md
README.md
requirements.txt
setup_enhanced.sh
src/audio_stream_manager.py
src/audio_utils.py
src/button_handler.py
src/configure_bluetooth_audio.py
src/conversation_cache.py
src/fastrtc_connection.py
src/fastrtc_guardrails.py
src/guardrails_safety.py
src/led_controller.py
src/opus_audio_codec.py
src/pommai_client_fastrtc.py
src/scripts/diagnose.sh
src/scripts/setup.sh
src/scripts/update.sh
src/sync_manager.py
src/wake_word_detector.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".env.example">
# Pommai Raspberry Pi Client Configuration
# Copy this file to .env and fill in your values

# FastRTC Gateway (canonical)
# For local testing with the Python FastRTC server, use:
# FASTRTC_GATEWAY_URL=ws://localhost:8080/ws
FASTRTC_GATEWAY_URL=wss://your-fastrtc-gateway.example.com/ws

# Authentication and device identity
AUTH_TOKEN=your-auth-token
DEVICE_ID=rpi-toy-001
TOY_ID=default-toy

# File Paths (adjust for your setup)
VOSK_MODEL_PATH=/home/pommai/models/vosk-model-small-en-us-0.15
CACHE_DB_PATH=/tmp/pommai_cache.db
AUDIO_RESPONSES_PATH=/home/pommai/audio_responses

# Optional: Override hardware pins if different
# BUTTON_PIN=17
# LED_RED_PIN=5
# LED_GREEN_PIN=6
# LED_BLUE_PIN=13

# Performance tuning
# MAX_MEMORY_MB=50
# MAX_CPU_PERCENT=30

# Safety settings
# OFFLINE_SAFETY_LEVEL=strict
# MAX_CONVERSATIONS_PER_HOUR=20

# Legacy variables (backwards-compatibility, will be deprecated)
# CONVEX_URL=wss://your-deployment.convex.site/audio-stream
# CONVEX_API_URL=https://your-deployment.convex.site
# POMMAI_USER_TOKEN=your-user-auth-token
# POMMAI_TOY_ID=toy-id-to-load
</file>

<file path="audio_patch.py">
#!/usr/bin/env python3
"""
Safe Audio Patch for Pommai Client
This script adds Bluetooth audio support without breaking existing setup
Run this ON YOUR PI to patch the client safely
"""

import os
import shutil
from datetime import datetime

def create_audio_utils():
    """Create the audio_utils.py file"""
    
    audio_utils_content = '''#!/usr/bin/env python3
"""Simple audio device detection for Pommai"""
import pyaudio
import logging
import subprocess

logger = logging.getLogger(__name__)

def get_audio_device_indices():
    """Find best audio devices"""
    p = pyaudio.PyAudio()
    
    mic_index = None
    bt_speaker_index = None
    hat_speaker_index = None
    
    for i in range(p.get_device_count()):
        try:
            info = p.get_device_info_by_index(i)
            name = info.get('name', '').lower()
            
            # Find microphone (ReSpeaker)
            if info.get('maxInputChannels', 0) > 0:
                if 'seeed' in name or 'respeaker' in name:
                    mic_index = i
                    logger.info(f"Found ReSpeaker Mic: {i}")
            
            # Find speaker (Bluetooth preferred)
            if info.get('maxOutputChannels', 0) > 0:
                if 'bluealsa' in name or 'bluetooth' in name:
                    bt_speaker_index = i
                    logger.info(f"Found Bluetooth: {i}")
                elif 'seeed' in name or 'respeaker' in name:
                    hat_speaker_index = i
                    logger.info(f"Found ReSpeaker Speaker: {i}")
                    
        except Exception as e:
            continue
    
    p.terminate()
    
    # Use Bluetooth if available, else ReSpeaker
    output = bt_speaker_index if bt_speaker_index is not None else hat_speaker_index
    
    logger.info(f"Using output device: {output}")
    return {"input": mic_index, "output": output}
'''
    
    with open('/home/pommai/app/audio_utils.py', 'w') as f:
        f.write(audio_utils_content)
    
    print("‚úì Created audio_utils.py")

def patch_client():
    """Patch the main client to use audio_utils"""
    
    client_path = '/home/pommai/app/pommai_client_fastrtc.py'
    backup_path = f'/home/pommai/app/pommai_client_fastrtc.py.backup.{datetime.now().strftime("%Y%m%d_%H%M%S")}'
    
    # Make backup
    shutil.copy2(client_path, backup_path)
    print(f"‚úì Backed up to {backup_path}")
    
    # Read current file
    with open(client_path, 'r') as f:
        lines = f.readlines()
    
    # Find where to add import
    import_added = False
    hardware_patched = False
    
    for i, line in enumerate(lines):
        # Add import after other local imports
        if not import_added and 'from led_controller import' in line:
            lines.insert(i+1, 'from audio_utils import get_audio_device_indices\n')
            import_added = True
            
        # Find HardwareController initialization and patch it
        if not hardware_patched and 'self.hardware = HardwareController(' in line:
            # Find the end of this initialization
            j = i
            while j < len(lines) and ')' not in lines[j]:
                j += 1
            
            # Replace the initialization
            new_init = '''        # Get audio devices with Bluetooth fallback
        audio_devices = get_audio_device_indices()
        self.hardware = HardwareController(
            sample_rate=config.SAMPLE_RATE,
            channels=config.CHANNELS,
            chunk_size=config.CHUNK_SIZE,
            input_device_index=audio_devices.get("input"),
            output_device_index=audio_devices.get("output")
        )
'''
            # Remove old lines and insert new
            del lines[i:j+1]
            lines.insert(i, new_init)
            hardware_patched = True
            break
    
    if import_added and hardware_patched:
        # Write patched file
        with open(client_path, 'w') as f:
            f.writelines(lines)
        print("‚úì Patched pommai_client_fastrtc.py")
        return True
    else:
        print("‚úó Could not patch client (may already be patched)")
        return False

def install_missing_packages():
    """Install only the missing packages"""
    print("\n Installing missing Bluetooth audio packages...")
    os.system('sudo apt-get update')
    os.system('sudo apt-get install -y bluealsa bluetooth bluez ffmpeg')
    print("‚úì Packages installed")

def setup_bluealsa_service():
    """Ensure BlueALSA service is running"""
    print("\nSetting up BlueALSA service...")
    
    service_content = '''[Unit]
Description=BlueALSA
After=bluetooth.service
Requires=bluetooth.service

[Service]
Type=simple
ExecStart=/usr/bin/bluealsa --profile=a2dp-sink --profile=a2dp-source

[Install]
WantedBy=multi-user.target
'''
    
    with open('/tmp/bluealsa.service', 'w') as f:
        f.write(service_content)
    
    os.system('sudo mv /tmp/bluealsa.service /etc/systemd/system/')
    os.system('sudo systemctl daemon-reload')
    os.system('sudo systemctl enable bluealsa')
    os.system('sudo systemctl start bluealsa')
    print("‚úì BlueALSA service configured")

def main():
    print("=" * 50)
    print("Pommai Audio Patch - Safe Bluetooth Addition")
    print("=" * 50)
    
    # Check if running on Pi
    if not os.path.exists('/home/pommai/app'):
        print("ERROR: This must be run on the Raspberry Pi in the pommai directory")
        return
    
    print("\nThis will:")
    print("1. Backup your current client")
    print("2. Add Bluetooth audio support")
    print("3. Keep all existing functionality")
    print("\nYour current setup will NOT be broken!")
    
    response = input("\nProceed? (y/n): ")
    if response.lower() != 'y':
        print("Cancelled")
        return
    
    # Apply patches
    create_audio_utils()
    
    if patch_client():
        print("\n‚úì Client patched successfully!")
        
        print("\nInstalling BlueALSA...")
        install_missing_packages()
        setup_bluealsa_service()
        
        print("\n" + "=" * 50)
        print("PATCH COMPLETE!")
        print("=" * 50)
        print("\nNext steps:")
        print("1. Restart the service: sudo systemctl restart pommai")
        print("2. Check logs: sudo journalctl -u pommai -f")
        print("\nYour Bluetooth speaker should now work!")
    else:
        print("\nPatch may have already been applied or failed")
        print("Check your backup files in /home/pommai/app/")

if __name__ == "__main__":
    main()
</file>

<file path="config/pommai.service">
[Unit]
Description=Pommai Smart Toy Client
After=network-online.target sound.target
Wants=network-online.target
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=10
User=pommai
Group=pommai
WorkingDirectory=/home/pommai/app
Environment="PATH=/home/pommai/app/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Environment="PYTHONPATH=/home/pommai/app"
ExecStart=/home/pommai/app/venv/bin/python /home/pommai/app/pommai_client_fastrtc.py

# Resource limits for Pi Zero 2W
MemoryMax=200M
CPUQuota=60%

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=pommai

# Security hardening (relaxed for GPIO/I2C/SPI access)
NoNewPrivileges=true
PrivateTmp=false
ProtectSystem=false
ProtectHome=false
ReadWritePaths=/home/pommai /tmp /var/log/pommai

[Install]
WantedBy=multi-user.target
</file>

<file path="debug_audio_flow.py">
#!/usr/bin/env python3
"""
Debug Audio Flow - Trace why audio isn't being processed by AI
"""

import asyncio
import json
import logging
import os
import time
from dotenv import load_dotenv

# Load environment
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_audio_flow():
    """Test the complete audio processing flow"""
    
    print("üîç Audio Flow Diagnostic Test")
    print("=" * 50)
    
    # Import the client components
    try:
        from src.fastrtc_connection import FastRTCConnection, FastRTCConfig
        from src.pommai_client_fastrtc import PommaiClientFastRTC, Config
        logger.info("‚úÖ Successfully imported client components")
    except ImportError as e:
        logger.error(f"‚ùå Failed to import client components: {e}")
        return
    
    # Create config
    config = Config()
    logger.info(f"üìã Config loaded:")
    logger.info(f"   Gateway URL: {config.FASTRTC_GATEWAY_URL}")
    logger.info(f"   Device ID: {config.DEVICE_ID}")
    logger.info(f"   Toy ID: {config.TOY_ID}")
    
    # Test 1: Basic WebSocket connection
    print("\n1. Testing WebSocket Connection...")
    print("-" * 30)
    
    try:
        import websockets
        
        # Build WebSocket URL
        gateway_url = config.FASTRTC_GATEWAY_URL
        if not gateway_url.endswith('/ws'):
            gateway_url = gateway_url.rstrip('/') + '/ws'
        
        ws_url = f"{gateway_url}/{config.DEVICE_ID}/{config.TOY_ID}"
        logger.info(f"Connecting to: {ws_url}")
        
        async with websockets.connect(ws_url, subprotocols=['fastrtc']) as ws:
            logger.info("‚úÖ WebSocket connected successfully")
            
            # Send configuration
            config_msg = {
                'type': 'config',
                'deviceId': config.DEVICE_ID,
                'toyId': config.TOY_ID,
                'audioFormat': 'pcm16',
                'sampleRate': 16000,
                'timestamp': time.time()
            }
            
            await ws.send(json.dumps(config_msg))
            logger.info("‚úÖ Configuration sent")
            
            # Test 2: Send test audio and check processing
            print("\n2. Testing Audio Processing...")
            print("-" * 30)
            
            # Generate test PCM16 audio (1 second of 440Hz tone)
            import numpy as np
            
            sample_rate = 16000
            duration = 1.0  # 1 second
            frequency = 440  # A4 note
            
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            wave = np.sin(frequency * 2 * np.pi * t) * 0.3  # Reduced amplitude
            pcm_data = (wave * 32767).astype(np.int16).tobytes()
            
            logger.info(f"Generated test audio: {len(pcm_data)} bytes")
            
            # Start streaming
            await ws.send(json.dumps({
                'type': 'start_streaming',
                'timestamp': time.time()
            }))
            logger.info("‚úÖ Started streaming mode")
            
            # Send audio in chunks
            chunk_size = 640  # 20ms at 16kHz
            chunks_sent = 0
            
            for i in range(0, len(pcm_data), chunk_size):
                chunk = pcm_data[i:i+chunk_size]
                is_final = (i + chunk_size >= len(pcm_data))
                
                msg = {
                    'type': 'audio_chunk',
                    'payload': {
                        'data': chunk.hex(),
                        'format': 'pcm16',
                        'sampleRate': 16000,
                        'isFinal': is_final
                    },
                    'timestamp': time.time()
                }
                
                await ws.send(json.dumps(msg))
                chunks_sent += 1
                
                if chunks_sent % 10 == 0:
                    logger.info(f"Sent {chunks_sent} audio chunks...")
                
                # Small delay to simulate real-time
                await asyncio.sleep(0.02)
            
            logger.info(f"‚úÖ Sent {chunks_sent} audio chunks total")
            
            # Stop streaming
            await ws.send(json.dumps({
                'type': 'stop_streaming',
                'timestamp': time.time()
            }))
            logger.info("‚úÖ Stopped streaming mode")
            
            # Test 3: Wait for AI response
            print("\n3. Waiting for AI Response...")
            print("-" * 30)
            
            timeout = 15  # 15 seconds timeout
            start_time = time.time()
            responses_received = 0
            
            while time.time() - start_time < timeout:
                try:
                    message = await asyncio.wait_for(ws.recv(), timeout=1.0)
                    data = json.loads(message)
                    
                    msg_type = data.get('type')
                    responses_received += 1
                    
                    logger.info(f"üì• Received: {msg_type}")
                    
                    if msg_type == 'text_response':
                        text = data.get('payload', {}).get('text', '')
                        logger.info(f"ü§ñ AI Response: {text}")
                        
                    elif msg_type == 'audio_response':
                        metadata = data.get('payload', {}).get('metadata', {})
                        audio_data = data.get('payload', {}).get('data', '')
                        logger.info(f"üîä Audio Response: format={metadata.get('format')}, "
                                  f"size={len(audio_data)//2}B, final={metadata.get('isFinal')}")
                        
                    elif msg_type == 'error':
                        error = data.get('error', 'Unknown error')
                        logger.error(f"‚ùå Server Error: {error}")
                        
                except asyncio.TimeoutError:
                    continue
                except Exception as e:
                    logger.error(f"‚ùå Error receiving message: {e}")
            
            logger.info(f"üìä Total responses received: {responses_received}")
            
            if responses_received == 0:
                logger.error("‚ùå No responses received - AI pipeline not processing audio!")
            else:
                logger.info("‚úÖ AI pipeline is responding")
                
    except Exception as e:
        logger.error(f"‚ùå WebSocket test failed: {e}")
    
    # Test 4: Check server logs (if accessible)
    print("\n4. Recommendations...")
    print("-" * 20)
    
    print("\nüîç Based on the test results:")
    
    if responses_received == 0:
        print("‚ùå ISSUE: Audio is not being processed by the AI pipeline")
        print("\nüí° Possible causes:")
        print("1. Audio format mismatch (check server expects PCM16)")
        print("2. Audio too short/quiet for speech detection")
        print("3. Server-side processing errors")
        print("4. Convex backend configuration issues")
        print("\nüõ†Ô∏è Next steps:")
        print("1. Check FastRTC gateway server logs")
        print("2. Verify ElevenLabs/Convex API keys")
        print("3. Test with longer, clearer audio")
        
    else:
        print("‚úÖ Audio processing pipeline is working!")
        print("The issue might be in the client-side audio playback")

if __name__ == "__main__":
    asyncio.run(test_audio_flow())
</file>

<file path="deploy_fixes.sh">
#!/bin/bash
# Deployment script to update Raspberry Pi client with fixes

echo "=== Pommai Client Update Script ==="
echo "This script will update the client with latest fixes"
echo ""

# Check if running on Pi
if [ ! -f /proc/device-tree/model ]; then
    echo "Warning: Not running on Raspberry Pi, but continuing..."
fi

# Stop the service if running
echo "Stopping pommai service..."
sudo systemctl stop pommai 2>/dev/null || true

# Backup current code
echo "Creating backup..."
sudo cp -r /opt/pommai/src /opt/pommai/src.backup.$(date +%Y%m%d_%H%M%S)

# Update fastrtc_connection.py with WebSocket URL fix
echo "Updating fastrtc_connection.py..."
cat > /tmp/fastrtc_connection_patch.py << 'EOF'
# Patch for fastrtc_connection.py - Fix WebSocket URL construction
# Apply this to line 87-98 in connect() method

            # Construct proper WebSocket URL with device_id and toy_id in path
            # Expected format: ws://host:port/ws/{device_id}/{toy_id}
            base_url = self.config.gateway_url.rstrip('/')
            if not base_url.endswith('/ws'):
                if '/ws' not in base_url:
                    base_url = f"{base_url}/ws"
            
            # Append device_id and toy_id to the path
            ws_url = f"{base_url}/{self.config.device_id}/{self.config.toy_id}"
            
            logger.info(f"Connecting to FastRTC gateway at {ws_url}")
EOF

# Update pommai_client_fastrtc.py configuration
echo "Updating pommai_client_fastrtc.py configuration..."
cat > /tmp/pommai_client_patch.py << 'EOF'
# Patch for pommai_client_fastrtc.py - Fix gateway URL configuration
# Update line 83-85 in Config class

    # FastRTC Gateway connection
    # Note: The actual WebSocket path will be constructed as: {GATEWAY_URL}/ws/{device_id}/{toy_id}
    FASTRTC_GATEWAY_URL: str = _get_env_with_fallback('FASTRTC_GATEWAY_URL', ['GATEWAY_URL'], 'ws://localhost:8080')
EOF

# Update conversation_cache.py with database schema fix
echo "Updating conversation_cache.py..."
cat > /tmp/conversation_cache_patch.py << 'EOF'
# Patch for conversation_cache.py - Add sync_attempts to usage_metrics
# Add after line 161 in _init_database() method

            # Add missing columns to existing tables (migration)
            try:
                await db.execute('ALTER TABLE usage_metrics ADD COLUMN sync_attempts INTEGER DEFAULT 0')
                await db.commit()
                logger.info("Added sync_attempts column to usage_metrics table")
            except Exception:
                # Column already exists, ignore
                pass
EOF

# Apply patches (you would need to actually apply these patches properly)
echo "Applying patches..."
echo "NOTE: Manual patching required - please update the files with the changes shown above"

# Update environment configuration
echo ""
echo "Updating environment configuration..."
if [ -f /opt/pommai/.env ]; then
    # Check if GATEWAY_URL is set
    if ! grep -q "GATEWAY_URL=" /opt/pommai/.env; then
        echo ""
        echo "Please add the following to /opt/pommai/.env:"
        echo "GATEWAY_URL=ws://YOUR_GATEWAY_IP:8080"
        echo ""
        echo "Replace YOUR_GATEWAY_IP with the actual IP address of your gateway server"
    else
        echo "GATEWAY_URL already configured in .env"
    fi
else
    echo "Creating .env file..."
    cat > /opt/pommai/.env << 'EOF'
# Pommai Client Configuration

# Gateway connection
GATEWAY_URL=ws://192.168.1.100:8080  # Replace with your gateway IP

# Device identification
DEVICE_ID=rpi-zero2w-001
TOY_ID=kd729cad81984f52pz1v1f3gh57q3774

# Audio configuration (optional)
PLAYBACK_SAMPLE_RATE=48000  # For Bluetooth speakers
AUDIO_SEND_FORMAT=pcm16     # or opus for compression

# Features
ENABLE_WAKE_WORD=false
ENABLE_OFFLINE_MODE=true

# Logging
LOG_LEVEL=INFO
EOF
    echo "Created .env file - please update GATEWAY_URL with your gateway IP"
fi

# Clear old database to force schema recreation
echo ""
read -p "Do you want to clear the database to fix schema issues? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "Backing up and clearing database..."
    sudo mv /opt/pommai/cache/conversations.db /opt/pommai/cache/conversations.db.backup.$(date +%Y%m%d_%H%M%S) 2>/dev/null || true
    echo "Database cleared - will be recreated on next start"
fi

# Restart the service
echo ""
echo "Starting pommai service..."
sudo systemctl start pommai

# Check status
sleep 2
sudo systemctl status pommai --no-pager | head -n 10

echo ""
echo "=== Update Complete ==="
echo ""
echo "IMPORTANT: Please manually apply the code patches shown above to:"
echo "  1. /opt/pommai/src/fastrtc_connection.py (lines 87-98)"
echo "  2. /opt/pommai/src/pommai_client_fastrtc.py (lines 83-85)"
echo "  3. /opt/pommai/src/conversation_cache.py (after line 161)"
echo ""
echo "Then restart the service with: sudo systemctl restart pommai"
echo ""
echo "To view logs: sudo journalctl -u pommai -f"
</file>

<file path="DEPLOYMENT_GUIDE.md">
# Pommai Client Deployment (Raspberry Pi OS Lite 64-bit)

This guide gives you exact, copy-paste steps to deploy the Pommai Raspberry Pi client on Raspberry Pi OS Lite (64-bit, Bookworm). It configures the ReSpeaker 2‚ÄëMics HAT (ALSA), installs dependencies, creates a systemd service, and starts the client.

If you previously followed DietPi instructions, ignore them. This guide replaces all older DietPi-specific steps.

---

## What you need
- Raspberry Pi Zero 2W with Raspberry Pi OS Lite (64-bit) Bookworm
- ReSpeaker 2‚ÄëMics Pi HAT installed on the GPIO header
- Wi‚ÄëFi with internet access and SSH enabled
- A small speaker (3.5mm or attached to the HAT‚Äôs output)
- Your PC on the same network, running the FastRTC Gateway (for local dev) or a hosted gateway

Tip: On first boot, ensure you set a password and enable SSH via Raspberry Pi Imager‚Äôs advanced options.

---

## Step 1 ‚Äî SSH into your Pi

```bash
# Replace <PI_IP> and <USERNAME> as needed (default user is usually 'pi')
ssh <USERNAME>@<PI_IP>
```

---

## Step 2 ‚Äî Copy the client folder to the Pi (from your PC)

Windows PowerShell (on your PC):
```powershell
# From the root of your project on your PC
# 1) Create a zip with the Raspberry Pi client files
Compress-Archive -Force -Path .\apps\raspberry-pi\* -DestinationPath .\pommai-raspi.zip

# 2) Copy the zip to your Pi (requires OpenSSH client on Windows)
scp .\pommai-raspi.zip <USERNAME>@<PI_IP>:/home/<USERNAME>/
```

Back on the Pi:
```bash
# Create a working directory and extract the files
mkdir -p ~/pommai-setup
unzip -q ~/pommai-raspi.zip -d ~/pommai-setup
cd ~/pommai-setup
```

---

## Step 3 ‚Äî One-time setup (installs deps, drivers, service)

Run the provided setup script from the project you just copied. It:
- Installs system packages, PyAudio, Opus, SQLite, etc.
- Enables I2C/SPI and installs the ReSpeaker driver
- Creates a dedicated user (pommai) and a Python venv
- Writes ALSA defaults for the ReSpeaker HAT
- Creates the systemd service to auto-start the client

```bash
# IMPORTANT: run from the directory that contains src/ and scripts/
# The script will handle Raspberry Pi OS Bookworm‚Äôs /boot/firmware/config.txt automatically.
sudo bash scripts/setup.sh
```

If prompted to reboot for hardware overlays, you can reboot at the end (or continue now and reboot later).

---

## Step 4 ‚Äî Configure your environment (.env)

```bash
# Edit the .env created by the setup script
sudo nano /home/pommai/app/.env
```

Replace values as needed. This annotated template shows what each variable means:

```bash
# ================= Pommai Client Configuration (.env) =================

# FastRTC Gateway WebSocket URL
# - For local testing: point to your PC running the gateway in Docker (change 192.168.x.x)
# - For hosted gateway: use your wss:// endpoint
FASTRTC_GATEWAY_URL=ws://192.168.1.100:8080/ws

# AUTH_TOKEN: Access token for your gateway (if your server requires auth)
# - For local dev, you can leave this empty if auth is disabled on your gateway
# - Never print or commit this token
AUTH_TOKEN=

# DEVICE_ID: Stable, unique ID for this hardware device
# - Choose any descriptive string; must stay the same across reboots
# - Used by the server to associate metrics and sync batches with this device
DEVICE_ID=rpi-zero2w-001

# TOY_ID: Which toy/personality/config to load on the server
# - Must match a configuration known to your gateway/server
# - For local dev, 'default-toy' is fine if your server accepts it
TOY_ID=default-toy

# Paths (defaults are fine unless you customized setup locations)
VOSK_MODEL_PATH=/home/pommai/models/vosk-model-small-en-us-0.15
CACHE_DB_PATH=/tmp/pommai_cache.db
AUDIO_RESPONSES_PATH=/home/pommai/audio_responses

# Optional features
# - Enable wake word only if needed (adds CPU load on Pi Zero 2W)
ENABLE_WAKE_WORD=false
# - Keep offline mode enabled to cache conversations and metrics
ENABLE_OFFLINE_MODE=true
# =====================================================================
```

Save and exit (Ctrl+O, Enter, Ctrl+X). Then secure the file:
```bash
sudo chown pommai:pommai /home/pommai/app/.env
sudo chmod 600 /home/pommai/app/.env
```

---

## Step 5 ‚Äî Start the service and tail logs

```bash
# Enable on boot and start now
sudo systemctl enable pommai
sudo systemctl start pommai

# Follow logs (Ctrl+C to stop)
sudo journalctl -u pommai -f
```

You should see logs showing a WebSocket connection to your gateway and audio initialization.

---

## Step 6 ‚Äî Verify audio and HAT

```bash
# List playback and capture devices (should show 'seeed' card)
aplay -l
arecord -l

# Quick speaker test (1 kHz tone for ~2 seconds)
timeout 2 speaker-test -t sine -f 1000 -c 2 >/dev/null 2>&1 || echo "Speaker test may have been skipped"

# Optional: record 3 seconds and play back
arecord -d 3 -f S16_LE -r 16000 -c 1 /tmp/test.wav && aplay /tmp/test.wav
```

If you don‚Äôt see the seeed device or you get audio errors, reboot:
```bash
sudo reboot
```

---

## Optional: Bluetooth audio (BlueALSA)
The default path is ALSA directly to the ReSpeaker HAT. If you later want Bluetooth audio output via BlueALSA, you can re-run setup with a playback profile override:
```bash
# Rerun setup to write a BlueALSA-focused /etc/asound.conf (experimental)
cd ~/pommai-setup
sudo AUDIO_PLAYBACK_PROFILE=bluealsa bash scripts/setup.sh
```
Make sure your Bluetooth speaker is paired and set as the default sink first.

---

## What the key settings mean
- AUTH_TOKEN: A bearer token the gateway uses to authenticate this device. Omit for local dev if your gateway doesn‚Äôt require auth. Keep it secret.
- DEVICE_ID: A stable identifier for the physical Pi. Pick something unique and persistent. Used for metrics and sync tracking.
- TOY_ID: The toy/personality/config to load on the server. Your server should recognize this string and return the right settings.
- FASTRTC_GATEWAY_URL: The WebSocket URL the client connects to. For local dev, point it at your PC‚Äôs LAN IP: ws://<your-pc-ip>:8080/ws.

---

## Quick troubleshooting
```bash
# Follow logs
sudo journalctl -u pommai -f

# Check service status
sudo systemctl status pommai --no-pager

# Confirm gateway hostname is resolvable and reachable
# (replace URL from your .env)
getent hosts $(echo $(grep ^FASTRTC_GATEWAY_URL= /home/pommai/app/.env | cut -d= -f2) | sed -E 's|^wss?://([^/:]+).*|\1|')
```

If audio devices don‚Äôt show up, check overlays were written to /boot/firmware/config.txt (Bookworm) or /boot/config.txt (older) and reboot.

---

## Success checklist
- Service is running: `sudo systemctl is-active pommai` returns active
- Logs show ‚ÄúSuccessfully connected to FastRTC gateway‚Äù
- LED feedback changes when listening/speaking (on Pi)
- You hear TTS playback from the speaker

That‚Äôs it. Your Pommai Raspberry Pi client should now be up and running on Raspberry Pi OS Lite (64-bit).
</file>

<file path="fix_bluetooth_audio.sh">
#!/bin/bash

echo "=== Fixing Bluetooth Audio Device Busy Issue ==="
echo ""

# 1. Check what's using the audio device
echo "1. Checking what processes are using audio devices..."
lsof /dev/snd/* 2>/dev/null || echo "No processes found using /dev/snd"
echo ""

# 2. Check if pommai service is running
echo "2. Checking if pommai service is running..."
systemctl status pommai --no-pager | grep -E "Active:|Main PID:"
echo ""

# 3. Stop pommai service temporarily
echo "3. Stopping pommai service to free audio device..."
sudo systemctl stop pommai
sleep 2
echo "Pommai service stopped"
echo ""

# 4. Check BlueALSA processes
echo "4. Checking BlueALSA processes..."
ps aux | grep -E "bluealsa|bluetoothd" | grep -v grep
echo ""

# 5. Restart BlueALSA to clear any stuck connections
echo "5. Restarting BlueALSA service..."
sudo systemctl restart bluealsa
sleep 2
echo "BlueALSA restarted"
echo ""

# 6. Check Bluetooth device status
echo "6. Checking Bluetooth device connection..."
bluetoothctl info | grep -E "Device|Name:|Connected:"
echo ""

# 7. Test audio directly with ALSA
echo "7. Testing audio with ALSA tools..."
echo "   Playing test tone for 2 seconds..."

# Try different device names
echo "   Trying bluealsa device..."
timeout 2 speaker-test -c 1 -t sine -f 440 -D bluealsa 2>&1 | grep -E "Rate|Playback|error" || echo "bluealsa test done"

echo ""
echo "   Trying default device..."
timeout 2 speaker-test -c 1 -t sine -f 440 2>&1 | grep -E "Rate|Playback|error" || echo "default test done"

echo ""
echo "   Trying hw:0,0..."
timeout 2 speaker-test -c 1 -t sine -f 440 -D hw:0,0 2>&1 | grep -E "Rate|Playback|error" || echo "hw:0,0 test done"

echo ""
# 8. Check ALSA configuration
echo "8. Checking ALSA configuration..."
if [ -f /etc/asound.conf ]; then
    echo "Contents of /etc/asound.conf:"
    cat /etc/asound.conf
else
    echo "No /etc/asound.conf found"
fi

if [ -f ~/.asoundrc ]; then
    echo "Contents of ~/.asoundrc:"
    cat ~/.asoundrc
else
    echo "No ~/.asoundrc found"
fi

echo ""
echo "=== Fix Complete ==="
echo ""
echo "Next steps:"
echo "1. Run the Python test again: python3 test_elevenlabs_bluetooth.py"
echo "2. If it works, restart pommai: sudo systemctl start pommai"
echo "3. If still busy, try using device index 6 (bt) or 7 (speaker) instead of 2"
echo "4. You may need to modify audio_utils.py to use the correct device index"
</file>

<file path="hardware_controller_improved.py">
#!/usr/bin/env python3
"""
Improved Hardware Controller that opens/closes audio streams on demand
This prevents "Device or resource busy" errors
"""

import pyaudio
import logging
from typing import Optional
import threading

logger = logging.getLogger(__name__)


class LazyHardwareController:
    """
    Hardware controller that opens audio streams only when needed.
    This prevents blocking the Bluetooth device when idle.
    """
    
    def __init__(self, sample_rate: int, channels: int, chunk_size: int,
                 input_device_index: Optional[int] = None,
                 output_device_index: Optional[int] = None,
                 output_sample_rate: Optional[int] = None):
        # Store configuration
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk_size = chunk_size
        self.input_device_index = input_device_index
        self.output_device_index = output_device_index
        self.output_sample_rate = output_sample_rate or sample_rate
        
        # PyAudio instance (keep this open)
        self._pa = pyaudio.PyAudio()
        
        # Streams (open on demand)
        self._input_stream = None
        self._output_stream = None
        
        # Thread safety
        self._lock = threading.Lock()
        
        logger.info(f"LazyHardwareController initialized - Input: {input_device_index}, Output: {output_device_index}")
    
    @property
    def input_stream(self):
        """Get or create input stream on demand"""
        with self._lock:
            if self._input_stream is None or not self._input_stream.is_active():
                logger.debug("Opening input stream on demand")
                try:
                    if self._input_stream:
                        self._input_stream.close()
                except:
                    pass
                    
                self._input_stream = self._pa.open(
                    format=pyaudio.paInt16,
                    channels=self.channels,
                    rate=self.sample_rate,
                    input=True,
                    input_device_index=self.input_device_index,
                    frames_per_buffer=self.chunk_size
                )
            return self._input_stream
    
    @property
    def output_stream(self):
        """Get or create output stream on demand"""
        with self._lock:
            if self._output_stream is None or not self._output_stream.is_active():
                logger.debug(f"Opening output stream on demand (device {self.output_device_index})")
                try:
                    if self._output_stream:
                        self._output_stream.close()
                except:
                    pass
                
                # Use larger buffer for Bluetooth to reduce underruns
                out_buffer = max(self.chunk_size, 2048)
                self._output_stream = self._pa.open(
                    format=pyaudio.paInt16,
                    channels=self.channels,
                    rate=self.output_sample_rate,
                    output=True,
                    output_device_index=self.output_device_index,
                    frames_per_buffer=out_buffer
                )
            return self._output_stream
    
    def close_input_stream(self):
        """Close input stream to free the device"""
        with self._lock:
            if self._input_stream:
                try:
                    logger.debug("Closing input stream")
                    self._input_stream.stop_stream()
                    self._input_stream.close()
                except Exception as e:
                    logger.warning(f"Error closing input stream: {e}")
                finally:
                    self._input_stream = None
    
    def close_output_stream(self):
        """Close output stream to free the device"""
        with self._lock:
            if self._output_stream:
                try:
                    logger.debug("Closing output stream")
                    self._output_stream.stop_stream()
                    self._output_stream.close()
                except Exception as e:
                    logger.warning(f"Error closing output stream: {e}")
                finally:
                    self._output_stream = None
    
    def cleanup(self):
        """Clean up all resources"""
        logger.info("Cleaning up hardware controller")
        self.close_input_stream()
        self.close_output_stream()
        
        try:
            self._pa.terminate()
        except Exception as e:
            logger.warning(f"Error terminating PyAudio: {e}")


class SmartAudioStreamManager:
    """
    Enhanced AudioStreamManager that closes streams when idle
    """
    
    def __init__(self, hardware_controller, config):
        self.hardware = hardware_controller
        self.config = config
        # ... rest of initialization ...
        
    async def play_audio_stream(self, audio_chunks):
        """Play audio and close stream when done"""
        try:
            # Play audio using hardware.output_stream
            # ... existing playback code ...
            pass
        finally:
            # IMPORTANT: Close the output stream when done
            self.hardware.close_output_stream()
            logger.info("Output stream closed after playback")
    
    async def stop_recording(self):
        """Stop recording and close input stream"""
        # ... existing stop code ...
        self.hardware.close_input_stream()
        logger.info("Input stream closed after recording")
</file>

<file path="quick_fix.sh">
#!/bin/bash
# Quick Fix Script for Pommai Raspberry Pi Issues

echo "üîß Pommai Quick Fix Script"
echo "=========================="

# 1. Fix database schema issue
echo "1. Fixing database schema..."
cd /home/pi/pommai/apps/raspberry-pi 2>/dev/null || cd ~/pommai/apps/raspberry-pi 2>/dev/null || cd .

# Remove the problematic database to force recreation
if [ -f "conversation_cache.db" ]; then
    echo "   Backing up and removing conversation_cache.db..."
    mv conversation_cache.db conversation_cache.db.backup.$(date +%Y%m%d_%H%M%S)
fi

# 2. Install missing Python packages
echo "2. Installing missing Python packages..."
pip3 install websockets --user
pip3 install pyaudio --user
pip3 install numpy --user

# 3. Restart services
echo "3. Restarting services..."
sudo systemctl stop pommai
sleep 2
sudo systemctl start pommai

echo "4. Checking service status..."
if systemctl is-active --quiet pommai; then
    echo "   ‚úÖ Pommai service is running"
else
    echo "   ‚ùå Pommai service failed to start"
    echo "   Checking logs:"
    sudo journalctl -u pommai -n 10 --no-pager
fi

echo ""
echo "üîß Quick fixes applied!"
echo "Now test by pressing the button and checking logs with:"
echo "   sudo journalctl -u pommai -f"
</file>

<file path="raspberrypinewsetup.md">
we installed RASPBERRY PI LITE OS 64 BIT INSTEAD OF DIET PI DUE TO ISSUES WITH THE KERNEL AND DRIVERS.
We have connected the respeaker HAT to the pi, we have installed bluetooth and enabled connected a speaker by deafault. 
we tested the recording and playing audio and it worked! for now we are sticking to Blue alsa.
Verified the ReSpeaker card appeared as seeed2micvoicec in ALSA device lists.

2. Addressed Kernel and Header Compatibility
Ensured the running kernel version matched installed kernel headers (- important for DKMS driver compilation).

Resolved mismatches by either accepting the installer‚Äôs kernel downgrade or installing matching headers for the current kernel.

Cleaned up any broken DKMS module states or leftover files from failed installs.

3. Set Up Bluetooth Speaker for Audio Output
Installed Bluetooth tools and BlueALSA audio bridge packages.

Paired the Bluetooth speaker/headset using bluetoothctl:

Enabled power, agent, pairable, discoverable modes on Pi‚Äôs Bluetooth.

Scanned and paired/trusted your speaker using its MAC address.

Connected to the Bluetooth audio sink.

Verified Bluetooth device connection and profiles (A2DP for high-quality audio output).

4. Configured ALSA for Playback/Capture Routing
Created or updated /etc/asound.conf to use a custom ALSA default device:

Playback routed through BlueALSA to the Bluetooth speaker.

Capture routed directly to the ReSpeaker device (card 0, device 0).

This allowed arecord and aplay to use ‚Äúdefault‚Äù devices without specifying hardware IDs.

5. Audio Testing and Format Adjustment
Identified the exact card and device number for ReSpeaker with arecord -l.

Recorded audio at device hw:0,0 but with ReSpeaker-compatible parameters:

16-bit little-endian format, 16 kHz sample rate, 2 channels (stereo) due to device hardware capabilities.

Played back the recorded audio over Bluetooth via BlueALSA device.

6. Understanding Audio Systems Used
Used ALSA as the base sound system for device recognition and low-level audio I/O.

Used BlueALSA, a lightweight ALSA Bluetooth audio bridge, to route audio playback to Bluetooth speakers without PulseAudio overhead.

Avoided PulseAudio complexity due to headless setup and to keep the audio pipeline simple and reliable.

Summary
You successfully:

Built and installed ReSpeaker drivers matching your kernel.

Paired and connected Bluetooth audio speakers.

Routed ALSA capture and playback to proper devices via /etc/asound.conf.

Recorded high-quality stereo audio using ReSpeaker mics.

Played audio back over Bluetooth speakers, validating end-to-end functionality.

This setup gives you a stable, headless speech input/output system with high-quality microphones and Bluetooth wireless audio output!
</file>

<file path="README.md">
# Pommai Raspberry Pi Client

This is the Raspberry Pi Zero 2W client for the Pommai smart toy platform. It provides voice interaction capabilities with multiple toy personalities, Guardian mode safety features, and offline functionality.

## Features

- **Real-time voice interaction** via FastRTC WebSocket gateway
- **Multiple toy personalities** - Switch between different AI toy configurations
- **Guardian mode** - Enhanced safety features for children
- **Offline mode** - Basic interactions when internet is unavailable
- **Wake word detection** - Hands-free activation with "Hey Pommai"
- **Hardware integration** - Button control and LED feedback via ReSpeaker HAT
- **Audio compression** - Opus codec for efficient streaming
- **Secure communication** - Token-based authentication with FastRTC gateway

## Hardware Requirements

- Raspberry Pi Zero 2W (512MB RAM)
- ReSpeaker 2-Mics Pi HAT
- MicroSD card (8GB minimum)
- Power supply (5V 2.5A recommended)
- Optional: Speaker for audio output

## Software Requirements

- DietPi OS (32-bit) or Raspberry Pi OS Lite
- Python 3.9 or higher
- ALSA audio drivers
- Internet connection for initial setup

## Installation

### 1. Prepare the Raspberry Pi

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install system dependencies
sudo apt install -y python3-pip python3-venv git
sudo apt install -y portaudio19-dev python3-pyaudio
sudo apt install -y libopus0 libopus-dev
sudo apt install -y alsa-utils

# Install ReSpeaker drivers
git clone https://github.com/respeaker/seeed-voicecard
cd seeed-voicecard
sudo ./install.sh
sudo reboot
```

### 2. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/your-org/pommai.git
cd pommai/apps/raspberry-pi

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# Download Vosk model
mkdir -p /home/pommai/models
cd /home/pommai/models
wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
unzip vosk-model-small-en-us-0.15.zip
```

### 3. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit configuration
nano .env
```

Required configuration:
- `FASTRTC_GATEWAY_URL` - Your FastRTC gateway WebSocket URL
- `AUTH_TOKEN` - Authentication token from web platform
- `DEVICE_ID` - Unique identifier for this device
- `TOY_ID` - Initial toy to load

### 4. Test Installation

```bash
# Test audio
python tests/test_audio.py

# Test GPIO/LEDs
python tests/test_leds.py

# Test button
python tests/test_button.py
```

## Usage

### Running the Client

```bash
# Activate virtual environment
source venv/bin/activate

# Run the client
python src/pommai_client_fastrtc.py
```

### Systemd Service (Recommended)

Create a systemd service for automatic startup:

```bash
sudo cp config/pommai.service /etc/systemd/system/
sudo systemctl enable pommai
sudo systemctl start pommai
```

Check service status:
```bash
sudo systemctl status pommai
sudo journalctl -u pommai -f
```

## LED Patterns

The ReSpeaker HAT LEDs indicate different states:

- **Blue breathing** - Idle, waiting for wake word
- **Blue pulse** - Listening/Recording
- **Rainbow swirl** - Processing/Thinking
- **Green solid** - Speaking
- **Red flash** - Error or offline
- **Yellow pulse** - Loading toy configuration

## Button Controls

- **Single press** - Start/stop recording (push-to-talk)
- **Long press (3s)** - Enter safe mode
- **Triple press** - Factory reset (when implemented)

## Offline Mode

When internet is unavailable, the toy provides:
- Basic greetings and responses
- Simple songs and jokes
- Safety-compliant interactions only
- Cached responses for common queries

All offline interactions are logged and synced when connection is restored.

## Troubleshooting

### No Audio Input
```bash
# Check audio devices
arecord -l
# Test recording
arecord -d 5 test.wav
```

### GPIO Permission Error
```bash
# Add user to gpio group
sudo usermod -a -G gpio $USER
# Logout and login again
```

### High CPU Usage
- Check Vosk model size (use smaller model if needed)
- Verify Opus codec is properly installed
- Monitor with `htop` or `ps aux`

### Connection Issues
- Verify FASTRTC_GATEWAY_URL and AUTH_TOKEN are correct
- Check device can reach the gateway host (see diagnose.sh)
- Test network connectivity
- Review logs: `journalctl -u pommai -n 100`

## Development

### Project Structure
```
raspberry-pi/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ pommai_client_fastrtc.py  # Main FastRTC client application
‚îÇ   ‚îú‚îÄ‚îÄ fastrtc_connection.py     # FastRTC WebSocket handler
‚îÇ   ‚îú‚îÄ‚îÄ pommai_client.py          # Legacy Convex client (deprecated)
‚îÇ   ‚îú‚îÄ‚îÄ audio_stream_manager.py   # Audio capture/playback
‚îÇ   ‚îú‚îÄ‚îÄ opus_audio_codec.py       # Opus compression
‚îÇ   ‚îú‚îÄ‚îÄ led_controller.py         # LED patterns and control
‚îÇ   ‚îú‚îÄ‚îÄ button_handler.py         # GPIO button handling
‚îÇ   ‚îú‚îÄ‚îÄ wake_word_detector.py     # "Hey Pommai" detection
‚îÇ   ‚îî‚îÄ‚îÄ conversation_cache.py     # Offline mode support
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ pommai.service            # Systemd service file
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                  # Automated deployment
‚îÇ   ‚îú‚îÄ‚îÄ update.sh                 # Update script
‚îÇ   ‚îî‚îÄ‚îÄ diagnose.sh               # System diagnostics
‚îú‚îÄ‚îÄ audio_responses/              # Offline audio files
‚îú‚îÄ‚îÄ tests/                        # Hardware and integration tests
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ .env.example                  # Configuration template
‚îî‚îÄ‚îÄ README.md                     # This file
```

### Testing
```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_websocket.py -v
```

### Monitoring
```bash
# Check memory usage
free -h

# Monitor CPU
top -d 1

# Check service logs
sudo journalctl -u pommai --since "1 hour ago"
```

## Security

- Device authentication uses unique tokens
- All communication is encrypted (WSS/HTTPS)
- Audio is not stored permanently
- Guardian mode enforces content filtering
- Offline mode has strict safety rules

## License

See main project LICENSE file.

## Support

For issues and questions:
1. Check troubleshooting section above
2. Review logs with `journalctl -u pommai`
3. Open an issue on GitHub
4. Contact support at support@pommai.com
</file>

<file path="requirements.txt">
# Core dependencies for Pommai Raspberry Pi Client
# Tested on Raspberry Pi Zero 2W with Python 3.9+

# WebSocket communication (for FastRTC gateway)
websockets==12.0

# Audio processing
pyaudio==0.2.14
numpy==1.24.3

# Opus audio codec
# Note: pyopus might need manual installation
# Alternative: opuslib==3.0.1
opuslib==3.0.1  # Changed to opuslib for better compatibility

# GPIO control for Raspberry Pi
RPi.GPIO==0.7.1

# Wake word detection
vosk==0.3.45

# Async file operations
aiofiles==23.2.1
aiosqlite==0.19.0

# Environment configuration
python-dotenv==1.0.0

# HTTP client for file uploads
requests==2.31.0

# System monitoring (optional)
psutil==5.9.8

# Convex Python client
convex==0.6.0

# Safety and Content Moderation
guardrails-ai==0.5.10

# Additional audio processing (if needed)
# scipy==1.10.1
# soundfile==0.12.1

# Development dependencies (optional)
# pytest==7.4.3
# pytest-asyncio==0.21.1
# black==23.11.0
# flake8==6.1.0
</file>

<file path="setup_enhanced.sh">
#!/bin/bash
#
# Pommai Smart Toy Raspberry Pi Setup Script (v2 - BlueALSA & Fallback Support)
# For Raspberry Pi OS Lite (64-bit, Bookworm)
# This script installs all necessary software, drivers, and configurations
# for both ReSpeaker HAT and Bluetooth audio output with automatic fallback
#

set -e # Exit immediately if a command exits with a non-zero status.

# --- Colors for Output ---
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# --- Configuration ---
POMMAI_USER="pommai"
POMMAI_HOME="/home/${POMMAI_USER}"
POMMAI_APP_DIR="${POMMAI_HOME}/app"
VOSK_MODEL_DIR="${POMMAI_HOME}/models"
AUDIO_RESPONSES_DIR="${POMMAI_HOME}/audio_responses"
LOG_DIR="/var/log/pommai"

# Auto-detect correct config.txt path for Bullseye vs Bookworm
BOOT_CONFIG="/boot/firmware/config.txt"
if [ ! -f "$BOOT_CONFIG" ]; then
  BOOT_CONFIG="/boot/config.txt"
fi

echo -e "${BLUE}================================================${NC}"
echo -e "${BLUE}  Pommai Smart Toy Setup Script v2.0${NC}"
echo -e "${BLUE}  With Bluetooth Audio & Smart Fallback${NC}"
echo -e "${BLUE}================================================${NC}"
echo ""

# --- Check if running as root ---
if [[ $EUID -ne 0 ]]; then
   echo -e "${RED}ERROR: This script must be run as root. Please use 'sudo bash setup_enhanced.sh'${NC}" 
   exit 1
fi

# --- Check if running on Raspberry Pi ---
if ! grep -q "Raspberry Pi" /proc/cpuinfo 2>/dev/null; then
    echo -e "${YELLOW}Warning: This script is designed for Raspberry Pi${NC}"
    read -p "Continue anyway? (y/N) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi

# --- Step 1: System Preparation ---
echo -e "${GREEN}[1/12] Updating system and installing core dependencies...${NC}"
apt-get update
apt-get install -y \
    git python3-pip python3-venv python3-dev \
    portaudio19-dev libatlas-base-dev \
    libopus-dev libopus0 opus-tools \
    sqlite3 wget unzip \
    alsa-utils i2c-tools \
    bluetooth bluez libbluetooth-dev bluealsa \
    ffmpeg \
    build-essential \
    libglib2.0-dev \
    libdbus-1-dev \
    libudev-dev \
    libical-dev \
    libreadline-dev

# --- Step 2: User and Directory Setup ---
echo -e "${GREEN}[2/12] Setting up user and directories...${NC}"
if ! id "$POMMAI_USER" &>/dev/null; then
    useradd -m -s /bin/bash "$POMMAI_USER"
    echo -e "  ‚úì Created user: ${POMMAI_USER}"
else
    echo -e "  ‚úì User ${POMMAI_USER} already exists"
fi

# Add user to all necessary groups including bluetooth
usermod -aG audio,gpio,i2c,spi,bluetooth,dialout "$POMMAI_USER"
echo -e "  ‚úì Added user to required groups"

# Create all necessary directories
mkdir -p "${POMMAI_APP_DIR}" "${VOSK_MODEL_DIR}" "${AUDIO_RESPONSES_DIR}" "${LOG_DIR}"
chown -R "${POMMAI_USER}:${POMMAI_USER}" "${POMMAI_HOME}"
chown -R "${POMMAI_USER}:${POMMAI_USER}" "${LOG_DIR}"
echo -e "  ‚úì Created application directories"

# --- Step 3: Hardware Configuration (ReSpeaker HAT) ---
echo -e "${GREEN}[3/12] Configuring hardware interfaces for ReSpeaker HAT...${NC}"

# Remove any existing entries
sed -i '/^dtparam=i2c_arm/d' "$BOOT_CONFIG"
sed -i '/^dtparam=spi/d' "$BOOT_CONFIG"
sed -i '/^dtoverlay=seeed-2mic-voicecard/d' "$BOOT_CONFIG"

# Add fresh entries
echo "dtparam=i2c_arm=on" >> "$BOOT_CONFIG"
echo "dtparam=spi=on" >> "$BOOT_CONFIG"
echo "dtoverlay=seeed-2mic-voicecard" >> "$BOOT_CONFIG"
echo -e "  ‚úì Updated ${BOOT_CONFIG} for I2C, SPI, and ReSpeaker"

# --- Step 4: Install ReSpeaker Drivers ---
echo -e "${GREEN}[4/12] Installing ReSpeaker HAT drivers...${NC}"
cd /tmp
if [ -d "seeed-voicecard" ]; then
    rm -rf seeed-voicecard
fi
git clone https://github.com/respeaker/seeed-voicecard.git
cd seeed-voicecard
./install.sh
echo -e "  ‚úì ReSpeaker drivers installed"
cd /tmp
rm -rf seeed-voicecard

# --- Step 5: Configure Bluetooth Audio (BlueALSA) ---
echo -e "${GREEN}[5/12] Configuring Bluetooth audio with BlueALSA...${NC}"

# Enable and start bluetooth service
systemctl enable bluetooth
systemctl start bluetooth
echo -e "  ‚úì Bluetooth service enabled"

# Configure BlueALSA service
cat > /etc/systemd/system/bluealsa.service << 'EOF'
[Unit]
Description=BlueALSA Bluetooth Audio ALSA Backend
After=bluetooth.service
Requires=bluetooth.service

[Service]
Type=simple
ExecStart=/usr/bin/bluealsa --profile=a2dp-sink --profile=a2dp-source
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable bluealsa
systemctl start bluealsa
echo -e "  ‚úì BlueALSA service configured and started"

# --- Step 6: Download Vosk Model ---
echo -e "${GREEN}[6/12] Downloading offline wake-word model...${NC}"
if [ ! -d "${VOSK_MODEL_DIR}/vosk-model-small-en-us-0.15" ]; then
    cd "${VOSK_MODEL_DIR}"
    wget -q -O vosk-model.zip https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
    unzip -q vosk-model.zip
    rm vosk-model.zip
    chown -R "${POMMAI_USER}:${POMMAI_USER}" "${VOSK_MODEL_DIR}"
    echo -e "  ‚úì Vosk model installed"
else
    echo -e "  ‚úì Vosk model already exists"
fi

# --- Step 7: Setup Python Environment ---
echo -e "${GREEN}[7/12] Setting up Python virtual environment...${NC}"
cd "${POMMAI_APP_DIR}"
sudo -u "$POMMAI_USER" python3 -m venv venv
echo -e "  ‚úì Virtual environment created"

# Copy requirements file if it exists
if [ -f "./requirements.txt" ]; then
    cp ./requirements.txt "${POMMAI_APP_DIR}/"
    chown "${POMMAI_USER}:${POMMAI_USER}" "${POMMAI_APP_DIR}/requirements.txt"
fi

# Upgrade pip and install dependencies
sudo -u "$POMMAI_USER" "${POMMAI_APP_DIR}/venv/bin/pip" install --upgrade pip setuptools wheel
echo -e "  ‚úì Pip upgraded"

# Install Python dependencies
if [ -f "${POMMAI_APP_DIR}/requirements.txt" ]; then
    sudo -u "$POMMAI_USER" "${POMMAI_APP_DIR}/venv/bin/pip" install -r "${POMMAI_APP_DIR}/requirements.txt"
else
    sudo -u "$POMMAI_USER" "${POMMAI_APP_DIR}/venv/bin/pip" install \
        websockets==12.0 \
        pyaudio==0.2.14 \
        RPi.GPIO==0.7.1 \
        vosk==0.3.45 \
        opuslib==3.0.1 \
        aiofiles==23.2.1 \
        python-dotenv==1.0.0 \
        aiosqlite==0.19.0 \
        numpy==1.24.3 \
        requests==2.31.0 \
        psutil==5.9.8 \
        pydub==0.25.1
fi
echo -e "  ‚úì Python dependencies installed"

# --- Step 8: Configure ALSA for Bluetooth Fallback ---
echo -e "${GREEN}[8/12] Configuring ALSA for Bluetooth audio with fallback...${NC}"

# Create system-wide ALSA configuration
cat > /etc/asound.conf << 'EOF'
# System-wide ALSA configuration for Pommai
# This config attempts to use Bluetooth first, falls back to ReSpeaker

pcm.!default {
    type asym
    playback.pcm {
        type plug
        slave.pcm "playback_auto"
    }
    capture.pcm {
        type plug
        slave.pcm "capture_respeaker"
    }
}

# Automatic playback selection with fallback
pcm.playback_auto {
    type plug
    slave.pcm {
        @func refer
        name {
            @func concat
            strings [
                "pcm."
                {
                    @func refer
                    name "bluetooth_or_respeaker"
                    default "hw:seeed2micvoicec,0"
                }
            ]
        }
    }
}

# BlueALSA PCM for Bluetooth devices
pcm.bluealsa {
    type bluealsa
    device "ANY"
    profile "a2dp"
}

# ReSpeaker capture device
pcm.capture_respeaker {
    type hw
    card seeed2micvoicec
    device 0
}

# ReSpeaker playback device
pcm.playback_respeaker {
    type hw
    card seeed2micvoicec
    device 0
}

ctl.!default {
    type hw
    card seeed2micvoicec
}
EOF
echo -e "  ‚úì ALSA configuration created"

# Create user-specific ALSA config with smart fallback
ASOUNDRC_PATH="${POMMAI_HOME}/.asoundrc"
cat > "$ASOUNDRC_PATH" << 'EOF'
# User ALSA configuration for Pommai Client
# Attempts Bluetooth first, falls back to ReSpeaker

# Try BlueALSA first, fall back to ReSpeaker
pcm.!default {
    type asym
    playback.pcm {
        type plug
        slave.pcm "smart_output"
    }
    capture.pcm {
        type plug
        slave.pcm "hw:seeed2micvoicec,0"
    }
}

# Smart output that tries Bluetooth first
pcm.smart_output {
    type plug
    slave.pcm {
        @func refer
        name {
            @func concat
            strings [
                "pcm."
                {
                    @func refer
                    name {
                        @func concat
                        strings [
                            "cards."
                            {
                                @func refer
                                name "bluealsa_available"
                                default "hw:seeed2micvoicec,0"
                            }
                        ]
                    }
                }
            ]
        }
    }
}

pcm.bluealsa {
    type bluealsa
    device "ANY"
    profile "a2dp"
}

ctl.!default {
    type hw
    card seeed2micvoicec
}
EOF
chown "${POMMAI_USER}:${POMMAI_USER}" "$ASOUNDRC_PATH"
echo -e "  ‚úì User ALSA configuration created"

# --- Step 9: Copy Application Files ---
echo -e "${GREEN}[9/12] Copying application files...${NC}"

# Copy all Python source files
if [ -d "./src" ]; then
    cp -r ./src/*.py "${POMMAI_APP_DIR}/"
    chown -R "${POMMAI_USER}:${POMMAI_USER}" "${POMMAI_APP_DIR}"
    echo -e "  ‚úì Application files copied"
else
    echo -e "  ‚ö† Source files not found in ./src/"
fi

# --- Step 10: Setup Systemd Service ---
echo -e "${GREEN}[10/12] Setting up systemd service...${NC}"

cat > /etc/systemd/system/pommai.service << 'EOF'
[Unit]
Description=Pommai Smart Toy Client
After=network-online.target sound.target bluetooth.target bluealsa.service
Wants=network-online.target
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=10
User=pommai
Group=pommai
WorkingDirectory=/home/pommai/app
Environment="PATH=/home/pommai/app/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Environment="PYTHONPATH=/home/pommai/app"
Environment="PULSE_RUNTIME_PATH=/run/user/1000/pulse"
ExecStartPre=/bin/sleep 10
ExecStart=/home/pommai/app/venv/bin/python /home/pommai/app/pommai_client_fastrtc.py

# Resource limits for Pi Zero 2W
MemoryMax=200M
CPUQuota=60%

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=pommai

# Security (relaxed for hardware access)
NoNewPrivileges=true
PrivateTmp=false
ProtectSystem=false
ProtectHome=false
ReadWritePaths=/home/pommai /tmp /var/log/pommai

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable pommai.service
echo -e "  ‚úì Pommai service created and enabled"

# --- Step 11: Create Configuration Template ---
echo -e "${GREEN}[11/12] Creating configuration template...${NC}"

ENV_FILE="${POMMAI_APP_DIR}/.env"
if [ ! -f "$ENV_FILE" ]; then
    cat > "$ENV_FILE" << 'EOF'
# Pommai Client Configuration

# FastRTC Gateway Connection
FASTRTC_GATEWAY_URL=ws://your-gateway-address:8080/ws

# Device Identification
DEVICE_ID=rpi-toy-001
TOY_ID=default-toy
AUTH_TOKEN=

# Audio Configuration
AUDIO_SEND_FORMAT=opus  # opus, pcm16, or wav
ENABLE_WAKE_WORD=false
ENABLE_OFFLINE_MODE=true

# Logging
LOG_LEVEL=INFO
EOF
    chown "${POMMAI_USER}:${POMMAI_USER}" "$ENV_FILE"
    chmod 600 "$ENV_FILE"
    echo -e "  ‚úì Configuration template created"
else
    echo -e "  ‚úì Configuration file already exists"
fi

# --- Step 12: Final System Configuration ---
echo -e "${GREEN}[12/12] Performing final system configuration...${NC}"

# Enable I2C and SPI kernel modules
if ! lsmod | grep -q "i2c_dev"; then
    modprobe i2c-dev
    echo "i2c-dev" >> /etc/modules
fi

if ! lsmod | grep -q "spidev"; then
    modprobe spidev
    echo "spidev" >> /etc/modules
fi

# Set up audio permissions
usermod -aG audio,bluetooth,dialout "$POMMAI_USER"

# Create test script
cat > "${POMMAI_APP_DIR}/test_audio.py" << 'EOF'
#!/usr/bin/env python3
"""Quick audio test script"""
import sys
sys.path.insert(0, '/home/pommai/app')
from audio_utils import get_audio_device_indices, test_audio_output, check_bluetooth_connection

# Check Bluetooth
bt_connected, bt_device = check_bluetooth_connection()
if bt_connected:
    print(f"‚úì Bluetooth device connected: {bt_device}")
else:
    print("‚úó No Bluetooth device connected")

# Find audio devices
devices = get_audio_device_indices()
print(f"‚úì Input device: {devices['input']}")
print(f"‚úì Output device: {devices['output']}")

# Test output
if devices['output'] is not None:
    print("Playing test tone...")
    test_audio_output(devices['output'], duration=1.0)
    print("Test complete!")
EOF
chmod +x "${POMMAI_APP_DIR}/test_audio.py"
chown "${POMMAI_USER}:${POMMAI_USER}" "${POMMAI_APP_DIR}/test_audio.py"

echo ""
echo -e "${GREEN}================================================${NC}"
echo -e "${GREEN}        SETUP COMPLETE!${NC}"
echo -e "${GREEN}================================================${NC}"
echo ""
echo -e "${YELLOW}IMPORTANT NEXT STEPS:${NC}"
echo ""
echo "1. Edit the configuration file:"
echo -e "   ${BLUE}sudo nano ${ENV_FILE}${NC}"
echo "   Set: FASTRTC_GATEWAY_URL, DEVICE_ID, TOY_ID"
echo ""
echo "2. Pair your Bluetooth speaker (if using):"
echo -e "   ${BLUE}sudo bluetoothctl${NC}"
echo "   Commands: scan on ‚Üí pair <MAC> ‚Üí trust <MAC> ‚Üí connect <MAC>"
echo ""
echo "3. Test audio configuration:"
echo -e "   ${BLUE}sudo -u pommai ${POMMAI_APP_DIR}/venv/bin/python ${POMMAI_APP_DIR}/test_audio.py${NC}"
echo ""
echo "4. Start the service:"
echo -e "   ${BLUE}sudo systemctl start pommai${NC}"
echo "   ${BLUE}sudo journalctl -u pommai -f${NC}  (to view logs)"
echo ""
echo "5. A system reboot is recommended for all changes to take effect."
echo ""
read -p "Reboot now? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "Rebooting in 5 seconds..."
    sleep 5
    reboot
fi
</file>

<file path="src/audio_stream_manager.py">
#!/usr/bin/env python3
"""
Audio Stream Manager for Pommai Raspberry Pi Client
Handles real-time audio capture, compression, streaming, and playback
"""

import asyncio
import collections
import logging
import time
import struct
from typing import Optional, AsyncGenerator, Callable, Dict, Any, List
from dataclasses import dataclass
from enum import Enum
import numpy as np

import pyaudio


class AudioState(Enum):
    """Audio streaming state machine"""
    IDLE = "idle"
    RECORDING = "recording"
    STREAMING = "streaming"
    PROCESSING = "processing"
    RECEIVING = "receiving"
    PLAYING = "playing"
    ERROR = "error"


@dataclass
class AudioConfig:
    """Audio configuration parameters"""
    sample_rate: int = 16000
    channels: int = 1
    format: int = pyaudio.paInt16
    chunk_size: int = 1024
    frame_size: int = 320  # 20ms at 16kHz
    
    # Buffer configuration
    recording_buffer_size: int = 50  # ~3 seconds
    playback_buffer_size: int = 10   # ~600ms
    min_playback_buffer: int = 3     # Start playback after 3 chunks
    
    # Network configuration
    frames_per_packet: int = 3       # 60ms per network packet
    network_chunk_size: int = 960    # 60ms of audio
    
    # Performance limits
    max_recording_buffer: int = 100  # ~6 seconds
    max_playback_buffer: int = 50    # ~3 seconds


class CircularAudioBuffer:
    """Thread-safe circular buffer for audio data"""
    
    def __init__(self, maxsize: int):
        self.buffer = collections.deque(maxlen=maxsize)
        self.lock = asyncio.Lock()
        
    async def add(self, chunk: bytes):
        """Add audio chunk to buffer"""
        async with self.lock:
            self.buffer.append(chunk)
    
    async def get(self) -> Optional[bytes]:
        """Get oldest chunk from buffer"""
        async with self.lock:
            return self.buffer.popleft() if self.buffer else None
    
    async def get_all(self) -> bytes:
        """Get all buffered audio as single bytes object"""
        async with self.lock:
            return b''.join(self.buffer)
    
    async def clear(self):
        """Clear buffer"""
        async with self.lock:
            self.buffer.clear()
    
    def __len__(self) -> int:
        return len(self.buffer)


class JitterBuffer:
    """Handle network jitter and packet reordering"""
    
    def __init__(self, target_delay_ms: int = 100):
        self.buffer: Dict[int, bytes] = {}
        self.target_delay = target_delay_ms
        self.next_sequence = 0
        self.max_buffer_size = 50
        
    def add_packet(self, sequence: int, data: bytes, timestamp: float):
        """Add packet to jitter buffer"""
        if len(self.buffer) < self.max_buffer_size:
            self.buffer[sequence] = (data, timestamp)
    
    def get_packet(self) -> Optional[bytes]:
        """Get next packet in sequence"""
        if self.next_sequence in self.buffer:
            data, timestamp = self.buffer.pop(self.next_sequence)
            self.next_sequence += 1
            
            # Check if we've met target delay
            current_time = time.time() * 1000
            packet_age = current_time - timestamp
            
            if packet_age >= self.target_delay:
                return data
            else:
                # Re-add packet if not old enough
                self.buffer[self.next_sequence - 1] = (data, timestamp)
                return None
        
        # Handle missing packet
        if self.buffer and min(self.buffer.keys()) > self.next_sequence:
            # Skip missing packet
            self.next_sequence = min(self.buffer.keys())
        
        return None


class AudioStreamManager:
    """Manages audio streaming between Pi and cloud"""
    
    def __init__(self, hardware_controller, config: AudioConfig):
        self.hardware = hardware_controller
        self.config = config
        self.state = AudioState.IDLE
        
        # Audio streams from hardware controller
        self.input_stream = hardware_controller.input_stream
        self.output_stream = hardware_controller.output_stream
        
        # Buffers
        self.recording_buffer = CircularAudioBuffer(config.recording_buffer_size)
        self.playback_buffer = CircularAudioBuffer(config.playback_buffer_size)
        self.jitter_buffer = JitterBuffer()
        
        # Control flags
        self.is_recording = False
        self.is_playing = False
        self.is_streaming = False
        
        # Callbacks
        self.on_audio_chunk: Optional[Callable] = None
        self.on_silence_detected: Optional[Callable] = None
        
        # Performance monitoring
        self.stats = {
            'chunks_recorded': 0,
            'chunks_played': 0,
            'underruns': 0,
            'overruns': 0,
            'average_latency': 0
        }
        
        # Silence detection
        self.silence_threshold = 500  # RMS threshold
        self.silence_duration = 0
        self.max_silence_duration = 2.0  # 2 seconds
        
        logging.info("Audio Stream Manager initialized")
    
    async def start_recording(self, streaming: bool = True) -> None:
        """Start audio recording from microphone"""
        if self.is_recording:
            logging.warning("Already recording")
            return
        
        self.is_recording = True
        self.is_streaming = streaming
        self.state = AudioState.RECORDING
        
        # Clear buffers
        await self.recording_buffer.clear()
        
        # Start recording task
        asyncio.create_task(self._recording_loop())
        
        logging.info("Started audio recording")
    
    async def stop_recording(self) -> bytes:
        """Stop recording and return all recorded audio"""
        self.is_recording = False
        self.is_streaming = False
        
        # Wait a bit for recording to finish
        await asyncio.sleep(0.1)
        
        # Get all recorded audio
        all_audio = await self.recording_buffer.get_all()
        
        self.state = AudioState.IDLE
        logging.info(f"Stopped recording. Total size: {len(all_audio)} bytes")
        
        return all_audio
    
    async def _recording_loop(self):
        """Main recording loop"""
        sequence = 0
        
        try:
            while self.is_recording:
                # Read audio chunk
                try:
                    audio_data = self.input_stream.read(
                        self.config.chunk_size,
                        exception_on_overflow=False
                    )
                except Exception as e:
                    if "overflow" in str(e).lower():
                        self.stats['overruns'] += 1
                        # Clear buffer and continue
                        available = self.input_stream.get_read_available()
                        if available > 0:
                            self.input_stream.read(available, exception_on_overflow=False)
                        continue
                    else:
                        logging.error(f"Recording error: {e}")
                        await asyncio.sleep(0.01)
                        continue
                
                # Add to buffer
                await self.recording_buffer.add(audio_data)
                self.stats['chunks_recorded'] += 1
                
                # Check for silence
                if self._is_silence(audio_data):
                    self.silence_duration += self.config.chunk_size / self.config.sample_rate
                    if self.silence_duration >= self.max_silence_duration:
                        if self.on_silence_detected:
                            await self.on_silence_detected()
                else:
                    self.silence_duration = 0
                
                # Stream if enabled
                if self.is_streaming and self.on_audio_chunk:
                    await self.on_audio_chunk(audio_data, sequence)
                    sequence += 1
                
                # Small yield to prevent blocking
                await asyncio.sleep(0)
                
        except Exception as e:
            logging.error(f"Recording loop error: {e}")
            self.state = AudioState.ERROR
        finally:
            self.is_recording = False
    
    def _is_silence(self, audio_data: bytes) -> bool:
        """Detect if audio chunk is silence"""
        # Convert to numpy array
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        
        # Calculate RMS (Root Mean Square)
        rms = np.sqrt(np.mean(audio_array ** 2))
        
        return rms < self.silence_threshold
    
    async def play_audio_stream(self, audio_chunks: AsyncGenerator[Dict[str, Any], None]):
        """Play incoming audio stream with buffering"""
        if self.is_playing:
            logging.warning("Already playing audio - resetting state")
            # Force reset the playing state in case it's stuck
            self.is_playing = False
            self.state = AudioState.IDLE
            await asyncio.sleep(0.1)  # Small delay to let any current playback finish
        
        self.is_playing = True
        self.state = AudioState.RECEIVING
        
        # Clear playback buffer
        await self.playback_buffer.clear()
        
        try:
            # Buffer chunks until minimum reached
            chunk_count = 0
            min_buffer_reached = False
            
            async for chunk in audio_chunks:
                if not self.is_playing:
                    break
                
                # Add to buffer
                audio_data = chunk.get('data', b'')
                if audio_data:
                    await self.playback_buffer.add(audio_data)
                    chunk_count += 1
                
                # Check if minimum buffer reached
                if not min_buffer_reached and chunk_count >= self.config.min_playback_buffer:
                    min_buffer_reached = True
                    self.state = AudioState.PLAYING
                    # Start playback task
                    asyncio.create_task(self._playback_loop())
                
                # Handle final chunk
                if chunk.get('is_final', False):
                    break
            
            # If we never reached minimum buffer, play what we have
            if not min_buffer_reached and chunk_count > 0:
                self.state = AudioState.PLAYING
                await self._playback_remaining()
            
        except Exception as e:
            logging.error(f"Audio stream error: {e}", exc_info=True)
            self.state = AudioState.ERROR
        finally:
            # Wait for playback to finish with timeout
            timeout_counter = 0
            while self.is_playing and len(self.playback_buffer) > 0 and timeout_counter < 50:  # 5 second timeout
                await asyncio.sleep(0.1)
                timeout_counter += 1
            
            if timeout_counter >= 50:
                logging.warning("Playback buffer timeout - forcing cleanup")
            
            # Always reset state
            self.is_playing = False
            self.state = AudioState.IDLE
    
    async def _playback_loop(self):
        """Main playback loop"""
        try:
            logging.info(f"PLAYBACK LOOP: Starting, output_stream={self.output_stream}")
            chunks_written = 0
            while self.is_playing:
                # Get audio from buffer
                audio_data = await self.playback_buffer.get()
                
                if audio_data:
                    # Play audio
                    try:
                        logging.debug(f"PLAYBACK: Writing chunk {chunks_written+1}, size={len(audio_data)} bytes")
                        self.output_stream.write(audio_data)
                        self.stats['chunks_played'] += 1
                        chunks_written += 1
                        if chunks_written == 1:
                            logging.info("PLAYBACK: First chunk successfully written to output stream")
                    except Exception as e:
                        if "underflow" in str(e).lower():
                            self.stats['underruns'] += 1
                            logging.warning(f"PLAYBACK: Buffer underflow, inserting silence")
                            # Insert small silence to recover
                            silence = b'\x00' * len(audio_data)
                            self.output_stream.write(silence)
                        else:
                            logging.error(f"PLAYBACK ERROR: Failed to write to output stream: {e}")
                            # Try to recover by clearing the buffer and continuing
                            try:
                                logging.info("PLAYBACK: Attempting to recover output stream...")
                                await self.playback_buffer.clear()
                                await asyncio.sleep(0.1)
                                # Set flag to stop playback
                                self.is_playing = False
                                break
                            except:
                                pass
                else:
                    # Buffer empty, wait a bit
                    await asyncio.sleep(0.01)
                    
                    # Check if we should stop
                    if not self.is_playing or (len(self.playback_buffer) == 0 and self.state != AudioState.RECEIVING):
                        break
                        
        except Exception as e:
            logging.error(f"Playback loop error: {e}", exc_info=True)
            self.state = AudioState.ERROR
        finally:
            # Ensure playback state is cleared
            self.is_playing = False
    
    async def _playback_remaining(self):
        """Play any remaining audio in buffer"""
        while len(self.playback_buffer) > 0:
            audio_data = await self.playback_buffer.get()
            if audio_data:
                try:
                    self.output_stream.write(audio_data)
                    self.stats['chunks_played'] += 1
                except Exception as e:
                    logging.error(f"Final playback error: {e}")
    
    async def play_audio_data(self, audio_data: bytes):
        """Play pre-loaded audio data"""
        if self.is_playing:
            logging.warning("Already playing audio")
            return
        
        self.is_playing = True
        self.state = AudioState.PLAYING
        
        try:
            # Split into chunks
            chunk_size = self.config.chunk_size * 2  # 16-bit samples
            chunks = [audio_data[i:i + chunk_size] for i in range(0, len(audio_data), chunk_size)]
            
            # Play chunks
            for chunk in chunks:
                if not self.is_playing:
                    break
                    
                try:
                    self.output_stream.write(chunk)
                    self.stats['chunks_played'] += 1
                except Exception as e:
                    logging.error(f"Playback error: {e}")
                
                # Small delay between chunks
                await asyncio.sleep(0)
                
        except Exception as e:
            logging.error(f"Audio playback error: {e}")
            self.state = AudioState.ERROR
        finally:
            self.is_playing = False
            self.state = AudioState.IDLE
    
    def stop_playback(self):
        """Stop audio playback"""
        self.is_playing = False
        logging.info("Stopped audio playback")
    
    def set_volume(self, volume: float):
        """Set output volume (0.0 to 1.0)"""
        # This would need ALSA mixer integration
        # For now, just log
        logging.info(f"Volume set to {volume * 100:.0f}%")
    
    def get_stats(self) -> Dict[str, Any]:
        """Get performance statistics"""
        return {
            **self.stats,
            'recording_buffer_size': len(self.recording_buffer),
            'playback_buffer_size': len(self.playback_buffer),
            'state': self.state.value
        }
    
    async def test_audio_levels(self, duration: float = 5.0):
        """Monitor audio input levels for testing"""
        logging.info(f"Testing audio levels for {duration} seconds...")
        
        start_time = time.time()
        max_level = 0
        
        while time.time() - start_time < duration:
            try:
                audio_data = self.input_stream.read(self.config.chunk_size, exception_on_overflow=False)
                audio_array = np.frombuffer(audio_data, dtype=np.int16)
                
                # Calculate RMS
                rms = np.sqrt(np.mean(audio_array ** 2))
                level = min(100, int(rms / 32768 * 200))
                
                if level > max_level:
                    max_level = level
                
                # Log every second
                if int(time.time() - start_time) % 1 == 0:
                    logging.info(f"Audio level: {level}% (Max: {max_level}%)")
                    
            except Exception as e:
                logging.error(f"Level test error: {e}")
                
            await asyncio.sleep(0.1)
        
        logging.info(f"Audio level test complete. Max level: {max_level}%")
        return max_level

    # Convenience helpers for client compatibility
    async def initialize(self) -> None:
        """No-op initializer for API compatibility."""
        return None

    async def read_chunk(self):
        """Read one input chunk and return as numpy int16 array."""
        try:
            data = self.input_stream.read(self.config.chunk_size, exception_on_overflow=False)
            return np.frombuffer(data, dtype=np.int16)
        except Exception as e:
            logging.error(f"read_chunk error: {e}")
            return None

    async def play_audio(self, pcm_bytes: bytes):
        """Play a single PCM buffer (bytes)."""
        try:
            await self.play_audio_data(pcm_bytes)
        except Exception as e:
            logging.error(f"play_audio error: {e}")

    async def cleanup(self) -> None:
        """Cleanup hook; streams are owned by hardware controller."""
        # Ensure playback loop is stopped
        self.is_playing = False
        return None
</file>

<file path="src/audio_utils.py">
#!/usr/bin/env python3
"""
Audio device detection utilities for Pommai Raspberry Pi client
Provides smart audio device selection with Bluetooth priority
"""

import pyaudio
import logging
import subprocess
from typing import Dict, Optional, Tuple

logger = logging.getLogger(__name__)

def get_audio_device_indices() -> Dict[str, Optional[int]]:
    """
    Find best audio devices with Bluetooth priority.
    Based on test results, Bluetooth is typically at index 2.
    
    Returns:
        Dict with 'input' and 'output' device indices
    """
    p = pyaudio.PyAudio()
    
    mic_index = None
    bt_speaker_index = None
    hat_speaker_index = None
    
    logger.info("Scanning for audio devices...")
    
    for i in range(p.get_device_count()):
        try:
            info = p.get_device_info_by_index(i)
            name = info.get('name', '').lower()
            channels_in = info.get('maxInputChannels', 0)
            channels_out = info.get('maxOutputChannels', 0)
            
            # Log device info for debugging
            if channels_in > 0 or channels_out > 0:
                logger.debug(f"Device {i}: {info['name']} (In:{channels_in}, Out:{channels_out})")
            
            # Find microphone (ReSpeaker or WM8960)
            if channels_in > 0:
                if any(keyword in name for keyword in ['seeed', 'respeaker', 'wm8960', 'capture']):
                    if mic_index is None:  # Take first matching input device
                        mic_index = i
                        logger.info(f"Found ReSpeaker Mic: index={i}, name='{info['name']}'")
            
            # Find speakers
            if channels_out > 0:
                # Check for Bluetooth device (based on test, it's at index 2)
                # BlueALSA devices typically show up as "bluealsa" or at specific indices
                if i == 2 or 'bluealsa' in name or 'bluetooth' in name:
                    bt_speaker_index = i
                    logger.info(f"Found Bluetooth Speaker: index={i}, name='{info['name']}'")
                # Check for ReSpeaker/WM8960 output
                elif any(keyword in name for keyword in ['seeed', 'respeaker', 'wm8960', 'playback']) or i == 0:
                    if hat_speaker_index is None:  # Take first matching output device
                        hat_speaker_index = i
                        logger.info(f"Found ReSpeaker Speaker: index={i}, name='{info['name']}'")
                    
        except Exception as e:
            logger.debug(f"Error checking device {i}: {e}")
            continue
    
    p.terminate()
    
    # Determine output device: prefer Bluetooth if available
    output_device = bt_speaker_index if bt_speaker_index is not None else hat_speaker_index
    
    # Log final selection
    if output_device is not None:
        device_type = 'Bluetooth' if output_device == bt_speaker_index else 'ReSpeaker HAT'
        logger.info(f"Selected Output: index={output_device} ({device_type})")
    else:
        logger.warning("No preferred output device found, will use system default")
    
    if mic_index is None:
        logger.warning("No ReSpeaker microphone found, will use system default")
    else:
        logger.info(f"Selected Input: index={mic_index}")
    
    return {
        "input": mic_index,
        "output": output_device
    }


def check_bluetooth_connection() -> Tuple[bool, Optional[str]]:
    """
    Check if a Bluetooth audio device is connected
    
    Returns:
        Tuple of (is_connected, device_name)
    """
    try:
        # Check BlueALSA for connected devices
        result = subprocess.run(
            ["bluetoothctl", "devices", "Connected"],
            capture_output=True,
            text=True,
            timeout=5
        )
        
        if result.returncode == 0 and result.stdout:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if line.strip():
                    # Parse device info
                    parts = line.split(' ', 2)
                    if len(parts) >= 3:
                        device_name = parts[2]
                        logger.info(f"Bluetooth device connected: {device_name}")
                        return True, device_name
        
        return False, None
        
    except Exception as e:
        logger.warning(f"Could not check Bluetooth status: {e}")
        return False, None


def convert_mp3_to_pcm(mp3_data: bytes, sample_rate: int = 16000) -> bytes:
    """
    Convert MP3 audio data to PCM16 format using ffmpeg
    
    Args:
        mp3_data: MP3 audio bytes
        sample_rate: Target sample rate (default 16000 Hz)
    
    Returns:
        PCM16 audio bytes
    """
    try:
        # Use ffmpeg to convert MP3 to PCM16
        process = subprocess.Popen(
            [
                'ffmpeg',
                '-i', 'pipe:0',  # Input from stdin
                '-f', 's16le',    # Output format: signed 16-bit little-endian
                '-ar', str(sample_rate),  # Sample rate
                '-ac', '1',       # Mono
                '-loglevel', 'error',
                'pipe:1'          # Output to stdout
            ],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        pcm_data, error = process.communicate(input=mp3_data)
        
        if process.returncode != 0:
            logger.error(f"ffmpeg conversion error: {error.decode()}")
            return b''
        
        return pcm_data
        
    except FileNotFoundError:
        logger.error("ffmpeg not found. Install with: sudo apt-get install ffmpeg")
        return b''
    except Exception as e:
        logger.error(f"MP3 to PCM conversion error: {e}")
        return b''


def test_audio_output(device_index: Optional[int] = None, duration: float = 1.0):
    """
    Test audio output with a beep sound
    
    Args:
        device_index: Output device index (None for default)
        duration: Duration of test sound in seconds
    """
    import numpy as np
    
    p = pyaudio.PyAudio()
    
    # Generate a 440Hz sine wave
    sample_rate = 16000
    frequency = 440
    samples = int(sample_rate * duration)
    t = np.linspace(0, duration, samples)
    audio_data = (np.sin(2 * np.pi * frequency * t) * 0.3 * 32767).astype(np.int16)
    
    try:
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=sample_rate,
            output=True,
            output_device_index=device_index,
            frames_per_buffer=1024
        )
        
        logger.info(f"Playing test tone on device {device_index}...")
        stream.write(audio_data.tobytes())
        
        stream.stop_stream()
        stream.close()
        
    except Exception as e:
        logger.error(f"Audio test failed: {e}")
    finally:
        p.terminate()


def ensure_bluealsa_running() -> bool:
    """
    Ensure BlueALSA service is running
    
    Returns:
        True if BlueALSA is running or was started successfully
    """
    try:
        # Check if bluealsa is running
        result = subprocess.run(
            ["systemctl", "is-active", "bluealsa"],
            capture_output=True,
            text=True
        )
        
        if result.stdout.strip() == "active":
            logger.info("BlueALSA service is running")
            return True
        
        # Try to start it
        logger.info("Starting BlueALSA service...")
        subprocess.run(["sudo", "systemctl", "start", "bluealsa"], check=False)
        
        # Check again
        result = subprocess.run(
            ["systemctl", "is-active", "bluealsa"],
            capture_output=True,
            text=True
        )
        
        if result.stdout.strip() == "active":
            logger.info("BlueALSA service started successfully")
            return True
        else:
            logger.warning("Failed to start BlueALSA service")
            return False
            
    except Exception as e:
        logger.warning(f"Could not check/start BlueALSA: {e}")
        return False
</file>

<file path="src/button_handler.py">
#!/usr/bin/env python3
"""
Button Handler for Pommai Raspberry Pi Client
- Proper GPIO setup (BCM mode + pull-up)
- Debounce, multi-press (single/double/triple), and long-press detection
- Thread-safe handoff from RPi.GPIO callback thread to asyncio event loop
"""

import asyncio
import time
import logging
from typing import Optional, Callable

try:
    import RPi.GPIO as GPIO
except Exception:
    # Minimal stub for non-Pi environments (unit tests, linting)
    class _GPIOStub:
        BCM = 'BCM'
        OUT = 'OUT'
        IN = 'IN'
        LOW = 0
        HIGH = 1
        BOTH = 'BOTH'
        PUD_UP = 'PUD_UP'
        def setmode(self, *args, **kwargs): pass
        def setwarnings(self, *args, **kwargs): pass
        def setup(self, *args, **kwargs): pass
        def add_event_detect(self, *args, **kwargs): pass
        def remove_event_detect(self, *args, **kwargs): pass
        def input(self, *args, **kwargs): return self.HIGH
        def cleanup(self, *args, **kwargs): pass
    GPIO = _GPIOStub()

LOGGER = logging.getLogger(__name__)

# Default BCM pin for button (matches your gpio-control.md)
DEFAULT_BUTTON_PIN = 17  # BCM 17


class ButtonHandler:
    """Advanced button handler with multiple interaction patterns."""

    def __init__(
        self,
        button_pin: int = DEFAULT_BUTTON_PIN,
        loop: Optional[asyncio.AbstractEventLoop] = None,
        debounce_time: float = 0.05,         # 50 ms
        long_press_threshold: float = 3.0,   # 3 seconds
        multi_press_window: float = 0.5      # 500 ms
    ):
        self.button_pin = int(button_pin)
        self.loop = loop or asyncio.get_event_loop()

        # State
        self.is_pressed = False
        self.press_start_time: Optional[float] = None
        self.last_edge_time = 0.0
        self.press_count = 0
        self.long_press_triggered = False

        # Timers (asyncio tasks)
        self._long_press_task: Optional[asyncio.Task] = None
        self._multi_press_task: Optional[asyncio.Task] = None
        self._poll_task: Optional[asyncio.Task] = None

        # Config
        self.debounce_time = float(debounce_time)
        self.long_press_threshold = float(long_press_threshold)
        self.multi_press_window = float(multi_press_window)

        # Callbacks (may be sync or async)
        self.on_press_callback: Optional[Callable] = None
        self.on_release_callback: Optional[Callable] = None
        self.on_single_press_callback: Optional[Callable] = None
        self.on_double_press_callback: Optional[Callable] = None
        self.on_triple_press_callback: Optional[Callable] = None
        self.on_long_press_callback: Optional[Callable] = None

        # GPIO setup: BCM mode, input with pull-up, then edge detect
        try:
            # Check if GPIO mode is already set
            current_mode = GPIO.getmode()
            if current_mode is None:
                GPIO.setmode(GPIO.BCM)
            elif current_mode != GPIO.BCM:
                LOGGER.warning("GPIO mode already set to %s, expected BCM", current_mode)
            
            GPIO.setwarnings(False)
            
            # Setup the button pin as input with pull-up
            GPIO.setup(self.button_pin, GPIO.IN, pull_up_down=GPIO.PUD_UP)
            LOGGER.debug("GPIO %d setup as input with pull-up", self.button_pin)
        except Exception as e:
            LOGGER.error("GPIO setup failed: %s", e)
            # Try to continue anyway in case it's already setup
            pass

        # Clear any stale detect before adding
        try:
            GPIO.remove_event_detect(self.button_pin)
        except Exception:
            pass

        try:
            GPIO.add_event_detect(
                self.button_pin,
                GPIO.BOTH,
                callback=self._gpio_callback,  # called in GPIO's own thread
                bouncetime=int(self.debounce_time * 1000)
            )
            LOGGER.info("Button handler initialized on GPIO %d (edge detect)", self.button_pin)
        except Exception as e:
            LOGGER.error("GPIO add_event_detect failed (using polling fallback): %s", e)
            # Start polling fallback
            self._poll_task = self.loop.create_task(self._poll_button_fallback())
            LOGGER.info("Button handler initialized on GPIO %d (polling fallback)", self.button_pin)

    def set_callbacks(
        self,
        on_press: Optional[Callable] = None,
        on_release: Optional[Callable] = None,
        on_single_press: Optional[Callable] = None,
        on_double_press: Optional[Callable] = None,
        on_triple_press: Optional[Callable] = None,
        on_long_press: Optional[Callable] = None,
    ):
        """Set callback functions for different button events (sync or async)."""
        self.on_press_callback = on_press
        self.on_release_callback = on_release
        self.on_single_press_callback = on_single_press
        self.on_double_press_callback = on_double_press
        self.on_triple_press_callback = on_triple_press
        self.on_long_press_callback = on_long_press

    # -------- GPIO callback (runs in RPi.GPIO thread) --------

    def _gpio_callback(self, channel):
        """Threaded GPIO interrupt callback; hand off to asyncio loop."""
        now = time.monotonic()

        # Software debounce
        if now - self.last_edge_time < self.debounce_time:
            return
        self.last_edge_time = now

        try:
            # With pull-up, LOW means pressed
            pressed = (GPIO.input(channel) == GPIO.LOW)
        except Exception:
            pressed = False

        # Hand off to main asyncio loop thread-safely
        self.loop.call_soon_threadsafe(self._schedule_edge, pressed, now)

    def _schedule_edge(self, pressed: bool, timestamp: float):
        """Runs in asyncio loop thread; schedules press/release handlers."""
        if pressed and not self.is_pressed:
            self.loop.create_task(self._handle_press(timestamp))
        elif not pressed and self.is_pressed:
            self.loop.create_task(self._handle_release(timestamp))

    # -------- Async handlers (run in asyncio loop) --------

    async def _handle_press(self, timestamp: float):
        self.is_pressed = True
        self.press_start_time = timestamp
        self.long_press_triggered = False
        LOGGER.debug("Button pressed")

        # Immediate callback
        if self.on_press_callback:
            await self._safe_callback(self.on_press_callback)

        # Start long-press timer
        self._cancel_task(self._long_press_task)
        self._long_press_task = self.loop.create_task(self._long_press_detector())

        # Count for multi-press
        self.press_count += 1

        # (Re)start multi-press window timer
        self._cancel_task(self._multi_press_task)
        self._multi_press_task = self.loop.create_task(self._multi_press_timeout())

    async def _handle_release(self, timestamp: float):
        self.is_pressed = False
        LOGGER.debug("Button released")

        # Stop long-press detector if still running
        self._cancel_task(self._long_press_task)

        # Compute press duration
        duration = 0.0
        if self.press_start_time is not None:
            duration = max(0.0, timestamp - self.press_start_time)

        # ALWAYS fire release callback to stop recording even after a long-press
        if self.on_release_callback:
            await self._safe_callback(self.on_release_callback, duration)

    async def _long_press_detector(self):
        try:
            await asyncio.sleep(self.long_press_threshold)
            if self.is_pressed:
                self.long_press_triggered = True
                # Reset multi-press counting if long-press fires
                self.press_count = 0
                self._cancel_task(self._multi_press_task)

                LOGGER.info("Long press detected")
                if self.on_long_press_callback:
                    await self._safe_callback(self.on_long_press_callback)
        except asyncio.CancelledError:
            pass

    async def _multi_press_timeout(self):
        try:
            await asyncio.sleep(self.multi_press_window)
            # Window ended; interpret presses
            count = self.press_count
            self.press_count = 0

            if count == 1:
                LOGGER.info("Single press detected")
                if self.on_single_press_callback:
                    await self._safe_callback(self.on_single_press_callback)
            elif count == 2:
                LOGGER.info("Double press detected")
                if self.on_double_press_callback:
                    await self._safe_callback(self.on_double_press_callback)
            elif count >= 3:
                LOGGER.info("Triple press detected (%d)", count)
                if self.on_triple_press_callback:
                    await self._safe_callback(self.on_triple_press_callback)
        except asyncio.CancelledError:
            pass

    # -------- Utils --------

    async def _poll_button_fallback(self, interval: float = 0.01):
        """Polling fallback to synthesize edges when kernel edge detect is unavailable."""
        last = None
        while True:
            try:
                pressed = (GPIO.input(self.button_pin) == GPIO.LOW)
            except Exception:
                await asyncio.sleep(0.1)
                continue
            now = time.monotonic()
            if last is None:
                last = pressed
            elif pressed != last:
                if now - self.last_edge_time >= self.debounce_time:
                    self.last_edge_time = now
                    self._schedule_edge(pressed, now)
                last = pressed
            await asyncio.sleep(interval)

    def _cancel_task(self, task: Optional[asyncio.Task]):
        if task and not task.done():
            task.cancel()

    async def _safe_callback(self, callback: Callable, *args):
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(*args)
            else:
                try:
                    callback(*args)
                except TypeError:
                    # Fallback: some callbacks may not accept duration param
                    callback()
        except Exception as e:
            LOGGER.error("Button callback error: %s", e)

    def cleanup(self):
        """Cleanup GPIO resources and cancel timers."""
        try:
            GPIO.remove_event_detect(self.button_pin)
        except Exception:
            pass
        self._cancel_task(self._long_press_task)
        self._cancel_task(self._multi_press_task)
        self._cancel_task(self._poll_task)


class ButtonPatternDetector:
    """Optional: detect press-sequence patterns (e.g., 'SSL', 'DL', etc.)."""

    def __init__(self, button_handler: ButtonHandler):
        self.button_handler = button_handler
        self.sequence = []
        self.sequence_timeout = 2.0  # seconds
        self._sequence_task: Optional[asyncio.Task] = None
        self.patterns: dict[str, Callable] = {}

        # Wrap existing callbacks to collect sequence
        orig_single = button_handler.on_single_press_callback
        orig_double = button_handler.on_double_press_callback
        orig_triple = button_handler.on_triple_press_callback
        orig_long = button_handler.on_long_press_callback

        async def single_wrapper():
            self._add('S')
            if orig_single:
                await self._maybe_await(orig_single)

        async def double_wrapper():
            self._add('D')
            if orig_double:
                await self._maybe_await(orig_double)

        async def triple_wrapper():
            self._add('T')
            if orig_triple:
                await self._maybe_await(orig_triple)

        async def long_wrapper():
            self._add('L')
            if orig_long:
                await self._maybe_await(orig_long)

        button_handler.on_single_press_callback = single_wrapper
        button_handler.on_double_press_callback = double_wrapper
        button_handler.on_triple_press_callback = triple_wrapper
        button_handler.on_long_press_callback = long_wrapper

    def register_pattern(self, pattern: str, callback: Callable):
        """
        Pattern symbols:
        - S: Single press
        - D: Double press
        - T: Triple press
        - L: Long press
        Example: "SSL" = Single, Single, Long
        """
        self.patterns[pattern] = callback
        LOGGER.info("Registered button pattern: %s", pattern)

    def _add(self, sym: str):
        self.sequence.append(sym)
        # Restart timeout
        if self._sequence_task and not self._sequence_task.done():
            self._sequence_task.cancel()
        self._sequence_task = asyncio.create_task(self._sequence_timeout())

        current = ''.join(self.sequence)
        for pattern, cb in self.patterns.items():
            if current.endswith(pattern):
                LOGGER.info("Pattern detected: %s", pattern)
                asyncio.create_task(self._maybe_await(cb))
                self.sequence.clear()
                if self._sequence_task and not self._sequence_task.done():
                    self._sequence_task.cancel()
                break

    async def _sequence_timeout(self):
        try:
            await asyncio.sleep(self.sequence_timeout)
            self.sequence.clear()
        except asyncio.CancelledError:
            pass

    async def _maybe_await(self, cb: Callable):
        try:
            if asyncio.iscoroutinefunction(cb):
                await cb()
            else:
                cb()
        except Exception as e:
            LOGGER.error("Pattern callback error: %s", e)
</file>

<file path="src/configure_bluetooth_audio.py">
#!/usr/bin/env python3
"""
Configure and test Bluetooth audio output for Pommai client
This script helps identify and configure the correct audio device for Bluetooth speakers
"""

import pyaudio
import numpy as np
import wave
import sys
import os
import time
import subprocess
from typing import Optional, List, Dict, Any

def run_command(cmd: str) -> str:
    """Run a shell command and return output"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.stdout.strip()
    except Exception as e:
        return f"Error: {e}"

def get_bluetooth_devices() -> List[str]:
    """Get list of connected Bluetooth devices"""
    devices = []
    output = run_command("bluetoothctl devices Connected")
    if output and "Error" not in output:
        for line in output.split('\n'):
            if line.strip():
                devices.append(line.strip())
    return devices

def list_audio_devices() -> Dict[int, Dict[str, Any]]:
    """List all available audio devices"""
    p = pyaudio.PyAudio()
    devices = {}
    
    print("\n=== Available Audio Devices ===\n")
    
    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        
        # Only show output devices
        if info['maxOutputChannels'] > 0:
            devices[i] = info
            
            # Check if it might be a Bluetooth device
            is_bluetooth = any(bt_keyword in info['name'].lower() 
                             for bt_keyword in ['bluetooth', 'bluez', 'bluealsa', 'a2dp'])
            
            print(f"Device {i}: {info['name']}")
            print(f"  Channels: {info['maxOutputChannels']}")
            print(f"  Sample Rate: {info['defaultSampleRate']} Hz")
            print(f"  Host API: {p.get_host_api_info_by_index(info['hostApi'])['name']}")
            if is_bluetooth:
                print("  *** Likely Bluetooth device ***")
            print()
    
    p.terminate()
    return devices

def test_audio_device(device_index: Optional[int] = None, duration: float = 2.0):
    """Test audio output on specified device"""
    p = pyaudio.PyAudio()
    
    # Audio parameters
    sample_rate = 16000
    channels = 1
    format = pyaudio.paInt16
    
    # Generate test tone (440 Hz)
    frequency = 440
    t = np.linspace(0, duration, int(sample_rate * duration))
    audio_data = (np.sin(frequency * 2 * np.pi * t) * 0.3 * 32767).astype(np.int16)
    
    try:
        if device_index is not None:
            device_info = p.get_device_info_by_index(device_index)
            print(f"\nTesting device {device_index}: {device_info['name']}")
        else:
            print("\nTesting default output device")
        
        # Open stream
        stream = p.open(
            format=format,
            channels=channels,
            rate=sample_rate,
            output=True,
            output_device_index=device_index,
            frames_per_buffer=1024
        )
        
        print(f"Playing {frequency}Hz test tone for {duration} seconds...")
        
        # Play audio
        stream.write(audio_data.tobytes())
        
        # Close stream
        stream.stop_stream()
        stream.close()
        
        print("Test complete!")
        return True
        
    except Exception as e:
        print(f"Error testing device: {e}")
        return False
    
    finally:
        p.terminate()

def find_bluetooth_device() -> Optional[int]:
    """Try to automatically find the Bluetooth audio device"""
    p = pyaudio.PyAudio()
    
    bluetooth_keywords = ['bluetooth', 'bluez', 'bluealsa', 'a2dp', 'pulse']
    
    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        
        # Check if output device
        if info['maxOutputChannels'] > 0:
            # Check if name contains Bluetooth keywords
            if any(keyword in info['name'].lower() for keyword in bluetooth_keywords):
                print(f"\nFound potential Bluetooth device: {info['name']} (index {i})")
                p.terminate()
                return i
    
    p.terminate()
    return None

def create_alsa_config(device_name: str = "bluealsa"):
    """Create ALSA configuration for Bluetooth audio"""
    config = f"""# ALSA configuration for Bluetooth audio
# Generated by configure_bluetooth_audio.py

pcm.!default {{
    type plug
    slave.pcm "{device_name}"
}}

ctl.!default {{
    type hw
    card 0
}}

# If using BlueALSA
pcm.bluealsa {{
    type bluealsa
    device "XX:XX:XX:XX:XX:XX"  # Replace with your Bluetooth device MAC
    profile "a2dp"
}}
"""
    
    config_path = os.path.expanduser("~/.asoundrc")
    print(f"\nALSA configuration to write to {config_path}:")
    print(config)
    
    response = input("\nDo you want to write this configuration? (y/n): ")
    if response.lower() == 'y':
        with open(config_path, 'w') as f:
            f.write(config)
        print(f"Configuration written to {config_path}")
        print("Note: Replace XX:XX:XX:XX:XX:XX with your Bluetooth device MAC address")

def configure_pulseaudio_bluetooth():
    """Configure PulseAudio for Bluetooth"""
    print("\n=== Configuring PulseAudio for Bluetooth ===\n")
    
    # Check if PulseAudio is running
    pa_status = run_command("pactl info 2>/dev/null | grep 'Server Name'")
    if not pa_status:
        print("PulseAudio is not running. Starting...")
        run_command("pulseaudio --start")
        time.sleep(2)
    
    # Load Bluetooth modules
    print("Loading Bluetooth modules...")
    run_command("pactl load-module module-bluetooth-policy 2>/dev/null")
    run_command("pactl load-module module-bluetooth-discover 2>/dev/null")
    
    # List sinks
    print("\nAvailable audio sinks:")
    sinks = run_command("pactl list short sinks")
    print(sinks)
    
    # Find Bluetooth sink
    bluetooth_sink = None
    for line in sinks.split('\n'):
        if 'bluez' in line.lower():
            bluetooth_sink = line.split()[1]
            break
    
    if bluetooth_sink:
        print(f"\nFound Bluetooth sink: {bluetooth_sink}")
        print(f"Setting as default...")
        run_command(f"pactl set-default-sink {bluetooth_sink}")
        print("Done!")
    else:
        print("\nNo Bluetooth sink found. Make sure your Bluetooth device is connected.")

def update_pommai_config(device_index: int):
    """Update Pommai client configuration to use specific audio device"""
    config_file = "audio_device_config.py"
    
    config_content = f"""# Audio device configuration for Pommai client
# Generated by configure_bluetooth_audio.py

AUDIO_OUTPUT_DEVICE_INDEX = {device_index}
AUDIO_INPUT_DEVICE_INDEX = None  # Use default microphone

# To use this in pommai_client_fastrtc.py, modify the HardwareController initialization:
# self.hardware = HardwareController(
#     sample_rate=config.SAMPLE_RATE,
#     channels=config.CHANNELS,
#     chunk_size=config.CHUNK_SIZE,
#     input_device_index=AUDIO_INPUT_DEVICE_INDEX,
#     output_device_index=AUDIO_OUTPUT_DEVICE_INDEX
# )
"""
    
    print(f"\n=== Configuration to add to Pommai client ===")
    print(config_content)
    
    # Save to file
    with open(config_file, 'w') as f:
        f.write(config_content)
    print(f"\nConfiguration saved to {config_file}")
    
    # Also show how to update the main client
    print("\nTo apply this configuration, update pommai_client_fastrtc.py:")
    print("1. Import the configuration at the top:")
    print("   from audio_device_config import AUDIO_OUTPUT_DEVICE_INDEX, AUDIO_INPUT_DEVICE_INDEX")
    print("\n2. Update the HardwareController initialization (around line 189):")
    print("   output_device_index=AUDIO_OUTPUT_DEVICE_INDEX")

def main():
    print("=" * 50)
    print("Pommai Bluetooth Audio Configuration Tool")
    print("=" * 50)
    
    # Check Bluetooth devices
    print("\n=== Bluetooth Devices ===")
    bt_devices = get_bluetooth_devices()
    if bt_devices:
        print("Connected Bluetooth devices:")
        for device in bt_devices:
            print(f"  - {device}")
    else:
        print("No Bluetooth devices connected")
        print("Please connect your Bluetooth speaker first:")
        print("  bluetoothctl")
        print("  > power on")
        print("  > scan on")
        print("  > pair XX:XX:XX:XX:XX:XX")
        print("  > connect XX:XX:XX:XX:XX:XX")
        sys.exit(1)
    
    # List audio devices
    devices = list_audio_devices()
    
    if not devices:
        print("No output audio devices found!")
        sys.exit(1)
    
    # Try to find Bluetooth device automatically
    bt_device_index = find_bluetooth_device()
    
    if bt_device_index is not None:
        print(f"\nAutomatically detected Bluetooth device at index {bt_device_index}")
        response = input("Do you want to test this device? (y/n): ")
        if response.lower() == 'y':
            if test_audio_device(bt_device_index):
                response = input("\nDid you hear the test tone? (y/n): ")
                if response.lower() == 'y':
                    print("\nGreat! Bluetooth audio is working.")
                    update_pommai_config(bt_device_index)
                else:
                    print("\nAudio test failed. Trying other configurations...")
    
    # Manual device selection
    print("\n=== Manual Device Selection ===")
    print("Enter device index to test, or 'q' to quit:")
    
    while True:
        choice = input("\nDevice index (or 'q'): ").strip()
        
        if choice.lower() == 'q':
            break
        
        try:
            device_index = int(choice)
            if device_index in devices:
                if test_audio_device(device_index):
                    response = input("\nDid you hear the test tone? (y/n): ")
                    if response.lower() == 'y':
                        print("\nExcellent! This device works.")
                        update_pommai_config(device_index)
                        break
            else:
                print("Invalid device index")
        except ValueError:
            print("Please enter a valid number or 'q'")
    
    # Additional configuration options
    print("\n=== Additional Configuration Options ===")
    print("1. Configure PulseAudio for Bluetooth")
    print("2. Create ALSA configuration")
    print("3. Exit")
    
    choice = input("\nChoice (1-3): ").strip()
    
    if choice == '1':
        configure_pulseaudio_bluetooth()
    elif choice == '2':
        create_alsa_config()
    
    print("\n=== Configuration Complete ===")
    print("\nIf audio is still not working:")
    print("1. Make sure Bluetooth speaker is in A2DP mode (not HSP/HFP)")
    print("2. Check system volume is not muted")
    print("3. Restart the Pommai client with updated configuration")
    print("4. Check logs for any PyAudio errors")

if __name__ == "__main__":
    main()
</file>

<file path="src/conversation_cache.py">
#!/usr/bin/env python3
"""
SQLite Conversation Cache Module for Pommai Smart Toy
Implements local caching for offline functionality, conversation history, and sync
"""

import asyncio
import sqlite3
import json
import logging
import os
import time
import hashlib
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import aiofiles
import aiosqlite

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SyncStatus(Enum):
    """Sync status for cached data"""
    PENDING = "pending"
    SYNCING = "syncing"
    SYNCED = "synced"
    FAILED = "failed"


class DataType(Enum):
    """Types of data stored in cache"""
    CONVERSATION = "conversation"
    SAFETY_EVENT = "safety_event"
    USAGE_METRIC = "usage_metric"
    ERROR_LOG = "error_log"
    TOY_CONFIG = "toy_config"


@dataclass
class CacheConfig:
    """Configuration for conversation cache"""
    # Use tmpfs for performance as recommended in docs
    db_path: str = "/tmp/pommai_cache.db"
    backup_path: str = "/opt/pommai/cache/backup.db"
    
    # Cache limits
    max_conversations: int = 1000
    max_cached_responses: int = 100
    conversation_retention_days: int = 30
    
    # Sync settings
    sync_interval_seconds: int = 300  # 5 minutes
    sync_batch_size: int = 50
    max_sync_retries: int = 3
    
    # Performance settings
    enable_wal_mode: bool = True  # Write-Ahead Logging for concurrency
    cache_size_kb: int = 2000  # 2MB cache
    busy_timeout_ms: int = 5000  # 5 second timeout


class ConversationCache:
    """SQLite-based conversation cache with offline support"""
    
    def __init__(self, config: Optional[CacheConfig] = None):
        self.config = config or CacheConfig()
        self.db_path = self.config.db_path
        self._ensure_directories()
        self._init_sync = True
        
    def _ensure_directories(self):
        """Ensure cache directories exist"""
        os.makedirs(os.path.dirname(self.config.db_path), exist_ok=True)
        os.makedirs(os.path.dirname(self.config.backup_path), exist_ok=True)
        
    async def initialize(self):
        """Initialize database with async support"""
        await self._init_database()
        await self._preload_offline_responses()
        logger.info(f"Conversation cache initialized at {self.db_path}")
        
    async def _init_database(self):
        """Initialize SQLite database schema"""
        async with aiosqlite.connect(self.db_path) as db:
            # Enable WAL mode for better concurrency
            if self.config.enable_wal_mode:
                await db.execute("PRAGMA journal_mode=WAL")
            
            # Set cache size
            await db.execute(f"PRAGMA cache_size=-{self.config.cache_size_kb}")
            
            # Set busy timeout
            await db.execute(f"PRAGMA busy_timeout={self.config.busy_timeout_ms}")
            
            # Conversations table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS conversations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    conversation_id TEXT UNIQUE,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    user_input TEXT,
                    toy_response TEXT,
                    toy_id TEXT,
                    was_offline BOOLEAN DEFAULT 0,
                    is_safe BOOLEAN DEFAULT 1,
                    audio_path TEXT,
                    duration_seconds REAL,
                    sync_status TEXT DEFAULT 'pending',
                    sync_attempts INTEGER DEFAULT 0,
                    sync_error TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Cached responses for offline mode
            await db.execute('''
                CREATE TABLE IF NOT EXISTS cached_responses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    command TEXT UNIQUE,
                    response_text TEXT,
                    response_audio BLOB,
                    audio_path TEXT,
                    usage_count INTEGER DEFAULT 0,
                    last_used DATETIME,
                    popularity_score REAL DEFAULT 0.0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Toy configurations cache
            await db.execute('''
                CREATE TABLE IF NOT EXISTS toy_configurations (
                    toy_id TEXT PRIMARY KEY,
                    name TEXT,
                    personality_prompt TEXT,
                    voice_settings TEXT,
                    is_for_kids BOOLEAN DEFAULT 0,
                    safety_level TEXT,
                    knowledge_base TEXT,
                    wake_word TEXT,
                    custom_responses TEXT,
                    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
                    sync_status TEXT DEFAULT 'synced'
                )
            ''')
            
            # Usage metrics table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS usage_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    metric_type TEXT,
                    metric_value REAL,
                    toy_id TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    sync_status TEXT DEFAULT 'pending',
                    sync_attempts INTEGER DEFAULT 0,
                    metadata TEXT
                )
            ''')
            
            # Add missing columns to existing tables (migration)
            try:
                await db.execute('ALTER TABLE usage_metrics ADD COLUMN sync_attempts INTEGER DEFAULT 0')
                await db.commit()
                logger.info("Added sync_attempts column to usage_metrics table")
            except Exception:
                # Column already exists, ignore
                pass
            
            # Safety events table
            await db.execute('''
                CREATE TABLE IF NOT EXISTS safety_events (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    event_type TEXT,
                    severity TEXT,
                    content TEXT,
                    toy_id TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    is_urgent BOOLEAN DEFAULT 0,
                    parent_notified BOOLEAN DEFAULT 0,
                    sync_status TEXT DEFAULT 'pending',
                    details TEXT
                )
            ''')
            
            # Offline sync queue
            await db.execute('''
                CREATE TABLE IF NOT EXISTS offline_queue (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    data_type TEXT NOT NULL,
                    payload TEXT NOT NULL,
                    priority INTEGER DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    sync_status TEXT DEFAULT 'pending',
                    sync_attempts INTEGER DEFAULT 0,
                    last_attempt DATETIME,
                    error_message TEXT
                )
            ''')
            
            # Create indexes for performance
            await db.execute('CREATE INDEX IF NOT EXISTS idx_conversations_sync ON conversations(sync_status)')
            await db.execute('CREATE INDEX IF NOT EXISTS idx_conversations_timestamp ON conversations(timestamp)')
            await db.execute('CREATE INDEX IF NOT EXISTS idx_cached_responses_command ON cached_responses(command)')
            await db.execute('CREATE INDEX IF NOT EXISTS idx_offline_queue_status ON offline_queue(sync_status, priority)')
            
            await db.commit()
    
    async def _preload_offline_responses(self):
        """Preload default offline responses"""
        default_responses = [
            {
                'command': 'greeting',
                'text': "Hi there! I'm so happy to talk with you!",
                'audio_path': 'responses/greeting.opus'
            },
            {
                'command': 'sing_song',
                'text': "üéµ Twinkle twinkle little star... üéµ",
                'audio_path': 'responses/twinkle_star.opus'
            },
            {
                'command': 'tell_joke',
                'text': "Why did the teddy bear say no to dessert? Because she was stuffed!",
                'audio_path': 'responses/joke_1.opus'
            },
            {
                'command': 'goodnight',
                'text': "Sweet dreams, my friend! Sleep tight!",
                'audio_path': 'responses/goodnight.opus'
            },
            {
                'command': 'love_response',
                'text': "I love you too, buddy! You're the best!",
                'audio_path': 'responses/love_you.opus'
            },
            {
                'command': 'need_help',
                'text': "Let's find a grown-up to help you!",
                'audio_path': 'responses/find_help.opus'
            },
            {
                'command': 'play_offline',
                'text': "I need internet to play games, but we can sing songs!",
                'audio_path': 'responses/play_offline.opus'
            }
        ]
        
        async with aiosqlite.connect(self.db_path) as db:
            for response in default_responses:
                # Load audio file if exists
                audio_data = None
                if response['audio_path'] and os.path.exists(f"/opt/pommai/audio/{response['audio_path']}"):
                    try:
                        async with aiofiles.open(f"/opt/pommai/audio/{response['audio_path']}", 'rb') as f:
                            audio_data = await f.read()
                    except Exception as e:
                        logger.warning(f"Could not load audio file {response['audio_path']}: {e}")
                
                await db.execute('''
                    INSERT OR REPLACE INTO cached_responses 
                    (command, response_text, response_audio, audio_path) 
                    VALUES (?, ?, ?, ?)
                ''', (response['command'], response['text'], audio_data, response['audio_path']))
            
            await db.commit()
    
    async def save_conversation(self, 
                              user_input: str,
                              toy_response: str,
                              toy_id: str,
                              was_offline: bool = False,
                              is_safe: bool = True,
                              audio_path: Optional[str] = None,
                              duration_seconds: Optional[float] = None) -> str:
        """
        Save conversation to cache
        
        Returns:
            Conversation ID
        """
        conversation_id = f"{toy_id}_{int(time.time() * 1000)}"
        
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO conversations 
                (conversation_id, user_input, toy_response, toy_id, 
                 was_offline, is_safe, audio_path, duration_seconds)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (conversation_id, user_input, toy_response, toy_id, 
                  was_offline, is_safe, audio_path, duration_seconds))
            
            await db.commit()
            
            # Log metrics
            await self.log_metric('conversation_count', 1, toy_id)
            if was_offline:
                await self.log_metric('offline_conversation_count', 1, toy_id)
        
        # Queue for sync if online conversation
        if not was_offline:
            await self.queue_for_sync(DataType.CONVERSATION, {
                'conversation_id': conversation_id,
                'user_input': user_input,
                'toy_response': toy_response,
                'toy_id': toy_id,
                'timestamp': datetime.utcnow().isoformat()
            })
        
        return conversation_id
    
    async def get_offline_response(self, command: str) -> Optional[Dict[str, Any]]:
        """Get cached response for offline mode"""
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute('''
                SELECT response_text, response_audio, audio_path 
                FROM cached_responses 
                WHERE command = ?
            ''', (command,))
            
            result = await cursor.fetchone()
            
            if result:
                # Update usage stats
                await db.execute('''
                    UPDATE cached_responses 
                    SET usage_count = usage_count + 1, 
                        last_used = CURRENT_TIMESTAMP,
                        popularity_score = popularity_score + 1.0
                    WHERE command = ?
                ''', (command,))
                await db.commit()
                
                return {
                    'text': result[0],
                    'audio': result[1],
                    'audio_path': result[2]
                }
        
        return None
    
    async def cache_popular_response(self, 
                                   user_input: str,
                                   response_text: str,
                                   response_audio: Optional[bytes] = None,
                                   audio_path: Optional[str] = None):
        """Cache frequently used responses for offline access"""
        async with aiosqlite.connect(self.db_path) as db:
            # Check if this input appears frequently
            cursor = await db.execute('''
                SELECT COUNT(*) FROM conversations 
                WHERE user_input LIKE ? 
                AND timestamp > datetime('now', '-7 days')
            ''', (f'%{user_input}%',))
            
            count = (await cursor.fetchone())[0]
            
            if count > 5:  # If asked more than 5 times in a week
                # Generate a command key
                command_key = f"cached_{hashlib.md5(user_input.encode()).hexdigest()[:8]}"
                
                await db.execute('''
                    INSERT OR REPLACE INTO cached_responses 
                    (command, response_text, response_audio, audio_path, popularity_score) 
                    VALUES (?, ?, ?, ?, ?)
                ''', (command_key, response_text, response_audio, audio_path, count))
                
                await db.commit()
                
                logger.info(f"Cached popular response: {command_key}")
    
    async def save_toy_configuration(self, toy_config: Dict[str, Any]):
        """Save toy configuration to cache"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT OR REPLACE INTO toy_configurations 
                (toy_id, name, personality_prompt, voice_settings, 
                 is_for_kids, safety_level, knowledge_base, wake_word, custom_responses)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                toy_config['toy_id'],
                toy_config.get('name', 'Pommai'),
                toy_config.get('personality_prompt', ''),
                json.dumps(toy_config.get('voice_settings', {})),
                toy_config.get('is_for_kids', True),
                toy_config.get('safety_level', 'strict'),
                json.dumps(toy_config.get('knowledge_base', [])),
                toy_config.get('wake_word', 'hey pommai'),
                json.dumps(toy_config.get('custom_responses', {}))
            ))
            
            await db.commit()
    
    async def get_toy_configuration(self, toy_id: str) -> Optional[Dict[str, Any]]:
        """Get cached toy configuration"""
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute('''
                SELECT name, personality_prompt, voice_settings, 
                       is_for_kids, safety_level, knowledge_base, 
                       wake_word, custom_responses, last_updated
                FROM toy_configurations 
                WHERE toy_id = ?
            ''', (toy_id,))
            
            result = await cursor.fetchone()
            
            if result:
                return {
                    'toy_id': toy_id,
                    'name': result[0],
                    'personality_prompt': result[1],
                    'voice_settings': json.loads(result[2]),
                    'is_for_kids': bool(result[3]),
                    'safety_level': result[4],
                    'knowledge_base': json.loads(result[5]),
                    'wake_word': result[6],
                    'custom_responses': json.loads(result[7]),
                    'last_updated': result[8]
                }
        
        return None
    
    async def log_safety_event(self,
                             event_type: str,
                             severity: str,
                             content: str,
                             toy_id: str,
                             is_urgent: bool = False,
                             details: Optional[Dict] = None):
        """Log safety event for parent review"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO safety_events 
                (event_type, severity, content, toy_id, is_urgent, details)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (event_type, severity, content, toy_id, is_urgent, 
                  json.dumps(details or {})))
            
            await db.commit()
        
        # Queue for immediate sync if urgent
        priority = 10 if is_urgent else 5
        await self.queue_for_sync(DataType.SAFETY_EVENT, {
            'event_type': event_type,
            'severity': severity,
            'content': content,
            'toy_id': toy_id,
            'is_urgent': is_urgent,
            'details': details,
            'timestamp': datetime.utcnow().isoformat()
        }, priority=priority)
    
    async def log_metric(self, 
                        metric_type: str,
                        value: float,
                        toy_id: str,
                        metadata: Optional[Dict] = None):
        """Log usage metric"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO usage_metrics 
                (metric_type, metric_value, toy_id, metadata)
                VALUES (?, ?, ?, ?)
            ''', (metric_type, value, toy_id, json.dumps(metadata or {})))
            
            await db.commit()
    
    async def queue_for_sync(self, 
                           data_type: DataType,
                           payload: Dict[str, Any],
                           priority: int = 0):
        """Queue data for offline sync"""
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute('''
                INSERT INTO offline_queue 
                (data_type, payload, priority)
                VALUES (?, ?, ?)
            ''', (data_type.value, json.dumps(payload), priority))
            
            await db.commit()
    
    async def get_unsynced_items(self, 
                                limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """Get items pending sync"""
        limit = limit or self.config.sync_batch_size
        
        async with aiosqlite.connect(self.db_path) as db:
            # Get conversations
            cursor = await db.execute('''
                SELECT conversation_id, user_input, toy_response, 
                       toy_id, timestamp, audio_path
                FROM conversations 
                WHERE sync_status = 'pending' 
                AND sync_attempts < ?
                ORDER BY timestamp 
                LIMIT ?
            ''', (self.config.max_sync_retries, limit))
            
            conversations = []
            async for row in cursor:
                conversations.append({
                    'type': DataType.CONVERSATION.value,
                    'data': {
                        'conversation_id': row[0],
                        'user_input': row[1],
                        'toy_response': row[2],
                        'toy_id': row[3],
                        'timestamp': row[4],
                        'audio_path': row[5]
                    }
                })
            
            # Get offline queue items
            cursor = await db.execute('''
                SELECT id, data_type, payload, priority
                FROM offline_queue 
                WHERE sync_status = 'pending' 
                AND sync_attempts < ?
                ORDER BY priority DESC, created_at 
                LIMIT ?
            ''', (self.config.max_sync_retries, limit - len(conversations)))
            
            queue_items = []
            async for row in cursor:
                queue_items.append({
                    'id': row[0],
                    'type': row[1],
                    'data': json.loads(row[2]),
                    'priority': row[3]
                })
            
            return conversations + queue_items
    
    async def mark_synced(self, items: List[Dict[str, Any]]):
        """Mark items as successfully synced"""
        async with aiosqlite.connect(self.db_path) as db:
            for item in items:
                if item['type'] == DataType.CONVERSATION.value:
                    await db.execute('''
                        UPDATE conversations 
                        SET sync_status = 'synced' 
                        WHERE conversation_id = ?
                    ''', (item['data']['conversation_id'],))
                else:
                    await db.execute('''
                        UPDATE offline_queue 
                        SET sync_status = 'synced' 
                        WHERE id = ?
                    ''', (item['id'],))
            
            await db.commit()

    async def get_unsynced_metrics(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """Fetch unsynced usage metrics up to limit."""
        limit = limit or self.config.sync_batch_size
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute('''
                SELECT id, metric_type, metric_value, toy_id, timestamp, metadata
                FROM usage_metrics
                WHERE sync_status = 'pending'
                AND sync_attempts < ?
                ORDER BY timestamp
                LIMIT ?
            ''', (self.config.max_sync_retries, limit))
            results = []
            async for row in cursor:
                results.append({
                    'id': row[0],
                    'metric_type': row[1],
                    'metric_value': row[2],
                    'toy_id': row[3],
                    'timestamp': row[4],
                    'metadata': row[5]
                })
            return results

    async def mark_metrics_synced(self, metric_ids: List[int]):
        """Mark usage metrics as synced."""
        if not metric_ids:
            return
        async with aiosqlite.connect(self.db_path) as db:
            await db.executemany('''
                UPDATE usage_metrics SET sync_status = 'synced' WHERE id = ?
            ''', [(mid,) for mid in metric_ids])
            await db.commit()
    
    async def mark_sync_failed(self, items: List[Dict[str, Any]], error: str):
        """Mark items as failed sync with error"""
        async with aiosqlite.connect(self.db_path) as db:
            for item in items:
                if item['type'] == DataType.CONVERSATION.value:
                    await db.execute('''
                        UPDATE conversations 
                        SET sync_status = 'failed',
                            sync_attempts = sync_attempts + 1,
                            sync_error = ?
                        WHERE conversation_id = ?
                    ''', (error, item['data']['conversation_id']))
                else:
                    await db.execute('''
                        UPDATE offline_queue 
                        SET sync_status = 'failed',
                            sync_attempts = sync_attempts + 1,
                            last_attempt = CURRENT_TIMESTAMP,
                            error_message = ?
                        WHERE id = ?
                    ''', (error, item['id']))
            
            await db.commit()
    
    async def get_conversation_history(self, 
                                     toy_id: str,
                                     limit: int = 50) -> List[Dict[str, Any]]:
        """Get recent conversation history"""
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute('''
                SELECT conversation_id, timestamp, user_input, 
                       toy_response, was_offline, duration_seconds
                FROM conversations 
                WHERE toy_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            ''', (toy_id, limit))
            
            conversations = []
            async for row in cursor:
                conversations.append({
                    'conversation_id': row[0],
                    'timestamp': row[1],
                    'user_input': row[2],
                    'toy_response': row[3],
                    'was_offline': bool(row[4]),
                    'duration_seconds': row[5]
                })
            
            return conversations
    
    async def get_usage_statistics(self, toy_id: str) -> Dict[str, Any]:
        """Get usage statistics for a toy"""
        async with aiosqlite.connect(self.db_path) as db:
            # Total conversations
            cursor = await db.execute('''
                SELECT COUNT(*) FROM conversations WHERE toy_id = ?
            ''', (toy_id,))
            total_conversations = (await cursor.fetchone())[0]
            
            # Offline conversations
            cursor = await db.execute('''
                SELECT COUNT(*) FROM conversations 
                WHERE toy_id = ? AND was_offline = 1
            ''', (toy_id,))
            offline_conversations = (await cursor.fetchone())[0]
            
            # Safety events
            cursor = await db.execute('''
                SELECT COUNT(*) FROM safety_events WHERE toy_id = ?
            ''', (toy_id,))
            safety_events = (await cursor.fetchone())[0]
            
            # Average session duration
            cursor = await db.execute('''
                SELECT AVG(duration_seconds) FROM conversations 
                WHERE toy_id = ? AND duration_seconds IS NOT NULL
            ''', (toy_id,))
            avg_duration = (await cursor.fetchone())[0] or 0
            
            # Popular commands
            cursor = await db.execute('''
                SELECT command, usage_count 
                FROM cached_responses 
                ORDER BY usage_count DESC 
                LIMIT 5
            ''')
            
            popular_commands = []
            async for row in cursor:
                popular_commands.append({
                    'command': row[0],
                    'usage_count': row[1]
                })
            
            return {
                'total_conversations': total_conversations,
                'offline_conversations': offline_conversations,
                'online_percentage': (1 - offline_conversations / max(total_conversations, 1)) * 100,
                'safety_events': safety_events,
                'average_duration_seconds': avg_duration,
                'popular_commands': popular_commands
            }
    
    async def cleanup_old_data(self):
        """Clean up old data based on retention policy"""
        async with aiosqlite.connect(self.db_path) as db:
            # Remove old conversations
            await db.execute('''
                DELETE FROM conversations 
                WHERE timestamp < datetime('now', '-{} days')
                AND sync_status = 'synced'
            '''.format(self.config.conversation_retention_days))
            
            # Remove old metrics
            await db.execute('''
                DELETE FROM usage_metrics 
                WHERE timestamp < datetime('now', '-30 days')
                AND sync_status = 'synced'
            ''')
            
            # Clean up synced offline queue items
            await db.execute('''
                DELETE FROM offline_queue 
                WHERE sync_status = 'synced' 
                AND created_at < datetime('now', '-7 days')
            ''')
            
            # Vacuum to reclaim space
            await db.execute('VACUUM')
            
            await db.commit()
    
    async def backup_to_persistent(self):
        """Backup tmpfs database to persistent storage"""
        try:
            # Use aiosqlite backup API
            async with aiosqlite.connect(self.db_path) as source:
                async with aiosqlite.connect(self.config.backup_path) as backup:
                    await source.backup(backup)
            
            logger.info(f"Database backed up to {self.config.backup_path}")
            
        except Exception as e:
            logger.error(f"Backup failed: {e}")
    
    async def restore_from_backup(self):
        """Restore database from backup if exists"""
        if os.path.exists(self.config.backup_path):
            try:
                async with aiosqlite.connect(self.config.backup_path) as source:
                    async with aiosqlite.connect(self.db_path) as target:
                        await source.backup(target)
                
                logger.info("Database restored from backup")
                
            except Exception as e:
                logger.error(f"Restore failed: {e}")


class CacheSyncManager:
    """Manages periodic sync of cached data to cloud"""
    
    def __init__(self, cache: ConversationCache, sync_callback: Optional[callable] = None):
        self.cache = cache
        self.sync_callback = sync_callback
        self.is_running = False
        self.sync_task = None
        
    async def start(self):
        """Start periodic sync"""
        self.is_running = True
        self.sync_task = asyncio.create_task(self._sync_loop())
        logger.info("Cache sync manager started")
        
    async def stop(self):
        """Stop periodic sync"""
        self.is_running = False
        if self.sync_task:
            self.sync_task.cancel()
        logger.info("Cache sync manager stopped")
        
    async def _sync_loop(self):
        """Main sync loop"""
        while self.is_running:
            try:
                # Perform sync
                await self.sync_pending_data()
                
                # Cleanup old data
                await self.cache.cleanup_old_data()
                
                # Backup to persistent storage
                await self.cache.backup_to_persistent()
                
                # Wait for next sync
                await asyncio.sleep(self.cache.config.sync_interval_seconds)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Sync loop error: {e}")
                await asyncio.sleep(60)  # Wait before retry
    
    async def sync_pending_data(self):
        """Sync pending data to cloud"""
        if not self.sync_callback:
            return
        
        items = await self.cache.get_unsynced_items()
        
        if not items:
            return
        
        logger.info(f"Syncing {len(items)} items to cloud")
        
        try:
            # Call sync callback
            success = await self.sync_callback(items)
            
            if success:
                await self.cache.mark_synced(items)
                logger.info(f"Successfully synced {len(items)} items")
            else:
                await self.cache.mark_sync_failed(items, "Sync callback failed")
                
        except Exception as e:
            logger.error(f"Sync error: {e}")
            await self.cache.mark_sync_failed(items, str(e))


# Example usage and testing
if __name__ == "__main__":
    async def test_conversation_cache():
        """Test conversation cache functionality"""
        logger.info("Testing conversation cache...")
        
        # Create cache
        cache = ConversationCache()
        await cache.initialize()
        
        # Test saving conversation
        conv_id = await cache.save_conversation(
            user_input="Hello Pommai",
            toy_response="Hi there! I'm so happy to talk with you!",
            toy_id="test-toy-001",
            was_offline=False,
            duration_seconds=3.5
        )
        logger.info(f"Saved conversation: {conv_id}")
        
        # Test offline response
        response = await cache.get_offline_response("greeting")
        logger.info(f"Offline response: {response}")
        
        # Test toy configuration
        await cache.save_toy_configuration({
            'toy_id': 'test-toy-001',
            'name': 'Test Pommai',
            'is_for_kids': True,
            'safety_level': 'strict',
            'wake_word': 'hey pommai'
        })
        
        config = await cache.get_toy_configuration('test-toy-001')
        logger.info(f"Toy config: {config}")
        
        # Test safety event
        await cache.log_safety_event(
            event_type='blocked_content',
            severity='medium',
            content='User asked about violence',
            toy_id='test-toy-001',
            is_urgent=False
        )
        
        # Test metrics
        await cache.log_metric('conversation_count', 1, 'test-toy-001')
        
        # Test statistics
        stats = await cache.get_usage_statistics('test-toy-001')
        logger.info(f"Usage stats: {stats}")
        
        # Test sync
        unsynced = await cache.get_unsynced_items()
        logger.info(f"Unsynced items: {len(unsynced)}")
        
        # Test history
        history = await cache.get_conversation_history('test-toy-001')
        logger.info(f"Conversation history: {len(history)} items")
        
        logger.info("Conversation cache test completed!")
    
    # Run test
    asyncio.run(test_conversation_cache())
</file>

<file path="src/fastrtc_connection.py">
#!/usr/bin/env python3
"""
FastRTC WebSocket Connection Handler for Raspberry Pi
Simplified connection to FastRTC gateway for real-time audio streaming
"""

import asyncio
import json
import logging
import time
from typing import Optional, Dict, Any, Callable
from dataclasses import dataclass
from enum import Enum

import websockets
import numpy as np

# Configure logging
logger = logging.getLogger(__name__)


class ConnectionState(Enum):
    """Connection state enumeration"""
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    RECONNECTING = "reconnecting"
    FAILED = "failed"


@dataclass
class FastRTCConfig:
    """Configuration for FastRTC connection"""
    gateway_url: str
    device_id: str
    toy_id: str
    auth_token: Optional[str] = None
    reconnect_attempts: int = 5
    reconnect_delay: float = 2.0
    ping_interval: int = 30  # Increased from 20
    ping_timeout: int = 60  # Increased from 10 to handle long AI processing
    audio_format: str = "opus"
    sample_rate: int = 16000


class FastRTCConnection:
    """Simplified WebSocket connection to FastRTC gateway"""
    
    def __init__(self, config: FastRTCConfig):
        self.config = config
        self.ws: Optional[websockets.WebSocketClientProtocol] = None
        self.state = ConnectionState.DISCONNECTED
        self.reconnect_count = 0
        self.message_handlers: Dict[str, Callable] = {}
        self.receive_task: Optional[asyncio.Task] = None
        self.heartbeat_task: Optional[asyncio.Task] = None
        self.audio_queue = asyncio.Queue(maxsize=1000)
        self.last_activity = time.time()
        self.last_audio_sent_time = 0  # Track when we last sent audio
        
        # Register default handlers
        self._register_default_handlers()
    
    def _register_default_handlers(self):
        """Register default message handlers"""
        self.on_message("pong", self._handle_pong)
        self.on_message("audio_response", self._handle_audio_response)
        self.on_message("error", self._handle_error)
        self.on_message("config_update", self._handle_config_update)
    
    async def connect(self) -> bool:
        """Connect to FastRTC gateway"""
        if self.state == ConnectionState.CONNECTED:
            logger.warning("Already connected")
            return True
        
        self.state = ConnectionState.CONNECTING
        
        try:
            # Prepare connection headers
            headers = {
                'X-Device-ID': self.config.device_id,
                'X-Toy-ID': self.config.toy_id,
            }
            
            if self.config.auth_token:
                headers['Authorization'] = f'Bearer {self.config.auth_token}'
            
            # Construct proper WebSocket URL with device_id and toy_id in path
            # Expected format: ws://host:port/ws/{device_id}/{toy_id}
            base_url = self.config.gateway_url.rstrip('/')
            if not base_url.endswith('/ws'):
                if '/ws' not in base_url:
                    base_url = f"{base_url}/ws"
            
            # Append device_id and toy_id to the path
            ws_url = f"{base_url}/{self.config.device_id}/{self.config.toy_id}"
            
            logger.info(f"Connecting to FastRTC gateway at {ws_url}")
            
            # Establish WebSocket connection
            self.ws = await websockets.connect(
                ws_url,
                extra_headers=headers,
                ping_interval=self.config.ping_interval,
                ping_timeout=self.config.ping_timeout
            )
            
            # Send handshake
            await self._send_handshake()
            
            # Start background tasks
            self.receive_task = asyncio.create_task(self._receive_messages())
            self.heartbeat_task = asyncio.create_task(self._heartbeat_loop())
            
            self.state = ConnectionState.CONNECTED
            self.reconnect_count = 0
            logger.info("Successfully connected to FastRTC gateway")
            
            return True
            
        except Exception as e:
            logger.error(f"Connection failed: {e}")
            self.state = ConnectionState.FAILED
            
            # Attempt reconnection
            if self.reconnect_count < self.config.reconnect_attempts:
                await self._reconnect()
            
            return False
    
    async def disconnect(self):
        """Disconnect from gateway"""
        logger.info("Disconnecting from FastRTC gateway")
        
        # Cancel background tasks
        if self.receive_task:
            self.receive_task.cancel()
        if self.heartbeat_task:
            self.heartbeat_task.cancel()
        
        # Close WebSocket
        if self.ws:
            await self.ws.close()
            self.ws = None
        
        self.state = ConnectionState.DISCONNECTED
    
    async def _send_handshake(self):
        """Send initial handshake message"""
        handshake = {
            'type': 'handshake',
            'deviceId': self.config.device_id,
            'toyId': self.config.toy_id,
            'capabilities': {
                'audio': True,
                'wakeWord': True,
                'offlineMode': True,
                'opus': True,
                'sampleRate': self.config.sample_rate,
            },
            'timestamp': time.time()
        }
        
        await self.send_message(handshake)
        logger.debug("Handshake sent")
    
    async def send_message(self, message: Dict[str, Any]):
        """Send JSON message through WebSocket"""
        if not self.ws or self.state != ConnectionState.CONNECTED:
            logger.error(f"Cannot send message: WebSocket not connected (state={self.state})")
            return
        
        try:
            await self.ws.send(json.dumps(message))
            self.last_activity = time.time()
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            await self._handle_connection_error()
    
    async def send_audio_chunk(self, audio_data: bytes, is_final: bool = False, metadata: Optional[Dict] = None):
        """Send audio chunk to gateway"""
        if self.state != ConnectionState.CONNECTED:
            logger.warning("Cannot send audio: Not connected")
            return False
        
        current_time = time.time()
        
        # Clear the audio queue when starting a new interaction
        # This happens when we send the first chunk after a gap (new button press or wake word detection)
        if not is_final and (current_time - self.last_audio_sent_time) > 1.5:
            # It's been more than 1.5 seconds since last audio - this is a new interaction
            queue_size = self.audio_queue.qsize()
            if queue_size > 0:
                # Clear the queue
                cleared = 0
                while not self.audio_queue.empty():
                    try:
                        self.audio_queue.get_nowait()
                        cleared += 1
                    except asyncio.QueueEmpty:
                        break
                logger.info(f"Cleared {cleared} items from audio queue for new interaction (was {queue_size})")
        
        # Update the last audio sent time
        self.last_audio_sent_time = current_time
        
        message = {
            'type': 'audio_chunk',
            'payload': {
                'data': audio_data.hex() if isinstance(audio_data, bytes) else audio_data,
                'metadata': {
                    'isFinal': is_final,
                    'format': self.config.audio_format,
                    'sampleRate': self.config.sample_rate,
                    'timestamp': current_time,
                    **(metadata or {})
                }
            }
        }
        
        await self.send_message(message)
        return True
    
    async def start_streaming(self, audio_callback: Optional[Callable] = None):
        """Start audio streaming mode"""
        message = {
            'type': 'control',
            'command': 'start_streaming',
            'timestamp': time.time()
        }
        
        await self.send_message(message)
        
        if audio_callback:
            self.on_message("audio_chunk", audio_callback)
    
    async def stop_streaming(self):
        """Stop audio streaming mode"""
        message = {
            'type': 'control',
            'command': 'stop_streaming',
            'timestamp': time.time()
        }
        
        await self.send_message(message)
    
    async def _receive_messages(self):
        """Receive and process messages from gateway"""
        logger.info("Starting receive loop")
        try:
            while self.state == ConnectionState.CONNECTED and self.ws and not self.ws.closed:
                try:
                    # Use wait_for to add timeout to prevent hanging
                    message = await asyncio.wait_for(self.ws.recv(), timeout=60)
                    data = json.loads(message)
                    await self._handle_message(data)
                except asyncio.TimeoutError:
                    logger.warning("WebSocket receive timeout, sending ping")
                    try:
                        await self.ws.ping()
                    except Exception:
                        logger.error("Ping failed, connection lost")
                        break
                except json.JSONDecodeError:
                    logger.error(f"Invalid JSON received: {message[:100] if 'message' in locals() else 'unknown'}")
                except websockets.exceptions.ConnectionClosed:
                    logger.warning("WebSocket connection closed by server")
                    break
                except Exception as e:
                    logger.error(f"Error handling message: {e}")
                    if "connection" in str(e).lower():
                        break
            logger.info("Receive loop ended")
            # Connection lost
            if self.state == ConnectionState.CONNECTED:
                await self._handle_connection_error()
        except Exception as e:
            logger.error(f"Receive loop critical error: {e}")
            await self._handle_connection_error()
    
    async def _handle_message(self, message: Dict[str, Any]):
        """Handle received message"""
        msg_type = message.get('type')
        logger.debug(f"Received message type: {msg_type}")

        # Always enqueue audio chunks before user handlers
        if msg_type == 'audio_response':
            try:
                await self._handle_audio_response(message)
            except Exception as e:
                logger.error(f"Error enqueuing audio chunk: {e}")
        
        if msg_type in self.message_handlers:
            logger.debug(f"Found handler for {msg_type}, calling it")
            handler = self.message_handlers[msg_type]
            try:
                await handler(message)
            except Exception as e:
                logger.error(f"Handler error for {msg_type}: {e}")
        else:
            logger.debug(f"Unhandled message type: {msg_type} (registered: {list(self.message_handlers.keys())})")
        
        self.last_activity = time.time()
    
    async def _heartbeat_loop(self):
        """Send periodic heartbeat messages"""
        while self.state == ConnectionState.CONNECTED:
            try:
                await asyncio.sleep(30)  # Send heartbeat every 30 seconds
                
                if self.state == ConnectionState.CONNECTED:
                    await self.send_message({
                        'type': 'ping',
                        'timestamp': time.time()
                    })
                    
            except Exception as e:
                logger.error(f"Heartbeat error: {e}")
    
    async def _handle_connection_error(self):
        """Handle connection errors"""
        if self.state == ConnectionState.CONNECTED:
            self.state = ConnectionState.RECONNECTING
            await self._reconnect()
    
    async def _reconnect(self):
        """Attempt to reconnect to gateway"""
        self.reconnect_count += 1
        
        if self.reconnect_count > self.config.reconnect_attempts:
            logger.error("Max reconnection attempts reached")
            self.state = ConnectionState.FAILED
            return
        
        delay = self.config.reconnect_delay * (2 ** (self.reconnect_count - 1))
        delay = min(delay, 60)  # Cap at 60 seconds
        
        logger.info(f"Reconnecting in {delay:.1f} seconds (attempt {self.reconnect_count}/{self.config.reconnect_attempts})")
        await asyncio.sleep(delay)
        
        # Clean up old connection
        if self.ws:
            try:
                await self.ws.close()
            except Exception:
                pass
            self.ws = None
        # Cancel background tasks before reconnecting
        if self.receive_task:
            try:
                self.receive_task.cancel()
            except Exception:
                pass
        if self.heartbeat_task:
            try:
                self.heartbeat_task.cancel()
            except Exception:
                pass
        
        # Attempt reconnection
        await self.connect()
    
    def on_message(self, msg_type: str, handler: Callable):
        """Register a message handler"""
        self.message_handlers[msg_type] = handler
    
    async def _handle_pong(self, message: Dict):
        """Handle pong response"""
        logger.debug("Pong received")
    
    async def _handle_audio_response(self, message: Dict):
        """Handle audio response from server"""
        payload = message.get('payload', {})
        audio_data = payload.get('data')
        metadata = payload.get('metadata', {})
        
        if audio_data:
            # Convert hex string back to bytes
            audio_bytes = bytes.fromhex(audio_data)
            
            # Add to audio queue for playback (non-blocking)
            try:
                self.audio_queue.put_nowait({
                    'data': audio_bytes,
                    'metadata': metadata
                })
                logger.info(f"Queued audio chunk: {len(audio_bytes)} bytes, format={metadata.get('format')}, queue_size={self.audio_queue.qsize()}")
            except asyncio.QueueFull:
                logger.error("Audio queue full - dropping chunk")
        else:
            # Enqueue a final marker so consumers can stop cleanly
            if metadata.get('isFinal', False):
                try:
                    self.audio_queue.put_nowait({
                        'data': b'',
                        'metadata': metadata
                    })
                    logger.info("Queued final audio marker")
                except asyncio.QueueFull:
                    logger.error("Audio queue full - dropping final marker")
                
                # IMPORTANT: Trigger playback when final marker is received
                if self.audio_queue.qsize() > 0:
                    logger.info("TRIGGER: Audio chunks ready for playback (queue has %d items)", self.audio_queue.qsize())
                    # Send a synthetic audio_ready message to trigger playback
                    # Call the handler directly if it exists
                    if 'audio_ready' in self.message_handlers:
                        await self.message_handlers['audio_ready']({'type': 'audio_ready', 'trigger': 'final_marker'})
    
    async def _handle_error(self, message: Dict):
        """Handle error message from server"""
        error = message.get('error', 'Unknown error')
        logger.error(f"Server error: {error}")
    
    async def _handle_config_update(self, message: Dict):
        """Handle configuration update from server"""
        config = message.get('config', {})
        logger.info(f"Configuration update received: {config}")
    
    def is_connected(self) -> bool:
        """Check if connected to gateway"""
        return self.state == ConnectionState.CONNECTED
    
    def get_state(self) -> ConnectionState:
        """Get current connection state"""
        return self.state
    
    async def get_audio_chunk(self, timeout: float = 1.0) -> Optional[Dict]:
        """Get audio chunk from queue"""
        try:
            return await asyncio.wait_for(
                self.audio_queue.get(),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            return None
    
    def get_stats(self) -> Dict[str, Any]:
        """Get connection statistics"""
        return {
            'state': self.state.value,
            'reconnect_count': self.reconnect_count,
            'last_activity': time.time() - self.last_activity,
            'queue_size': self.audio_queue.qsize(),
            'connected': self.is_connected()
        }


# Convenience function for testing
async def test_connection():
    """Test FastRTC connection"""
    config = FastRTCConfig(
        gateway_url="ws://localhost:8080/ws",
        device_id="test-device",
        toy_id="test-toy"
    )
    
    client = FastRTCConnection(config)
    
    try:
        # Connect
        connected = await client.connect()
        if not connected:
            print("Failed to connect")
            return
        
        print("Connected successfully!")
        
        # Send test audio
        test_audio = b"test audio data"
        await client.send_audio_chunk(test_audio, is_final=True)
        
        # Wait for response
        await asyncio.sleep(2)
        
        # Get stats
        stats = client.get_stats()
        print(f"Stats: {stats}")
        
    finally:
        await client.disconnect()


if __name__ == "__main__":
    # Run test
    asyncio.run(test_connection())
</file>

<file path="src/fastrtc_guardrails.py">
#!/usr/bin/env python3
"""
FastRTC WebSocket Connection with GuardrailsAI Safety Integration
Enhanced connection handler with comprehensive content moderation
"""

import asyncio
import json
import logging
import time
from typing import Optional, Dict, Any, Callable, Tuple
from dataclasses import dataclass
from enum import Enum

import websockets
import numpy as np

# Import safety module
from guardrails_safety import (
    GuardrailsSafetyManager,
    SafetyConfig,
    SafetyLevel,
    FastRTCSafetyMiddleware,
    SafetyResult
)

# Configure logging
logger = logging.getLogger(__name__)


class ConnectionState(Enum):
    """Connection state enumeration"""
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    RECONNECTING = "reconnecting"
    FAILED = "failed"


@dataclass
class FastRTCConfig:
    """Configuration for FastRTC connection with safety"""
    gateway_url: str
    device_id: str
    toy_id: str
    auth_token: Optional[str] = None
    reconnect_attempts: int = 5
    reconnect_delay: float = 2.0
    ping_interval: int = 20
    ping_timeout: int = 10
    audio_format: str = "opus"
    sample_rate: int = 16000
    # Safety configuration
    age_group: str = "6-8"
    safety_level: SafetyLevel = SafetyLevel.MODERATE
    enable_safety: bool = True
    custom_blocked_words: list = None
    custom_blocked_topics: list = None


class FastRTCConnectionWithSafety:
    """FastRTC WebSocket connection with GuardrailsAI safety integration"""
    
    def __init__(self, config: FastRTCConfig):
        self.config = config
        self.ws: Optional[websockets.WebSocketClientProtocol] = None
        self.state = ConnectionState.DISCONNECTED
        self.reconnect_count = 0
        self.message_handlers: Dict[str, Callable] = {}
        self.receive_task: Optional[asyncio.Task] = None
        self.heartbeat_task: Optional[asyncio.Task] = None
        self.audio_queue = asyncio.Queue(maxsize=100)
        self.last_activity = time.time()
        
        # Initialize safety manager if enabled
        self.safety_middleware = None
        if config.enable_safety:
            self._initialize_safety()
        
        # Session info for safety context
        self.session_info = {
            "device_id": config.device_id,
            "toy_id": config.toy_id,
            "age_group": config.age_group,
            "session_id": f"{config.device_id}_{int(time.time())}",
            "start_time": time.time()
        }
        
        # Register default handlers
        self._register_default_handlers()
    
    def _initialize_safety(self):
        """Initialize GuardrailsAI safety manager"""
        safety_config = SafetyConfig(
            level=self.config.safety_level,
            age_group=self.config.age_group,
            block_personal_info=True,
            block_profanity=True,
            block_toxic_content=True,
            block_sensitive_topics=True,
            custom_blocked_words=self.config.custom_blocked_words or [],
            custom_blocked_topics=self.config.custom_blocked_topics or [],
            max_message_length=500 if self.config.age_group == "3-5" else 1000
        )
        
        self.safety_middleware = FastRTCSafetyMiddleware(safety_config)
        logger.info(f"Safety middleware initialized for age group: {self.config.age_group}")
    
    def _register_default_handlers(self):
        """Register default message handlers"""
        self.on_message("pong", self._handle_pong)
        self.on_message("audio_response", self._handle_audio_response)
        self.on_message("text_response", self._handle_text_response)
        self.on_message("error", self._handle_error)
        self.on_message("config_update", self._handle_config_update)
        self.on_message("safety_alert", self._handle_safety_alert)
    
    async def connect(self) -> bool:
        """Connect to FastRTC gateway with safety enabled"""
        if self.state == ConnectionState.CONNECTED:
            logger.warning("Already connected")
            return True
        
        self.state = ConnectionState.CONNECTING
        
        try:
            # Prepare connection headers
            headers = {
                'X-Device-ID': self.config.device_id,
                'X-Toy-ID': self.config.toy_id,
                'X-Safety-Enabled': str(self.config.enable_safety),
                'X-Age-Group': self.config.age_group,
            }
            
            if self.config.auth_token:
                headers['Authorization'] = f'Bearer {self.config.auth_token}'
            
            logger.info(f"Connecting to FastRTC gateway at {self.config.gateway_url}")
            
            # Establish WebSocket connection
            self.ws = await websockets.connect(
                self.config.gateway_url,
                extra_headers=headers,
                ping_interval=self.config.ping_interval,
                ping_timeout=self.config.ping_timeout
            )
            
            # Send handshake with safety info
            await self._send_handshake()
            
            # Start background tasks
            self.receive_task = asyncio.create_task(self._receive_messages())
            self.heartbeat_task = asyncio.create_task(self._heartbeat_loop())
            
            self.state = ConnectionState.CONNECTED
            self.reconnect_count = 0
            logger.info("Successfully connected to FastRTC gateway with safety enabled")
            
            return True
            
        except Exception as e:
            logger.error(f"Connection failed: {e}")
            self.state = ConnectionState.FAILED
            
            # Attempt reconnection
            if self.reconnect_count < self.config.reconnect_attempts:
                await self._reconnect()
            
            return False
    
    async def _send_handshake(self):
        """Send initial handshake message with safety configuration"""
        handshake = {
            'type': 'handshake',
            'deviceId': self.config.device_id,
            'toyId': self.config.toy_id,
            'capabilities': {
                'audio': True,
                'wakeWord': True,
                'offlineMode': True,
                'opus': True,
                'sampleRate': self.config.sample_rate,
                'safety': self.config.enable_safety,
                'guardrails': True,  # Indicate GuardrailsAI support
            },
            'safety': {
                'enabled': self.config.enable_safety,
                'level': self.config.safety_level.value if self.config.enable_safety else None,
                'ageGroup': self.config.age_group,
                'framework': 'guardrails-ai',
            },
            'timestamp': time.time()
        }
        
        await self.send_message(handshake)
        logger.debug("Handshake with safety config sent")
    
    async def send_text_message(self, text: str, metadata: Optional[Dict] = None) -> Tuple[bool, str, Optional[str]]:
        """
        Send text message with safety check
        
        Returns:
            Tuple of (is_safe, processed_text, redirect_response)
        """
        if self.state != ConnectionState.CONNECTED:
            logger.warning("Cannot send text: Not connected")
            return False, None, None
        
        # Check safety if enabled
        if self.safety_middleware:
            is_safe, processed_text, redirect = await self.safety_middleware.process_user_input(
                text, 
                {**self.session_info, **(metadata or {})}
            )
            
            if not is_safe:
                logger.warning(f"Unsafe content blocked: {text[:50]}...")
                
                # Send safety redirect response
                if redirect:
                    await self._send_safety_redirect(redirect)
                
                return False, None, redirect
            
            # Use processed text (with PII removed, etc.)
            text = processed_text
        
        # Send safe message
        message = {
            'type': 'text_message',
            'payload': {
                'text': text,
                'metadata': {
                    'timestamp': time.time(),
                    'safety_checked': self.config.enable_safety,
                    **(metadata or {})
                }
            }
        }
        
        await self.send_message(message)
        return True, text, None
    
    async def _handle_text_response(self, message: Dict[str, Any]):
        """Handle text response from server with safety check"""
        payload = message.get('payload', {})
        text = payload.get('text', '')
        
        if self.safety_middleware:
            # Check AI response safety
            is_safe, processed_text = await self.safety_middleware.process_ai_output(
                text,
                self.session_info
            )
            
            if not is_safe:
                logger.warning(f"Unsafe AI response filtered: {text[:50]}...")
                text = processed_text  # Use safe replacement
            else:
                text = processed_text
        
        # Process safe response
        if hasattr(self, 'text_response_callback'):
            await self.text_response_callback(text, payload.get('metadata', {}))
    
    async def send_audio_chunk(self, audio_data: bytes, transcript: Optional[str] = None, 
                              is_final: bool = False, metadata: Optional[Dict] = None) -> bool:
        """Send audio chunk with optional transcript for safety checking"""
        if self.state != ConnectionState.CONNECTED:
            logger.warning("Cannot send audio: Not connected")
            return False
        
        # If transcript is provided, check safety
        if transcript and self.safety_middleware:
            is_safe, processed_transcript, redirect = await self.safety_middleware.process_user_input(
                transcript,
                {**self.session_info, **(metadata or {})}
            )
            
            if not is_safe:
                logger.warning(f"Unsafe audio transcript blocked: {transcript[:50]}...")
                
                # Send safety redirect
                if redirect:
                    await self._send_safety_redirect(redirect)
                
                return False
            
            # Update transcript with processed version
            transcript = processed_transcript
        
        message = {
            'type': 'audio_chunk',
            'payload': {
                'data': audio_data.hex() if isinstance(audio_data, bytes) else audio_data,
                'transcript': transcript,  # Include transcript if available
                'metadata': {
                    'isFinal': is_final,
                    'format': self.config.audio_format,
                    'sampleRate': self.config.sample_rate,
                    'timestamp': time.time(),
                    'safety_checked': bool(transcript and self.safety_middleware),
                    **(metadata or {})
                }
            }
        }
        
        await self.send_message(message)
        return True
    
    async def _send_safety_redirect(self, redirect_text: str):
        """Send safety redirect response to client"""
        message = {
            'type': 'safety_redirect',
            'payload': {
                'text': redirect_text,
                'reason': 'content_filtered',
                'timestamp': time.time()
            }
        }
        
        await self.send_message(message)
        
        # Log safety event
        logger.info(f"Safety redirect sent: {redirect_text[:50]}...")
    
    async def _handle_safety_alert(self, message: Dict[str, Any]):
        """Handle safety alerts from server"""
        payload = message.get('payload', {})
        alert_type = payload.get('type', 'unknown')
        
        logger.warning(f"Safety alert received: {alert_type}")
        
        # Could trigger additional actions like:
        # - Notifying parents
        # - Adjusting safety levels
        # - Logging to monitoring service
        
        if hasattr(self, 'safety_alert_callback'):
            await self.safety_alert_callback(payload)
    
    def on_message(self, msg_type: str, handler: Callable):
        """Register message handler"""
        self.message_handlers[msg_type] = handler
    
    async def send_message(self, message: Dict[str, Any]):
        """Send JSON message through WebSocket"""
        if not self.ws or self.ws.closed:
            logger.error("Cannot send message: WebSocket not connected")
            return
        
        try:
            await self.ws.send(json.dumps(message))
            self.last_activity = time.time()
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            await self._handle_connection_error()
    
    async def _receive_messages(self):
        """Receive and process messages from server"""
        try:
            async for message in self.ws:
                try:
                    data = json.loads(message)
                    msg_type = data.get('type')
                    
                    # Process message through handler
                    if msg_type in self.message_handlers:
                        await self.message_handlers[msg_type](data)
                    else:
                        logger.debug(f"Unhandled message type: {msg_type}")
                    
                    self.last_activity = time.time()
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse message: {e}")
                except Exception as e:
                    logger.error(f"Error processing message: {e}")
                    
        except websockets.exceptions.ConnectionClosed:
            logger.warning("WebSocket connection closed")
            await self._handle_connection_error()
    
    async def _heartbeat_loop(self):
        """Send periodic heartbeat messages"""
        while self.state == ConnectionState.CONNECTED:
            try:
                await asyncio.sleep(self.config.ping_interval)
                
                # Send ping with safety stats
                ping_message = {
                    'type': 'ping',
                    'timestamp': time.time(),
                    'safety_stats': await self._get_safety_stats() if self.safety_middleware else None
                }
                
                await self.send_message(ping_message)
                
            except Exception as e:
                logger.error(f"Heartbeat error: {e}")
                break
    
    async def _get_safety_stats(self) -> Dict[str, Any]:
        """Get safety statistics for current session"""
        # This would integrate with the safety manager to get stats
        return {
            'session_duration': time.time() - self.session_info['start_time'],
            'safety_checks': 0,  # Would track actual checks
            'blocks': 0,  # Would track blocked messages
            'age_group': self.config.age_group,
            'safety_level': self.config.safety_level.value
        }
    
    async def _handle_pong(self, message: Dict[str, Any]):
        """Handle pong response"""
        logger.debug("Pong received")
    
    async def _handle_audio_response(self, message: Dict[str, Any]):
        """Handle audio response from server"""
        payload = message.get('payload', {})
        audio_data = payload.get('data')
        
        if audio_data:
            # Decode audio data
            audio_bytes = bytes.fromhex(audio_data)
            
            # Add to audio queue
            await self.audio_queue.put(audio_bytes)
            
            # Call audio callback if registered
            if hasattr(self, 'audio_response_callback'):
                await self.audio_response_callback(audio_bytes, payload.get('metadata', {}))
    
    async def _handle_error(self, message: Dict[str, Any]):
        """Handle error message from server"""
        error = message.get('payload', {})
        logger.error(f"Server error: {error}")
        
        # Handle specific error types
        error_type = error.get('type', 'unknown')
        
        if error_type == 'safety_violation':
            # Handle safety violations
            logger.warning(f"Safety violation: {error.get('message')}")
            
            if hasattr(self, 'safety_violation_callback'):
                await self.safety_violation_callback(error)
    
    async def _handle_config_update(self, message: Dict[str, Any]):
        """Handle configuration update from server"""
        config = message.get('payload', {})
        
        # Update safety configuration if provided
        if 'safety' in config:
            safety_config = config['safety']
            
            if safety_config.get('level'):
                self.config.safety_level = SafetyLevel(safety_config['level'])
            
            if safety_config.get('ageGroup'):
                self.config.age_group = safety_config['ageGroup']
            
            # Reinitialize safety with new config
            if self.config.enable_safety:
                self._initialize_safety()
                logger.info(f"Safety configuration updated: {safety_config}")
    
    async def _handle_connection_error(self):
        """Handle connection errors"""
        self.state = ConnectionState.FAILED
        
        # Attempt reconnection
        if self.reconnect_count < self.config.reconnect_attempts:
            await self._reconnect()
    
    async def _reconnect(self):
        """Attempt to reconnect to gateway"""
        self.state = ConnectionState.RECONNECTING
        self.reconnect_count += 1
        
        delay = self.config.reconnect_delay * (2 ** (self.reconnect_count - 1))
        logger.info(f"Reconnecting in {delay}s (attempt {self.reconnect_count}/{self.config.reconnect_attempts})")
        
        await asyncio.sleep(delay)
        await self.connect()
    
    async def disconnect(self):
        """Disconnect from gateway"""
        logger.info("Disconnecting from FastRTC gateway")
        
        # Cancel background tasks
        if self.receive_task:
            self.receive_task.cancel()
        if self.heartbeat_task:
            self.heartbeat_task.cancel()
        
        # Close WebSocket
        if self.ws:
            await self.ws.close()
            self.ws = None
        
        self.state = ConnectionState.DISCONNECTED
    
    def set_audio_callback(self, callback: Callable):
        """Set callback for audio responses"""
        self.audio_response_callback = callback
    
    def set_text_callback(self, callback: Callable):
        """Set callback for text responses"""
        self.text_response_callback = callback
    
    def set_safety_alert_callback(self, callback: Callable):
        """Set callback for safety alerts"""
        self.safety_alert_callback = callback
    
    def set_safety_violation_callback(self, callback: Callable):
        """Set callback for safety violations"""
        self.safety_violation_callback = callback


# Example usage
async def main():
    # Configure connection with safety
    config = FastRTCConfig(
        gateway_url="wss://pommai.co/fastrtc",
        device_id="test-device-001",
        toy_id="toy-123",
        age_group="6-8",
        safety_level=SafetyLevel.MODERATE,
        enable_safety=True,
        custom_blocked_words=["homework", "test"],
        custom_blocked_topics=["school stress"]
    )
    
    # Create connection
    connection = FastRTCConnectionWithSafety(config)
    
    # Set callbacks
    async def handle_audio(audio_data: bytes, metadata: Dict):
        print(f"Received audio response: {len(audio_data)} bytes")
    
    async def handle_text(text: str, metadata: Dict):
        print(f"Received text response: {text}")
    
    async def handle_safety_alert(alert: Dict):
        print(f"Safety alert: {alert}")
    
    connection.set_audio_callback(handle_audio)
    connection.set_text_callback(handle_text)
    connection.set_safety_alert_callback(handle_safety_alert)
    
    # Connect
    if await connection.connect():
        print("Connected successfully with safety enabled")
        
        # Test sending messages
        test_messages = [
            "Hello! What's your favorite game?",  # Safe
            "Can you tell me a story about dragons?",  # Safe for most ages
            "My phone number is 555-1234",  # PII - should be blocked
            "I don't like my homework",  # Custom blocked word
        ]
        
        for msg in test_messages:
            print(f"\nSending: {msg}")
            is_safe, processed, redirect = await connection.send_text_message(msg)
            
            if is_safe:
                print(f"Message sent: {processed}")
            else:
                print(f"Message blocked. Redirect: {redirect}")
        
        # Keep connection alive
        await asyncio.sleep(10)
        
        # Disconnect
        await connection.disconnect()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())
</file>

<file path="src/guardrails_safety.py">
"""
GuardrailsAI Safety Integration for Pommai FastRTC Server
Provides comprehensive content moderation and safety checks for child-safe interactions
"""

import os
import json
import logging
from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import asyncio

# GuardrailsAI imports
try:
    from guardrails import Guard
    from guardrails.hub import (
        ToxicLanguage,
        ProfanityCheck, 
        PIIChecker,
        SensitiveTopics,
        CompetitorCheck,
        Politeness,
        GibberishText,
        ValidLength
    )
    GUARDRAILS_AVAILABLE = True
except ImportError:
    GUARDRAILS_AVAILABLE = False
    logging.warning("GuardrailsAI not installed. Install with: pip install guardrails-ai")

# Fallback safety implementation if GuardrailsAI is not available
from difflib import SequenceMatcher
import re


class SafetyLevel(Enum):
    """Safety levels for content moderation"""
    STRICT = "strict"      # For young children (3-5)
    MODERATE = "moderate"  # For older children (6-8)
    RELAXED = "relaxed"    # For pre-teens (9-12)
    MINIMAL = "minimal"    # For adult users


@dataclass
class SafetyConfig:
    """Configuration for safety checks"""
    level: SafetyLevel
    age_group: str
    block_personal_info: bool = True
    block_profanity: bool = True
    block_toxic_content: bool = True
    block_sensitive_topics: bool = True
    custom_blocked_words: List[str] = None
    custom_blocked_topics: List[str] = None
    max_message_length: int = 500
    min_message_length: int = 1


@dataclass
class SafetyResult:
    """Result of safety check"""
    passed: bool
    reason: Optional[str] = None
    severity: Optional[str] = None
    modified_text: Optional[str] = None
    confidence: float = 0.0
    details: Dict[str, Any] = None


class GuardrailsSafetyManager:
    """
    Safety manager using GuardrailsAI for comprehensive content moderation
    """
    
    def __init__(self, config: SafetyConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Initialize GuardrailsAI guards if available
        if GUARDRAILS_AVAILABLE:
            self._initialize_guards()
        else:
            self.logger.warning("Using fallback safety implementation")
            self._initialize_fallback()
    
    def _initialize_guards(self):
        """Initialize GuardrailsAI guards based on safety level"""
        
        # Define thresholds based on safety level
        thresholds = {
            SafetyLevel.STRICT: {
                "toxicity": 0.1,
                "profanity": 0.0,
                "sensitivity": 0.2,
                "politeness": 0.8
            },
            SafetyLevel.MODERATE: {
                "toxicity": 0.3,
                "profanity": 0.1,
                "sensitivity": 0.4,
                "politeness": 0.6
            },
            SafetyLevel.RELAXED: {
                "toxicity": 0.5,
                "profanity": 0.3,
                "sensitivity": 0.6,
                "politeness": 0.4
            },
            SafetyLevel.MINIMAL: {
                "toxicity": 0.8,
                "profanity": 0.7,
                "sensitivity": 0.9,
                "politeness": 0.2
            }
        }
        
        level_thresholds = thresholds[self.config.level]
        
        # Create input guard for user messages
        self.input_guard = Guard().use_many(
            ToxicLanguage(threshold=level_thresholds["toxicity"]),
            ProfanityCheck(threshold=level_thresholds["profanity"]),
            PIIChecker(redact=self.config.block_personal_info),
            SensitiveTopics(
                topics=self._get_blocked_topics(),
                threshold=level_thresholds["sensitivity"]
            ),
            GibberishText(threshold=0.7),
            ValidLength(
                min=self.config.min_message_length,
                max=self.config.max_message_length
            )
        )
        
        # Create output guard for AI responses
        self.output_guard = Guard().use_many(
            ToxicLanguage(threshold=level_thresholds["toxicity"] * 0.5),  # Stricter for AI
            ProfanityCheck(threshold=0.0),  # No profanity in AI responses
            Politeness(threshold=level_thresholds["politeness"]),
            PIIChecker(redact=True),
            ValidLength(
                min=1,
                max=self.config.max_message_length * 2  # Allow longer AI responses
            )
        )
        
        # Add custom word filter if provided
        if self.config.custom_blocked_words:
            from guardrails.hub import RestrictToTopic
            self.input_guard.use(
                RestrictToTopic(
                    invalid_topics=self.config.custom_blocked_words,
                    disable_llm=True
                )
            )
    
    def _initialize_fallback(self):
        """Initialize fallback safety checks without GuardrailsAI"""
        
        # Default blocked words for different age groups
        self.blocked_words = {
            "3-5": [
                "kill", "death", "die", "hurt", "pain", "blood", "gun", "knife",
                "monster", "scary", "nightmare", "demon", "devil", "hell"
            ],
            "6-8": [
                "kill", "death", "murder", "suicide", "drug", "alcohol", "cigarette",
                "violence", "weapon", "bomb", "terrorist"
            ],
            "9-12": [
                "suicide", "self-harm", "drug", "cocaine", "heroin", "meth",
                "porn", "sex", "naked"
            ]
        }
        
        # Sensitive topics to avoid
        self.sensitive_topics = [
            "violence", "death", "drugs", "alcohol", "smoking",
            "adult content", "politics", "religion", "war"
        ]
        
        # Personal information patterns
        self.pii_patterns = [
            r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',  # Full phone number
            r'\b\d{3}[-.]?\d{4}\b',  # Short phone number (555-1234)
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',  # Email
            r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
            r'\b(?:\d{4}[-\s]?){3}\d{4}\b',  # Credit card
            r'\b\d{5}(?:[-\s]\d{4})?\b',  # ZIP code
        ]
    
    async def check_input(self, text: str, metadata: Dict[str, Any] = None) -> SafetyResult:
        """
        Check user input for safety violations
        
        Args:
            text: User input text
            metadata: Additional context (e.g., user age, session info)
            
        Returns:
            SafetyResult with pass/fail and details
        """
        
        if GUARDRAILS_AVAILABLE:
            return await self._check_with_guardrails(text, self.input_guard, "input")
        else:
            return await self._check_with_fallback(text, "input")
    
    async def check_output(self, text: str, metadata: Dict[str, Any] = None) -> SafetyResult:
        """
        Check AI output for safety violations
        
        Args:
            text: AI response text
            metadata: Additional context
            
        Returns:
            SafetyResult with pass/fail and details
        """
        
        if GUARDRAILS_AVAILABLE:
            return await self._check_with_guardrails(text, self.output_guard, "output")
        else:
            return await self._check_with_fallback(text, "output")
    
    async def _check_with_guardrails(self, text: str, guard: Any, check_type: str) -> SafetyResult:
        """Check text using GuardrailsAI"""
        
        try:
            # Run validation
            result = guard.validate(text)
            
            # Check if validation passed
            if result.validation_passed:
                return SafetyResult(
                    passed=True,
                    modified_text=result.validated_output,
                    confidence=1.0,
                    details={"validators": result.validator_results}
                )
            else:
                # Extract failure reasons
                failed_validators = [
                    v for v in result.validator_results 
                    if not v.get("passed", True)
                ]
                
                # Determine severity
                severity = self._determine_severity(failed_validators)
                
                # Get main failure reason
                main_reason = failed_validators[0].get("reason", "Content safety violation")
                
                return SafetyResult(
                    passed=False,
                    reason=main_reason,
                    severity=severity,
                    modified_text=None,
                    confidence=0.9,
                    details={
                        "failed_validators": failed_validators,
                        "all_results": result.validator_results
                    }
                )
                
        except Exception as e:
            self.logger.error(f"GuardrailsAI check failed: {e}")
            # Fall back to basic check
            return await self._check_with_fallback(text, check_type)
    
    async def _check_with_fallback(self, text: str, check_type: str) -> SafetyResult:
        """Fallback safety check without GuardrailsAI"""
        
        text_lower = text.lower()
        violations = []
        
        # Check for blocked words
        age_group = self.config.age_group or "6-8"
        blocked = self.blocked_words.get(age_group, self.blocked_words["6-8"])
        if self.config.custom_blocked_words:
            blocked.extend(self.config.custom_blocked_words)
        
        for word in blocked:
            if word.lower() in text_lower:
                violations.append(f"Blocked word: {word}")
        
        # Check for PII
        if self.config.block_personal_info:
            for pattern in self.pii_patterns:
                if re.search(pattern, text):
                    violations.append("Personal information detected")
                    break
        
        # Check for sensitive topics
        if self.config.block_sensitive_topics:
            for topic in self.sensitive_topics:
                if topic.lower() in text_lower:
                    violations.append(f"Sensitive topic: {topic}")
        
        # Check message length
        if len(text) > self.config.max_message_length:
            violations.append("Message too long")
        elif len(text) < self.config.min_message_length:
            violations.append("Message too short")
        
        # Check for gibberish (simple heuristic)
        if self._is_gibberish(text):
            violations.append("Gibberish text detected")
        
        if violations:
            return SafetyResult(
                passed=False,
                reason=violations[0],
                severity="high" if len(violations) > 2 else "medium",
                confidence=0.7,
                details={"violations": violations}
            )
        
        return SafetyResult(
            passed=True,
            modified_text=text,
            confidence=0.6
        )
    
    def _is_gibberish(self, text: str) -> bool:
        """Simple gibberish detection"""
        # Check for too many consonants in a row
        consonant_clusters = re.findall(r'[bcdfghjklmnpqrstvwxyz]{5,}', text.lower())
        if len(consonant_clusters) > 2:
            return True
        
        # Check for repeated characters
        repeated = re.findall(r'(.)\1{4,}', text)
        if repeated:
            return True
        
        # Check for lack of vowels
        vowel_ratio = len(re.findall(r'[aeiou]', text.lower())) / max(len(text), 1)
        if vowel_ratio < 0.1:
            return True
        
        return False
    
    def _determine_severity(self, violations: List[Dict]) -> str:
        """Determine overall severity from violations"""
        
        if not violations:
            return "none"
        
        severities = [v.get("severity", "medium") for v in violations]
        
        if "critical" in severities or "high" in severities:
            return "high"
        elif "medium" in severities:
            return "medium"
        else:
            return "low"
    
    def _get_blocked_topics(self) -> List[str]:
        """Get list of blocked topics based on age group"""
        
        base_topics = []
        
        if self.config.age_group == "3-5":
            base_topics = [
                "violence", "death", "scary stories", "monsters",
                "weapons", "fighting", "war", "disasters"
            ]
        elif self.config.age_group == "6-8":
            base_topics = [
                "violence", "death", "drugs", "alcohol",
                "weapons", "war", "adult topics"
            ]
        elif self.config.age_group == "9-12":
            base_topics = [
                "graphic violence", "self-harm", "drugs",
                "explicit content", "hate speech"
            ]
        
        if self.config.custom_blocked_topics:
            base_topics.extend(self.config.custom_blocked_topics)
        
        return base_topics
    
    async def get_safe_response(self, 
                                violation_reason: str,
                                age_group: str = None) -> str:
        """
        Generate a safe, age-appropriate redirect response
        
        Args:
            violation_reason: Why the content was blocked
            age_group: Target age group for response
            
        Returns:
            Safe response text
        """
        
        age_group = age_group or self.config.age_group
        
        responses = {
            "3-5": [
                "That's interesting! Let's talk about something fun instead. What's your favorite color?",
                "Hmm, how about we play a game? Can you name three animals that start with B?",
                "I love talking about happy things! What makes you smile?",
                "Let's think of something cheerful! What's your favorite toy?"
            ],
            "6-8": [
                "That's an interesting question! Let's explore something else. What's your favorite subject in school?",
                "How about we talk about something different? What's the coolest thing you learned recently?",
                "I'd love to hear about your hobbies! What do you like to do for fun?",
                "Let's change topics! If you could have any superpower, what would it be?"
            ],
            "9-12": [
                "Let's shift gears to something else. What are you currently interested in learning about?",
                "That topic isn't quite right for our chat. What's a book or movie you've enjoyed recently?",
                "How about we discuss something different? What's a skill you'd like to develop?",
                "Let's explore another topic. What's something creative you've done lately?"
            ]
        }
        
        import random
        age_responses = responses.get(age_group, responses["6-8"])
        return random.choice(age_responses)
    
    async def log_safety_incident(self,
                                  text: str,
                                  result: SafetyResult,
                                  user_id: str = None,
                                  session_id: str = None):
        """
        Log safety incidents for monitoring and improvement
        
        Args:
            text: The flagged text
            result: Safety check result
            user_id: User identifier
            session_id: Session identifier
        """
        
        incident = {
            "timestamp": asyncio.get_event_loop().time(),
            "text": text[:100],  # Truncate for privacy
            "reason": result.reason,
            "severity": result.severity,
            "user_id": user_id,
            "session_id": session_id,
            "safety_level": self.config.level.value,
            "age_group": self.config.age_group
        }
        
        # Log to file or monitoring service
        self.logger.warning(f"Safety incident: {json.dumps(incident)}")
        
        # Could also send to monitoring service, database, etc.
        # await self.send_to_monitoring(incident)


class FastRTCSafetyMiddleware:
    """
    Middleware for integrating safety checks into FastRTC pipeline
    """
    
    def __init__(self, safety_config: SafetyConfig):
        self.safety_manager = GuardrailsSafetyManager(safety_config)
        self.logger = logging.getLogger(__name__)
    
    async def process_user_input(self, 
                                 text: str,
                                 session_info: Dict[str, Any]) -> Tuple[bool, str, Optional[str]]:
        """
        Process user input through safety checks
        
        Args:
            text: User input text
            session_info: Session metadata (toy_id, user_id, etc.)
            
        Returns:
            Tuple of (is_safe, processed_text, redirect_response)
        """
        
        # Check input safety
        result = await self.safety_manager.check_input(text, session_info)
        
        if result.passed:
            # Return safe text (possibly modified to remove PII)
            return True, result.modified_text or text, None
        else:
            # Log incident
            await self.safety_manager.log_safety_incident(
                text, 
                result,
                session_info.get("user_id"),
                session_info.get("session_id")
            )
            
            # Get safe redirect response
            redirect = await self.safety_manager.get_safe_response(
                result.reason,
                session_info.get("age_group")
            )
            
            return False, None, redirect
    
    async def process_ai_output(self,
                                text: str,
                                session_info: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Process AI output through safety checks
        
        Args:
            text: AI response text
            session_info: Session metadata
            
        Returns:
            Tuple of (is_safe, processed_text)
        """
        
        # Check output safety
        result = await self.safety_manager.check_output(text, session_info)
        
        if result.passed:
            return True, result.modified_text or text
        else:
            # Log incident
            await self.safety_manager.log_safety_incident(
                text,
                result,
                session_info.get("user_id"),
                session_info.get("session_id")
            )
            
            # Return a generic safe response
            safe_response = "I need to think about that differently. Let's talk about something else!"
            return False, safe_response


# Integration with FastRTC server
async def integrate_safety_with_fastrtc(rtc_server):
    """
    Integrate safety checks into FastRTC server
    
    Args:
        rtc_server: The FastRTC server instance
    """
    
    # Create safety middleware for different age groups
    safety_configs = {
        "3-5": SafetyConfig(
            level=SafetyLevel.STRICT,
            age_group="3-5",
            max_message_length=200
        ),
        "6-8": SafetyConfig(
            level=SafetyLevel.MODERATE,
            age_group="6-8",
            max_message_length=300
        ),
        "9-12": SafetyConfig(
            level=SafetyLevel.RELAXED,
            age_group="9-12",
            max_message_length=500
        ),
        "adult": SafetyConfig(
            level=SafetyLevel.MINIMAL,
            age_group="adult",
            max_message_length=1000,
            block_personal_info=True
        )
    }
    
    # Add safety middleware to RTC server
    for age_group, config in safety_configs.items():
        middleware = FastRTCSafetyMiddleware(config)
        rtc_server.add_middleware(age_group, middleware)
    
    return rtc_server


# Example usage
if __name__ == "__main__":
    import asyncio
    
    async def test_safety():
        # Create safety config for young children
        config = SafetyConfig(
            level=SafetyLevel.STRICT,
            age_group="3-5",
            custom_blocked_words=["homework", "test"],
            custom_blocked_topics=["school stress"]
        )
        
        # Create safety manager
        manager = GuardrailsSafetyManager(config)
        
        # Test various inputs
        test_texts = [
            "Hello! What's your favorite game?",  # Safe
            "I want to hurt someone",  # Violent
            "My phone number is 555-1234",  # PII
            "asdkfjaslkdfj",  # Gibberish
            "Let's talk about death and monsters",  # Sensitive topic
        ]
        
        for text in test_texts:
            result = await manager.check_input(text)
            print(f"Text: {text[:50]}...")
            print(f"Passed: {result.passed}")
            if not result.passed:
                print(f"Reason: {result.reason}")
                safe_response = await manager.get_safe_response(result.reason)
                print(f"Redirect: {safe_response}")
            print("-" * 50)
    
    # Run test
    asyncio.run(test_safety())
</file>

<file path="src/led_controller.py">
#!/usr/bin/env python3
"""
LED Controller for Pommai Raspberry Pi Client
Manages all LED patterns and visual feedback for the ReSpeaker 2-Mics HAT
"""

import asyncio
import math
import time
import logging
from enum import Enum
from typing import Optional, Dict, Tuple
import os
try:
    import RPi.GPIO as GPIO
except Exception:
    class _GPIOStub:
        BCM = 'BCM'
        OUT = 'OUT'
        IN = 'IN'
        LOW = 0
        HIGH = 1
        class PWM:
            def __init__(self, *args, **kwargs):
                pass
            def start(self, *args, **kwargs):
                pass
            def ChangeDutyCycle(self, *args, **kwargs):
                pass
            def stop(self, *args, **kwargs):
                pass
    GPIO = _GPIOStub()

# Try to import spidev for APA102 control (ReSpeaker v2)
try:
    import spidev  # type: ignore
except Exception:
    spidev = None


class LEDPattern(Enum):
    """Predefined LED patterns for different states"""
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    SPEAKING = "speaking"
    ERROR = "error"
    CONNECTION_LOST = "connection_lost"
    LOADING_TOY = "loading_toy"
    SWITCHING_TOY = "switching_toy"
    GUARDIAN_ALERT = "guardian_alert"
    SAFE_MODE = "safe_mode"
    LOW_BATTERY = "low_battery"
    CELEBRATION = "celebration"
    THINKING = "thinking"
    OFFLINE = "offline"


class ColorMixer:
    """Helper class for RGB color mixing and conversions"""
    
    @staticmethod
    def rgb_to_duty_cycle(r: int, g: int, b: int) -> Dict[str, int]:
        """Convert RGB (0-255) to duty cycle (0-100)"""
        return {
            'red': int(r * 100 / 255),
            'green': int(g * 100 / 255),
            'blue': int(b * 100 / 255)
        }
    
    @staticmethod
    def hsv_to_rgb(h: float, s: float, v: float) -> Tuple[int, int, int]:
        """Convert HSV to RGB for smooth color transitions"""
        import colorsys
        r, g, b = colorsys.hsv_to_rgb(h, s, v)
        return int(r * 255), int(g * 255), int(b * 255)
    
    @staticmethod
    def interpolate_color(start: Tuple[int, int, int], end: Tuple[int, int, int], progress: float) -> Tuple[int, int, int]:
        """Linear interpolation between two colors"""
        r = int(start[0] + (end[0] - start[0]) * progress)
        g = int(start[1] + (end[1] - start[1]) * progress)
        b = int(start[2] + (end[2] - start[2]) * progress)
        return r, g, b


class PixelAPA102:
    """Minimal APA102 (DotStar) driver over spidev for ReSpeaker v2 LEDs."""
    def __init__(self, led_count: int = 2, spi_bus: int = 0, spi_dev: int = 0, max_mhz: int = 8):
        if spidev is None:
            raise RuntimeError("spidev not available")
        self.led_count = max(1, led_count)
        self.spi = spidev.SpiDev()
        self.spi.open(spi_bus, spi_dev)
        # Max clock speed (Hz). APA102 can handle high speeds; 8MHz is safe
        self.spi.max_speed_hz = max_mhz * 1_000_000
        self.spi.mode = 0b00

    def _frame(self, colors, brightness: float):
        # APA102 protocol: start frame (4x0x00), then per-LED: 0xE0 | brightness(5 bits) + B,G,R, end frame
        start = [0x00, 0x00, 0x00, 0x00]
        bval = max(1, min(31, int(31 * max(0.0, min(1.0, brightness)))))
        led_frames = []
        for (r, g, b) in colors:
            led_frames += [0xE0 | bval, b & 0xFF, g & 0xFF, r & 0xFF]
        end_len = (self.led_count + 15) // 16  # per spec
        end = [0xFF] * max(1, end_len)
        return start + led_frames + end

    def set_all(self, r: int, g: int, b: int, brightness: float = 0.5):
        frame = self._frame([(r, g, b)] * self.led_count, brightness)
        self.spi.xfer2(frame)

    def clear(self):
        self.set_all(0, 0, 0, 0.0)

    def close(self):
        try:
            self.clear()
        except Exception:
            pass
        self.spi.close()


class LEDController:
    """Main LED controller with async pattern support"""
    
    def __init__(self, pwm_controllers: Optional[Dict[str, GPIO.PWM]] = None):
        self.pwm_controllers = pwm_controllers or {}
        self.apa: Optional[PixelAPA102] = None
        self.current_pattern = None
        self.pattern_task: Optional[asyncio.Task] = None
        self.brightness_scale = 1.0  # Global brightness control
        self.low_power_mode = False
        
        # Try to initialize APA102 over SPI if available
        if spidev is not None:
            try:
                led_count = int(os.getenv('RESPEAKER_LED_COUNT', '2'))
                spi_bus = int(os.getenv('SPI_BUS', '0'))
                spi_dev = int(os.getenv('SPI_DEV', '0'))
                self.apa = PixelAPA102(led_count=led_count, spi_bus=spi_bus, spi_dev=spi_dev)
                logging.info("APA102 LED driver initialized (count=%d, bus=%d, dev=%d)", led_count, spi_bus, spi_dev)
            except Exception as e:
                logging.warning("APA102 init failed, falling back to PWM LEDs: %s", e)
        
    async def set_pattern(self, pattern: LEDPattern, **kwargs):
        """Set LED pattern with smooth transitions"""
        # Cancel current pattern if running
        if self.pattern_task and not self.pattern_task.done():
            self.pattern_task.cancel()
            try:
                await self.pattern_task
            except asyncio.CancelledError:
                pass
        
        # Clear LEDs briefly for transition
        await self._all_leds_off()
        await asyncio.sleep(0.05)
        
        self.current_pattern = pattern
        
        # Map patterns to methods
        pattern_methods = {
            LEDPattern.IDLE: self._pattern_idle_breathing,
            LEDPattern.LISTENING: self._pattern_listening_pulse,
            LEDPattern.PROCESSING: self._pattern_processing_swirl,
            LEDPattern.SPEAKING: self._pattern_speaking_solid,
            LEDPattern.ERROR: self._pattern_error_flash,
            LEDPattern.CONNECTION_LOST: self._pattern_connection_lost,
            LEDPattern.LOADING_TOY: self._pattern_loading_toy,
            LEDPattern.SWITCHING_TOY: self._pattern_switching_toy,
            LEDPattern.GUARDIAN_ALERT: self._pattern_guardian_alert,
            LEDPattern.SAFE_MODE: self._pattern_safe_mode,
            LEDPattern.LOW_BATTERY: self._pattern_low_battery,
            LEDPattern.CELEBRATION: self._pattern_celebration,
            LEDPattern.THINKING: self._pattern_thinking,
            LEDPattern.OFFLINE: self._pattern_offline,
        }
        
        method = pattern_methods.get(pattern)
        if method:
            self.pattern_task = asyncio.create_task(method(**kwargs))
        else:
            logging.warning(f"Unknown LED pattern: {pattern}")
    
    def set_brightness(self, scale: float):
        """Adjust overall LED brightness (0.0 to 1.0)"""
        self.brightness_scale = max(0.0, min(1.0, scale))
    
    def enable_low_power_mode(self):
        """Reduce LED brightness to save battery"""
        self.low_power_mode = True
        self.brightness_scale = 0.3
    
    def disable_low_power_mode(self):
        """Restore normal LED brightness"""
        self.low_power_mode = False
        self.brightness_scale = 1.0
    
    def _apply_brightness(self, duty_cycle: int) -> int:
        """Apply brightness scaling to duty cycle"""
        scaled = duty_cycle * self.brightness_scale
        if self.low_power_mode:
            scaled = min(scaled, 30)  # Cap at 30% in low power
        return int(scaled)
    
    async def _set_color(self, r: int, g: int, b: int):
        """Set LED color with brightness adjustment"""
        if self.apa is not None:
            # Map brightness_scale (0-1) to APA global brightness (0-1)
            self.apa.set_all(r, g, b, brightness=self.brightness_scale)
        elif self.pwm_controllers:
            duty_cycles = ColorMixer.rgb_to_duty_cycle(r, g, b)
            for color, duty in duty_cycles.items():
                adjusted_duty = self._apply_brightness(duty)
                self.pwm_controllers[color].ChangeDutyCycle(adjusted_duty)
        else:
            # No LED hardware available
            pass
    
    async def _all_leds_off(self):
        """Turn off all LEDs"""
        if self.apa is not None:
            try:
                self.apa.clear()
            except Exception:
                pass
        for pwm in self.pwm_controllers.values():
            pwm.ChangeDutyCycle(0)
    
    # Pattern Implementations
    
    async def _pattern_idle_breathing(self):
        """Gentle breathing effect in blue"""
        try:
            while True:
                # Breathe in
                for brightness in range(0, 30, 2):
                    await self._set_color(0, 0, int(brightness * 255 / 100))
                    await asyncio.sleep(0.05)
                
                # Hold
                await asyncio.sleep(0.2)
                
                # Breathe out
                for brightness in range(30, 0, -2):
                    await self._set_color(0, 0, int(brightness * 255 / 100))
                    await asyncio.sleep(0.05)
                
                # Pause
                await asyncio.sleep(0.5)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_listening_pulse(self):
        """Fast pulsing blue to indicate recording"""
        try:
            while True:
                # Double pulse
                for _ in range(2):
                    await self._set_color(0, 0, 255)
                    await asyncio.sleep(0.1)
                    await self._set_color(0, 0, 51)  # 20% blue
                    await asyncio.sleep(0.1)
                
                # Pause between pulse sets
                await asyncio.sleep(0.3)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_processing_swirl(self):
        """Rainbow swirl effect while thinking"""
        try:
            phase = 0
            while True:
                # Calculate RGB values using sine waves
                red = int(127 * (1 + math.sin(phase)))
                green = int(127 * (1 + math.sin(phase + 2.094)))  # 120 degrees
                blue = int(127 * (1 + math.sin(phase + 4.189)))   # 240 degrees
                
                await self._set_color(red, green, blue)
                
                # Advance phase
                phase += 0.1
                await asyncio.sleep(0.05)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_speaking_solid(self):
        """Solid green while speaking"""
        try:
            await self._set_color(0, 204, 0)  # Nice green
            
            # Keep solid until cancelled
            while True:
                await asyncio.sleep(1)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_error_flash(self):
        """Fast red flashing for errors"""
        try:
            while True:
                await self._set_color(255, 0, 0)
                await asyncio.sleep(0.1)
                await self._set_color(0, 0, 0)
                await asyncio.sleep(0.1)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_connection_lost(self):
        """Slow amber pulse for connection issues"""
        try:
            while True:
                # Pulse up
                for brightness in range(0, 80, 5):
                    r = int(brightness * 255 / 100)
                    g = int(brightness * 128 / 100)  # Half green for amber
                    await self._set_color(r, g, 0)
                    await asyncio.sleep(0.03)
                
                # Pulse down
                for brightness in range(80, 0, -5):
                    r = int(brightness * 255 / 100)
                    g = int(brightness * 128 / 100)
                    await self._set_color(r, g, 0)
                    await asyncio.sleep(0.03)
                
                await asyncio.sleep(0.5)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_loading_toy(self):
        """Spinning white effect for loading"""
        try:
            colors = [(255, 255, 255), (128, 128, 128), (64, 64, 64)]
            color_index = 0
            
            while True:
                await self._set_color(*colors[color_index])
                color_index = (color_index + 1) % len(colors)
                await asyncio.sleep(0.2)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_switching_toy(self):
        """Color transition effect for toy switching"""
        try:
            # Transition through toy personality colors
            colors = [
                (255, 0, 0),    # Red
                (255, 165, 0),  # Orange
                (255, 255, 0),  # Yellow
                (0, 255, 0),    # Green
                (0, 255, 255),  # Cyan
                (0, 0, 255),    # Blue
                (128, 0, 128),  # Purple
            ]
            
            while True:
                for i in range(len(colors)):
                    start_color = colors[i]
                    end_color = colors[(i + 1) % len(colors)]
                    
                    # Smooth transition
                    for step in range(20):
                        progress = step / 20
                        color = ColorMixer.interpolate_color(start_color, end_color, progress)
                        await self._set_color(*color)
                        await asyncio.sleep(0.05)
                        
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_guardian_alert(self):
        """Amber pulse for guardian mode alerts"""
        try:
            while True:
                # Quick double pulse
                for _ in range(2):
                    await self._set_color(255, 128, 0)  # Amber
                    await asyncio.sleep(0.15)
                    await self._set_color(0, 0, 0)
                    await asyncio.sleep(0.1)
                
                await asyncio.sleep(0.7)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_safe_mode(self):
        """Slow green breathing for safe mode"""
        try:
            while True:
                # Breathe in
                for brightness in range(10, 50, 3):
                    await self._set_color(0, int(brightness * 255 / 100), 0)
                    await asyncio.sleep(0.08)
                
                # Breathe out
                for brightness in range(50, 10, -3):
                    await self._set_color(0, int(brightness * 255 / 100), 0)
                    await asyncio.sleep(0.08)
                
                await asyncio.sleep(0.3)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_low_battery(self):
        """Red pulse for low battery warning"""
        try:
            while True:
                # Single slow pulse
                await self._set_color(255, 0, 0)
                await asyncio.sleep(0.5)
                await self._set_color(0, 0, 0)
                await asyncio.sleep(2.0)  # Long pause between pulses
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_celebration(self):
        """Fun rainbow celebration effect"""
        try:
            while True:
                # Fast rainbow cycle
                for hue in range(0, 360, 10):
                    r, g, b = ColorMixer.hsv_to_rgb(hue / 360, 1.0, 1.0)
                    await self._set_color(r, g, b)
                    await asyncio.sleep(0.03)
                    
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_thinking(self):
        """Gentle purple swirl for thinking"""
        try:
            phase = 0
            while True:
                # Purple variations
                brightness = 50 + 30 * math.sin(phase)
                await self._set_color(int(brightness), 0, int(brightness * 1.5))
                phase += 0.05
                await asyncio.sleep(0.05)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    async def _pattern_offline(self):
        """Dim white pulse for offline mode"""
        try:
            while True:
                # Very dim white pulse
                for brightness in range(0, 20, 2):
                    await self._set_color(brightness, brightness, brightness)
                    await asyncio.sleep(0.1)
                
                for brightness in range(20, 0, -2):
                    await self._set_color(brightness, brightness, brightness)
                    await asyncio.sleep(0.1)
                
                await asyncio.sleep(1.0)
                
        except asyncio.CancelledError:
            await self._all_leds_off()
            raise
    
    # Special Effects
    
    async def flash_color(self, r: int, g: int, b: int, duration: float = 0.1, count: int = 1):
        """Flash a specific color"""
        for _ in range(count):
            await self._set_color(r, g, b)
            await asyncio.sleep(duration)
            await self._all_leds_off()
            await asyncio.sleep(duration)
    
    async def fade_to_color(self, r: int, g: int, b: int, duration: float = 1.0):
        """Fade from current color to target color"""
        steps = 50
        step_duration = duration / steps
        
        # This is simplified - in production, track current color
        for step in range(steps):
            progress = step / steps
            brightness = int(progress * 100)
            await self._set_color(
                int(r * progress),
                int(g * progress),
                int(b * progress)
            )
            await asyncio.sleep(step_duration)
</file>

<file path="src/opus_audio_codec.py">
#!/usr/bin/env python3
"""
Opus Audio Codec Implementation for Pommai Smart Toy
Handles audio compression/decompression for network transmission
"""

import asyncio
import logging
import struct
import time
import collections
from typing import Optional, Dict, Any, AsyncGenerator, Tuple
from dataclasses import dataclass
from enum import Enum

try:
    import opuslib
except ImportError:
    try:
        # Fallback to pyopus if opuslib not available
        import pyopus as opuslib
    except ImportError:
        # Neither library available - we'll handle this in __init__
        opuslib = None

import numpy as np


# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class OpusConfig:
    """Opus codec configuration"""
    sample_rate: int = 16000
    channels: int = 1
    bitrate: int = 24000  # 24 kbps for good quality/size balance
    complexity: int = 5   # Balanced for Pi Zero 2W
    frame_size_ms: int = 20  # 20ms frames recommended
    packet_loss_perc: int = 10  # Expected packet loss %
    enable_fec: bool = True  # Forward Error Correction
    enable_dtx: bool = True  # Discontinuous Transmission
    
    @property
    def frame_size_samples(self) -> int:
        """Calculate frame size in samples"""
        return int(self.sample_rate * self.frame_size_ms / 1000)
    
    @property
    def frame_size_bytes(self) -> int:
        """Calculate frame size in bytes (16-bit samples)"""
        return self.frame_size_samples * 2 * self.channels


class NetworkQuality(Enum):
    """Network quality levels"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"


class OpusAudioCodec:
    """Opus audio codec with adaptive bitrate and FEC"""
    
    def __init__(self, config: Optional[OpusConfig] = None):
        self.config = config or OpusConfig()
        self.encoder = None
        self.decoder = None
        self.initialized = False
        
        # Check if we're using PCM16 format
        import os
        audio_format = os.getenv('AUDIO_SEND_FORMAT', 'opus').lower()
        
        if audio_format == 'pcm16':
            logger.info("PCM16 format configured, skipping Opus codec initialization")
        else:
            try:
                self._setup_codec()
                self.initialized = True
            except Exception as e:
                logger.error(f"Failed to initialize Opus codec: {e}")
                logger.info("Will use PCM16 format instead")
        
        self._setup_buffers()
        self._setup_metrics()
        
    def _setup_codec(self):
        """Initialize Opus encoder and decoder"""
        if opuslib is None:
            raise ImportError("No Opus library available (opuslib or pyopus)")
        
        try:
            # Create encoder
            self.encoder = opuslib.Encoder(
                self.config.sample_rate,
                self.config.channels,
                opuslib.APPLICATION_VOIP  # Optimized for voice
            )
            
            # Configure encoder with proper value passing
            self.encoder.bitrate = self.config.bitrate
            self.encoder.complexity = self.config.complexity
            
            # Handle the FEC setting issue
            try:
                self.encoder.inband_fec = self.config.enable_fec
            except TypeError:
                # Some versions need the value passed differently
                if hasattr(self.encoder, '_set_inband_fec'):
                    self.encoder._set_inband_fec(1 if self.config.enable_fec else 0)
                else:
                    logger.warning("Could not set inband_fec")
            
            self.encoder.packet_loss_perc = self.config.packet_loss_perc
            
            if hasattr(self.encoder, 'dtx'):
                self.encoder.dtx = self.config.enable_dtx
            
            if hasattr(self.encoder, 'signal'):
                self.encoder.signal = opuslib.SIGNAL_VOICE
            
            # Create decoder
            self.decoder = opuslib.Decoder(
                self.config.sample_rate,
                self.config.channels
            )
            
            logger.info(f"Opus (pylibopus) codec initialized: {self.config.bitrate}bps, "
                       f"{self.config.frame_size_ms}ms frames, "
                       f"FEC={self.config.enable_fec}, DTX={self.config.enable_dtx}")
            
        except Exception as e:
            logger.error(f"Failed to initialize Opus codec: {e}")
            raise
    
    def _setup_buffers(self):
        """Initialize audio buffers"""
        self.encode_buffer = bytearray()
        self.decode_buffer = bytearray()
        
        # Jitter buffer for network playback
        self.jitter_buffer = collections.deque(maxlen=10)
        
        # Packet loss concealment
        self.last_frame_size = self.config.frame_size_samples
        self.lost_packet_count = 0
        
    def _setup_metrics(self):
        """Initialize performance metrics"""
        self.metrics = {
            'frames_encoded': 0,
            'frames_decoded': 0,
            'bytes_compressed': 0,
            'bytes_original': 0,
            'encode_errors': 0,
            'decode_errors': 0,
            'packets_lost': 0,
            'network_quality': NetworkQuality.GOOD,
            'current_bitrate': self.config.bitrate
        }
        
    def encode_chunk(self, pcm_data: bytes) -> Optional[bytes]:
        """
        Encode PCM audio chunk to Opus
        
        Args:
            pcm_data: Raw PCM audio (16-bit, mono)
            
        Returns:
            Compressed Opus data with header
        """
        if not self.initialized or self.encoder is None:
            # Codec not initialized, return None to indicate PCM16 should be used
            return None
            
        try:
            # Validate input length
            expected_bytes = self.config.frame_size_bytes
            
            if len(pcm_data) < expected_bytes:
                # Pad with silence
                pcm_data += b'\x00' * (expected_bytes - len(pcm_data))
            elif len(pcm_data) > expected_bytes:
                # Trim excess
                pcm_data = pcm_data[:expected_bytes]
            
            # Encode frame
            encoded = self.encoder.encode(
                pcm_data,
                self.config.frame_size_samples
            )
            
            # Add header (length + frame size)
            header = struct.pack('!HH', len(encoded), self.config.frame_size_samples)
            
            # Update metrics
            self.metrics['frames_encoded'] += 1
            self.metrics['bytes_original'] += len(pcm_data)
            self.metrics['bytes_compressed'] += len(encoded)
            
            return header + encoded
            
        except Exception as e:
            logger.error(f"Encoding error: {e}")
            self.metrics['encode_errors'] += 1
            return None
    
    def decode_chunk(self, opus_data: bytes) -> Optional[bytes]:
        """
        Decode Opus audio chunk to PCM
        
        Args:
            opus_data: Compressed Opus data with header
            
        Returns:
            PCM audio data (16-bit, mono)
        """
        if not self.initialized or self.decoder is None:
            # Codec not initialized, return None
            return None
            
        try:
            # Extract header
            if len(opus_data) < 4:
                return self._generate_silence()
            
            encoded_len, frame_size = struct.unpack('!HH', opus_data[:4])
            encoded_data = opus_data[4:4+encoded_len]
            
            # Decode frame
            pcm_data = self.decoder.decode(encoded_data, frame_size)
            
            # Update metrics
            self.metrics['frames_decoded'] += 1
            self.last_frame_size = frame_size
            
            return pcm_data
            
        except Exception as e:
            logger.error(f"Decoding error: {e}")
            self.metrics['decode_errors'] += 1
            return self._handle_packet_loss()
    
    def decode_with_plc(self, opus_data: Optional[bytes] = None) -> bytes:
        """
        Decode with Packet Loss Concealment
        
        Args:
            opus_data: Compressed data or None for lost packet
            
        Returns:
            PCM audio with PLC if needed
        """
        if opus_data is None:
            # Packet lost - use PLC
            self.metrics['packets_lost'] += 1
            return self._handle_packet_loss()
        else:
            return self.decode_chunk(opus_data)
    
    def _handle_packet_loss(self) -> bytes:
        """Generate concealment audio for lost packet"""
        try:
            # Try to use decoder's built-in PLC
            if hasattr(self.decoder, 'decode') and hasattr(self.decoder.decode, '__call__'):
                pcm_data = self.decoder.decode(None, self.last_frame_size, fec=True)
                return pcm_data
        except:
            pass
        
        # Fallback to silence
        return self._generate_silence()
    
    def _generate_silence(self) -> bytes:
        """Generate silence for current frame size"""
        return b'\x00' * self.config.frame_size_bytes
    
    async def encode_stream(self, audio_stream: AsyncGenerator) -> AsyncGenerator:
        """
        Encode audio stream in real-time
        
        Args:
            audio_stream: Async generator of PCM chunks
            
        Yields:
            Dict with encoded data and metadata
        """
        sequence = 0
        
        async for chunk in audio_stream:
            # Add to buffer
            self.encode_buffer.extend(chunk)
            
            # Process complete frames
            while len(self.encode_buffer) >= self.config.frame_size_bytes:
                # Extract one frame
                frame_data = bytes(self.encode_buffer[:self.config.frame_size_bytes])
                self.encode_buffer = self.encode_buffer[self.config.frame_size_bytes:]
                
                # Check for voice activity
                if self.config.enable_dtx and self._is_silence(frame_data):
                    # Skip silent frames
                    continue
                
                # Encode frame
                encoded = self.encode_chunk(frame_data)
                
                if encoded:
                    yield {
                        'data': encoded,
                        'sequence': sequence,
                        'timestamp': time.time(),
                        'frame_size': self.config.frame_size_samples,
                        'compressed': True
                    }
                    sequence += 1
    
    def _is_silence(self, pcm_data: bytes, threshold_db: float = -40) -> bool:
        """
        Detect if audio frame is silence
        
        Args:
            pcm_data: PCM audio data
            threshold_db: Silence threshold in dBFS
            
        Returns:
            True if silence detected
        """
        try:
            # Convert to numpy array
            audio_array = np.frombuffer(pcm_data, dtype=np.int16)
            
            # Calculate RMS
            rms = np.sqrt(np.mean(audio_array.astype(np.float32) ** 2))
            
            # Convert to dBFS
            if rms > 0:
                db = 20 * np.log10(rms / 32768)
            else:
                db = -96
            
            return db < threshold_db
            
        except Exception:
            return False
    
    def adapt_bitrate(self, packet_loss: float, rtt_ms: float):
        """
        Dynamically adapt bitrate based on network conditions
        
        Args:
            packet_loss: Packet loss rate (0.0-1.0)
            rtt_ms: Round-trip time in milliseconds
        """
        # Calculate network quality score
        quality = 1.0 - (packet_loss * 2)  # Heavy penalty for loss
        quality -= max(0, (rtt_ms - 50) / 1000)  # Penalty for high RTT
        quality = max(0.0, min(1.0, quality))
        
        # Determine quality level
        if quality > 0.8:
            self.metrics['network_quality'] = NetworkQuality.EXCELLENT
            new_bitrate = 32000  # High quality
        elif quality > 0.6:
            self.metrics['network_quality'] = NetworkQuality.GOOD
            new_bitrate = 24000  # Normal quality
        elif quality > 0.4:
            self.metrics['network_quality'] = NetworkQuality.FAIR
            new_bitrate = 16000  # Reduced quality
        else:
            self.metrics['network_quality'] = NetworkQuality.POOR
            new_bitrate = 12000  # Minimum quality
        
        # Update encoder settings if initialized
        if self.encoder and new_bitrate != self.metrics['current_bitrate']:
            try:
                self.encoder.bitrate = new_bitrate
                self.metrics['current_bitrate'] = new_bitrate
                logger.info(f"Adapted bitrate to {new_bitrate}bps "
                           f"(quality: {self.metrics['network_quality'].value})")
                
                # Adjust FEC
                self.encoder.packet_loss_perc = int(packet_loss * 100)
            except Exception as e:
                logger.warning(f"Could not adapt bitrate: {e}")
    
    def get_compression_ratio(self) -> float:
        """Calculate current compression ratio"""
        if self.metrics['bytes_compressed'] == 0:
            return 0.0
        return self.metrics['bytes_original'] / self.metrics['bytes_compressed']
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get current codec metrics"""
        return {
            **self.metrics,
            'compression_ratio': self.get_compression_ratio(),
            'avg_frame_size': (self.metrics['bytes_compressed'] / 
                             max(1, self.metrics['frames_encoded']))
        }
    
    def reset_metrics(self):
        """Reset performance metrics"""
        self._setup_metrics()
    
    def cleanup(self):
        """Clean up codec resources"""
        try:
            # Clear buffers
            self.encode_buffer.clear()
            self.decode_buffer.clear()
            self.jitter_buffer.clear()
            
            logger.info("Opus codec cleaned up")
            
        except Exception as e:
            logger.error(f"Cleanup error: {e}")


class OpusStreamProcessor:
    """High-level Opus stream processor with buffering"""
    
    def __init__(self, config: Optional[OpusConfig] = None):
        self.codec = OpusAudioCodec(config)
        self.config = config or OpusConfig()
        self.processing_active = False
        
    async def process_duplex_stream(self,
                                   input_stream: AsyncGenerator,
                                   output_queue: asyncio.Queue,
                                   network_send: callable,
                                   network_recv: callable):
        """
        Process full-duplex audio streaming
        
        Args:
            input_stream: Microphone input generator
            output_queue: Speaker output queue
            network_send: Async function to send to network
            network_recv: Async function to receive from network
        """
        self.processing_active = True
        
        async def encode_task():
            """Encode and send audio"""
            async for encoded_frame in self.codec.encode_stream(input_stream):
                if not self.processing_active:
                    break
                await network_send(encoded_frame)
        
        async def decode_task():
            """Receive and decode audio"""
            while self.processing_active:
                try:
                    # Receive from network
                    opus_frame = await network_recv()
                    
                    if opus_frame:
                        # Decode
                        pcm_data = self.codec.decode_with_plc(opus_frame.get('data'))
                        
                        if pcm_data:
                            await output_queue.put({
                                'data': pcm_data,
                                'timestamp': opus_frame.get('timestamp', time.time())
                            })
                    
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"Decode task error: {e}")
                    await asyncio.sleep(0.01)
        
        # Run both tasks concurrently
        try:
            await asyncio.gather(
                encode_task(),
                decode_task()
            )
        finally:
            self.processing_active = False
    
    def stop(self):
        """Stop stream processing"""
        self.processing_active = False
        self.codec.cleanup()


# Example usage and testing
if __name__ == "__main__":
    import pyaudio
    
    async def test_opus_codec():
        """Test Opus codec functionality"""
        logger.info("Testing Opus codec...")
        
        # Create codec
        codec = OpusAudioCodec()
        
        # Test encoding/decoding
        test_samples = 320  # 20ms at 16kHz
        test_data = np.random.randint(-32768, 32767, test_samples, dtype=np.int16)
        pcm_data = test_data.tobytes()
        
        # Encode
        encoded = codec.encode_chunk(pcm_data)
        logger.info(f"Encoded {len(pcm_data)} bytes to {len(encoded)} bytes")
        
        # Decode
        decoded = codec.decode_chunk(encoded)
        logger.info(f"Decoded back to {len(decoded)} bytes")
        
        # Check metrics
        metrics = codec.get_metrics()
        logger.info(f"Compression ratio: {metrics['compression_ratio']:.2f}x")
        
        # Test packet loss concealment
        logger.info("\nTesting packet loss concealment...")
        plc_audio = codec.decode_with_plc(None)
        logger.info(f"Generated {len(plc_audio)} bytes of concealment audio")
        
        # Test adaptive bitrate
        logger.info("\nTesting adaptive bitrate...")
        codec.adapt_bitrate(0.05, 100)  # 5% loss, 100ms RTT
        logger.info(f"Network quality: {codec.metrics['network_quality'].value}")
        logger.info(f"Adapted bitrate: {codec.metrics['current_bitrate']}bps")
        
        # Test with real audio
        try:
            audio = pyaudio.PyAudio()
            
            # Create test stream
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                input=True,
                frames_per_buffer=320
            )
            
            logger.info("\nRecording 2 seconds of audio for compression test...")
            frames = []
            
            for _ in range(int(16000 / 320 * 2)):  # 2 seconds
                data = stream.read(320)
                frames.append(data)
                
                # Encode each frame
                encoded = codec.encode_chunk(data)
                if encoded:
                    decoded = codec.decode_chunk(encoded)
            
            stream.stop_stream()
            stream.close()
            audio.terminate()
            
            # Final metrics
            final_metrics = codec.get_metrics()
            logger.info(f"\nFinal compression ratio: {final_metrics['compression_ratio']:.2f}x")
            logger.info(f"Frames encoded: {final_metrics['frames_encoded']}")
            logger.info(f"Encoding errors: {final_metrics['encode_errors']}")
            
        except Exception as e:
            logger.warning(f"PyAudio test skipped: {e}")
        
        codec.cleanup()
        logger.info("\nOpus codec test completed!")
    
    # Run test
    asyncio.run(test_opus_codec())
</file>

<file path="src/pommai_client_fastrtc.py">
#!/usr/bin/env python3
"""
Updated Pommai Smart Toy Client for Raspberry Pi Zero 2W
Using FastRTC Gateway for simplified real-time communication

This updated client:
- Uses FastRTCConnection for WebSocket communication
- Streams audio; consumes audio_response chunks from a queue
- Handles PCM16/Opus, channels, endianness, and resampling
- Adds robust debug logging and env-based overrides
"""

import asyncio
import json
import logging
import os
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Optional, Dict, Any

# External dependencies
import pyaudio
import numpy as np
from dotenv import load_dotenv

# Local modules
from fastrtc_connection import FastRTCConnection, FastRTCConfig, ConnectionState
from led_controller import LEDController, LEDPattern
from button_handler import ButtonHandler
from audio_stream_manager import AudioStreamManager, AudioConfig
from opus_audio_codec import OpusAudioCodec, OpusConfig
from wake_word_detector import WakeWordDetector
from conversation_cache import ConversationCache, CacheConfig
from sync_manager import SyncManager

# Try to import audio utils for smart device detection
try:
    from audio_utils import get_audio_device_indices
    AUDIO_UTILS_AVAILABLE = True
except ImportError:
    AUDIO_UTILS_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.info("audio_utils not found, using default audio devices")

# Try to import RPi.GPIO (will fail on non-Pi systems)
try:
    import RPi.GPIO as GPIO
    ON_RASPBERRY_PI = True
except ImportError:
    ON_RASPBERRY_PI = False
    logging.warning("RPi.GPIO not available - running in simulation mode")

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def _get_env_with_fallback(primary, fallback_keys, default=None):
    """Read env var with fallbacks; log a warning if a legacy key is used."""
    val = os.getenv(primary)
    if val:
        return val
    for fk in fallback_keys:
        fb = os.getenv(fk)
        if fb:
            logger.warning(f"Using legacy env var {fk}; please set {primary} in .env")
            return fb
    return default if default is not None else ""


@dataclass
class Config:
    """Configuration for the updated Pommai client"""
    # FastRTC Gateway connection
    FASTRTC_GATEWAY_URL: str = _get_env_with_fallback('FASTRTC_GATEWAY_URL', ['CONVEX_URL'], 'ws://localhost:8080/ws')

    # Device identification
    DEVICE_ID: str = os.getenv('DEVICE_ID', 'rpi-toy-001')
    TOY_ID: str = _get_env_with_fallback('TOY_ID', ['POMMAI_TOY_ID'], 'default-toy')
    AUTH_TOKEN: str = _get_env_with_fallback('AUTH_TOKEN', ['POMMAI_USER_TOKEN'], '')

    # Audio settings
    SAMPLE_RATE: int = 16000
    CHUNK_SIZE: int = 320  # 20ms @ 16kHz aligns with Opus default frame
    CHANNELS: int = 1
    AUDIO_FORMAT: int = pyaudio.paInt16

    # Opus codec settings
    OPUS_BITRATE: int = 24000
    OPUS_COMPLEXITY: int = 5

    # GPIO pins (if on Raspberry Pi)
    BUTTON_PIN: int = 17
    LED_PINS: Dict[str, int] = field(default_factory=lambda: {
        'red': 5,
        'green': 6,
        'blue': 13
    })

    # Features
    ENABLE_WAKE_WORD: bool = os.getenv('ENABLE_WAKE_WORD', 'false').lower() == 'true'
    ENABLE_OFFLINE_MODE: bool = os.getenv('ENABLE_OFFLINE_MODE', 'true').lower() == 'true'

    # Performance
    MAX_RECONNECT_ATTEMPTS: int = 5
    RECONNECT_DELAY: float = 2.0


class ToyState(Enum):
    """State machine for toy operations"""
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    SPEAKING = "speaking"
    ERROR = "error"
    OFFLINE = "offline"
    CONNECTING = "connecting"


class HardwareController:
    """Manages PyAudio input/output streams for AudioStreamManager."""

    def __init__(self, sample_rate: int, channels: int, chunk_size: int,
                 input_device_index: Optional[int] = None,
                 output_device_index: Optional[int] = None,
                 output_sample_rate: Optional[int] = None):
        self._pa = pyaudio.PyAudio()
        self.input_stream = self._pa.open(
            format=pyaudio.paInt16,
            channels=channels,
            rate=sample_rate,
            input=True,
            input_device_index=input_device_index,
            frames_per_buffer=chunk_size
        )
        # Use a larger buffer for Bluetooth output to reduce underruns
        out_buffer = max(chunk_size, 1024)
        self.output_stream = self._pa.open(
            format=pyaudio.paInt16,
            channels=channels,
            rate=output_sample_rate or sample_rate,
            output=True,
            output_device_index=output_device_index,
            frames_per_buffer=out_buffer
        )

    def cleanup(self):
        try:
            if self.input_stream:
                self.input_stream.stop_stream()
                self.input_stream.close()
        except Exception:
            pass
        try:
            if self.output_stream:
                self.output_stream.stop_stream()
                self.output_stream.close()
        except Exception:
            pass
        try:
            self._pa.terminate()
        except Exception:
            pass


class PommaiClientFastRTC:
    """Main client application using FastRTC connection"""

    def __init__(self, config: Config):
        self.config = config
        self.state = ToyState.IDLE

        # Initialize FastRTC connection
        wire_format = os.getenv('AUDIO_SEND_FORMAT', 'opus').strip().lower()
        if wire_format not in ('opus', 'pcm16', 'wav'):
            wire_format = 'opus'
        rtc_config = FastRTCConfig(
            gateway_url=config.FASTRTC_GATEWAY_URL,
            device_id=config.DEVICE_ID,
            toy_id=config.TOY_ID,
            auth_token=config.AUTH_TOKEN,
            reconnect_attempts=config.MAX_RECONNECT_ATTEMPTS,
            reconnect_delay=config.RECONNECT_DELAY,
            audio_format=wire_format,
            sample_rate=config.SAMPLE_RATE
        )
        self.connection = FastRTCConnection(rtc_config)

        # Initialize audio components with smart device detection
        if AUDIO_UTILS_AVAILABLE:
            try:
                audio_devices = get_audio_device_indices()
                input_device = audio_devices.get("input")
                output_device = audio_devices.get("output")
                logger.info(f"Audio devices detected - Input: {input_device}, Output: {output_device}")
            except Exception as e:
                logger.warning(f"Failed to detect audio devices: {e}, using defaults")
                input_device = None
                output_device = None
        else:
            input_device = None
            output_device = None
            logger.info("Using default ALSA audio routing")

        # Optional hardcoded overrides via env
        try:
            forced_out = os.getenv('POMMAI_FORCE_OUTPUT_DEVICE_INDEX') or os.getenv('FORCE_OUTPUT_DEVICE_INDEX')
            if forced_out:
                output_device = int(forced_out)
                logger.info(f"HARDCODE_DEBUG: Using Output Device Index override: {output_device}")
        except Exception as e:
            logger.warning(f"HARDCODE_DEBUG: Invalid FORCE_OUTPUT_DEVICE_INDEX: {e}")
        try:
            forced_in = os.getenv('POMMAI_FORCE_INPUT_DEVICE_INDEX') or os.getenv('FORCE_INPUT_DEVICE_INDEX')
            if forced_in:
                input_device = int(forced_in)
                logger.info(f"HARDCODE_DEBUG: Using Input Device Index override: {input_device}")
        except Exception as e:
            logger.warning(f"HARDCODE_DEBUG: Invalid FORCE_INPUT_DEVICE_INDEX: {e}")

        # Playback rate (consider 24000 for ElevenLabs or 48000 for Bluetooth)
        try:
            playback_rate_env = os.getenv('PLAYBACK_SAMPLE_RATE') or os.getenv('FORCE_PLAYBACK_SAMPLE_RATE')
            playback_sample_rate = int(playback_rate_env) if playback_rate_env else None
        except Exception:
            playback_sample_rate = None

        self.hardware = HardwareController(
            sample_rate=config.SAMPLE_RATE,
            channels=config.CHANNELS,
            chunk_size=config.CHUNK_SIZE,
            input_device_index=input_device,
            output_device_index=output_device,
            output_sample_rate=playback_sample_rate
        )
        play_rate = playback_sample_rate or config.SAMPLE_RATE
        logger.info(f"AUDIO_DEVICE_SELECTION: Using Input Device Index: {input_device}")
        logger.info(f"AUDIO_DEVICE_SELECTION: Using Output Device Index: {output_device}")
        logger.info(f"AUDIO_DEVICE_SELECTION: Using Playback Sample Rate: {play_rate}")

        # Use 20ms playback chunks based on playback rate
        play_chunk_size = max(160, int(round(play_rate * 0.02)))
        if play_chunk_size % 2 == 1:
            play_chunk_size += 1
        self.audio_manager = AudioStreamManager(
            self.hardware,
            AudioConfig(sample_rate=play_rate, chunk_size=play_chunk_size, channels=config.CHANNELS)
        )

        self.opus_codec = OpusAudioCodec(OpusConfig(
            sample_rate=config.SAMPLE_RATE,
            channels=config.CHANNELS,
            bitrate=config.OPUS_BITRATE,
            complexity=config.OPUS_COMPLEXITY
        ))

        # Hardware controllers (Pi only)
        if ON_RASPBERRY_PI:
            try:
                GPIO.setmode(GPIO.BCM)
                GPIO.setwarnings(False)
                pwm_controllers = {}
                for color, pin in self.config.LED_PINS.items():
                    GPIO.setup(pin, GPIO.OUT)
                    pwm = GPIO.PWM(pin, 1000)
                    pwm.start(0)
                    pwm_controllers[color] = pwm
                self.led_controller = LEDController(pwm_controllers)
            except Exception as e:
                logger.error(f"LED controller init failed: {e}")
                self.led_controller = None

            try:
                self.button_handler = ButtonHandler(config.BUTTON_PIN)
                self.button_handler.set_callbacks(
                    on_press=self.on_button_press,
                    on_release=self.on_button_release
                )
            except Exception as e:
                logger.error(f"Button handler init failed: {e}")
                self.button_handler = None
        else:
            self.led_controller = None
            self.button_handler = None
            logger.info("Hardware controllers disabled (not on Raspberry Pi)")

        # Wake word detector (optional)
        self.wake_word_detector = None
        if config.ENABLE_WAKE_WORD:
            try:
                self.wake_word_detector = WakeWordDetector()
            except Exception as e:
                logger.error(f"Failed to initialize wake word detector: {e}")

        # Offline cache and sync manager with safe path
        self.cache: Optional[ConversationCache] = None
        if config.ENABLE_OFFLINE_MODE:
            try:
                cache_db = os.getenv('POMMAI_CACHE_DB') or '/home/pommai/cache/pommai_cache.db'
                cache_backup = os.getenv('POMMAI_CACHE_BACKUP') or '/home/pommai/cache/backup.db'
                try:
                    os.makedirs(os.path.dirname(cache_db), exist_ok=True)
                except Exception:
                    pass
                try:
                    os.makedirs(os.path.dirname(cache_backup), exist_ok=True)
                except Exception:
                    pass
                logger.info(f"CACHE: Using db_path={cache_db}, backup_path={cache_backup}")
                self.cache = ConversationCache(CacheConfig(db_path=cache_db, backup_path=cache_backup))
            except Exception as e:
                logger.error(f"ConversationCache init failed: {e} - disabling offline mode")
                self.cache = None
        self.sync_manager: Optional[SyncManager] = None

        # Audio recording state
        self.is_recording = False
        self.audio_buffer = []
        self.recording_task = None

        # Register message handlers (do NOT register 'audio_response' here)
        self._register_handlers()

    def _register_handlers(self):
        """Register message handlers for FastRTC connection."""
        # Audio chunks are enqueued by FastRTCConnection and read from get_audio_chunk()
        self.connection.on_message("text_response", self.handle_text_response)
        self.connection.on_message("audio_ready", self.handle_audio_ready)
        self.connection.on_message("config_update", self.handle_config_update)
        self.connection.on_message("error", self.handle_error)
        self.connection.on_message("toy_state", self.handle_toy_state)

    async def initialize(self) -> bool:
        """Initialize all components and connect to gateway"""
        logger.info("Initializing Pommai client with FastRTC...")

        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.LOADING_TOY)

        self.state = ToyState.CONNECTING

        connected = await self.connection.connect()
        if not connected:
            logger.error("Failed to connect to FastRTC gateway")
            self.state = ToyState.OFFLINE
            if self.led_controller:
                await self.led_controller.set_pattern(LEDPattern.ERROR)
            return False

        logger.info("Connected to FastRTC gateway successfully")

        # Initialize audio manager (no-op but future-proof)
        await self.audio_manager.initialize()

        # Initialize cache and start background sync
        if self.cache:
            try:
                await self.cache.initialize()
            except Exception as e:
                logger.error(f"Cache initialize failed: {e}. Disabling offline mode to continue.")
                self.cache = None
            if self.cache:
                self.sync_manager = SyncManager(self.cache, self.connection)
                await self.sync_manager.start()

        if self.wake_word_detector:
            asyncio.create_task(self.wake_word_loop())

        self.state = ToyState.IDLE
        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.IDLE)

        return True

    async def on_button_press(self):
        if self.state != ToyState.IDLE:
            logger.warning(f"Button pressed in state {self.state}, ignoring")
            return
        logger.info("Button pressed - starting recording")
        await self.start_recording()

    async def on_button_release(self, duration: float = 0.0):
        if self.state != ToyState.LISTENING:
            return
        logger.info("Button released (%.2fs) - stopping recording", duration)
        await self.stop_recording()

    async def start_recording(self):
        if self.is_recording:
            return
        self.state = ToyState.LISTENING
        self.is_recording = True
        self.audio_buffer = []
        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.LISTENING)
        await self.connection.start_streaming()
        self.recording_task = asyncio.create_task(self.record_audio())

    async def stop_recording(self):
        if not self.is_recording:
            return
        self.is_recording = False
        self.state = ToyState.PROCESSING
        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.PROCESSING)

        if self.recording_task:
            try:
                await asyncio.wait_for(self.recording_task, timeout=1.0)
            except (asyncio.TimeoutError, asyncio.CancelledError):
                self.recording_task.cancel()
                try:
                    await self.recording_task
                except asyncio.CancelledError:
                    pass

        await asyncio.sleep(0.1)

        # Send final marker
        if self.connection.config.audio_format == 'opus':
            if self.audio_buffer:
                audio_data = np.concatenate(self.audio_buffer)
                compressed = self.opus_codec.encode_chunk(audio_data.tobytes())
                if compressed:
                    await self.connection.send_audio_chunk(compressed, is_final=True)
                else:
                    await self.connection.send_audio_chunk(b"", is_final=True)
            else:
                await self.connection.send_audio_chunk(b"", is_final=True)
        else:
            await self.connection.send_audio_chunk(b"", is_final=True)
            logger.info("Sent final audio marker for PCM16 stream")

        await self.connection.stop_streaming()

        # Fallback trigger if no text_response arrives
        asyncio.create_task(self._monitor_audio_queue())

    async def record_audio(self):
        try:
            while self.is_recording:
                audio_chunk = await self.audio_manager.read_chunk()
                if audio_chunk is None:
                    continue

                # Debug mic chunk sizes
                if not hasattr(self, '_rec_chunk_count'):
                    self._rec_chunk_count = 0
                self._rec_chunk_count += 1
                if self._rec_chunk_count <= 3 or self._rec_chunk_count % 50 == 0:
                    try:
                        size_bytes = getattr(audio_chunk, 'nbytes', len(audio_chunk))
                    except Exception:
                        size_bytes = None
                    logger.debug(f"MIC_CHUNK: idx={self._rec_chunk_count}, size={size_bytes} bytes")

                # Buffer (for final opus send)
                self.audio_buffer.append(audio_chunk)

                if self.connection.config.audio_format == 'opus':
                    compressed = self.opus_codec.encode_chunk(audio_chunk.tobytes())
                    if compressed:
                        await self.connection.send_audio_chunk(compressed, is_final=False)
                else:
                    await self.connection.send_audio_chunk(audio_chunk.tobytes(), is_final=False)

                await asyncio.sleep(0.01)

        except asyncio.CancelledError:
            logger.debug("Recording task cancelled")
        except Exception as e:
            logger.error(f"Recording error: {e}")
            self.is_recording = False

    async def play_audio_from_queue(self):
        """Play audio chunks from the connection's queue (handles format/endianness/resampling)."""
        if getattr(self, "_audio_playback_running", False):
            logger.warning("Audio playback already running; ignoring duplicate trigger")
            return
        
        # Clear any stale audio from previous sessions
        while not self.connection.audio_queue.empty():
            try:
                self.connection.audio_queue.get_nowait()
            except asyncio.QueueEmpty:
                break
        logger.debug("Cleared audio queue before starting new playback")
        
        self._audio_playback_running = True

        logger.info("PLAYBACK: Starting audio playback from queue")
        self.state = ToyState.SPEAKING
        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.SPEAKING)

        try:
            frame_bytes = self.audio_manager.config.chunk_size * 2  # 16-bit samples

            def _resample_pcm16(pcm_bytes: bytes, src_rate: int, dst_rate: int) -> bytes:
                if not pcm_bytes or src_rate == dst_rate:
                    return pcm_bytes
                try:
                    pcm = np.frombuffer(pcm_bytes, dtype=np.int16).astype(np.float32)
                    ratio = float(dst_rate) / float(src_rate)
                    new_len = int(max(1, round(len(pcm) * ratio)))
                    x = np.linspace(0, len(pcm) - 1, num=len(pcm), dtype=np.float32)
                    xi = np.linspace(0, len(pcm) - 1, num=new_len, dtype=np.float32)
                    yi = np.interp(xi, x, pcm)
                    return np.clip(yi, -32768, 32767).astype(np.int16).tobytes()
                except Exception as _e:
                    logger.debug(f"Resampler error (falling back to original rate): {_e}")
                    return pcm_bytes

            async def audio_chunk_generator():
                pcm_accum = bytearray()
                consecutive_timeouts = 0
                max_timeouts = 5
                output_rate = self.audio_manager.config.sample_rate

                while True:
                    chunk = await self.connection.get_audio_chunk(timeout=5.0)
                    if not chunk:
                        consecutive_timeouts += 1
                        if consecutive_timeouts >= max_timeouts:
                            logger.warning("Max timeouts waiting for audio; ending stream")
                            if len(pcm_accum) > 0:
                                yield {'data': bytes(pcm_accum), 'is_final': False}
                                pcm_accum.clear()
                            yield {'data': b'', 'is_final': True}
                            break
                        continue
                    consecutive_timeouts = 0

                    audio_data = chunk.get('data', b'')
                    metadata = chunk.get('metadata', {})
                    audio_format = metadata.get('format', 'opus')
                    src_rate = int(metadata.get('sampleRate', 16000))
                    channels = int(metadata.get('channels', 1))
                    endian = metadata.get('endian', 'le')
                    is_final = metadata.get('isFinal', False)

                    pcm_data = b''
                    if audio_data:
                        if audio_format == 'pcm16':
                            # Downmix / endianness handling
                            if channels == 2 or endian == 'be' or os.getenv('PCM_SWAP_BYTES', 'false').lower() == 'true':
                                try:
                                    dtype = '<i2' if endian == 'le' else '>i2'
                                    arr = np.frombuffer(audio_data, dtype=dtype)
                                    if channels == 2:
                                        if len(arr) % 2 == 1:
                                            arr = arr[:-1]
                                        arr = arr.reshape(-1, 2)
                                        arr = arr.mean(axis=1)
                                    if os.getenv('PCM_SWAP_BYTES', 'false').lower() == 'true':
                                        arr = arr.byteswap()
                                    arr = np.clip(arr, -32768, 32767).astype(np.int16)
                                    pcm_data = arr.tobytes()
                                except Exception as _e:
                                    logger.warning(f"PCM downmix/endianness adjust failed: {_e}; using raw bytes")
                                    pcm_data = audio_data
                            else:
                                pcm_data = audio_data
                        elif audio_format == 'opus':
                            pcm_data = self.opus_codec.decode_chunk(audio_data) or b''
                        else:
                            logger.warning(f"Unsupported audio format: {audio_format}")
                            pcm_data = b''

                        # Resample if needed
                        if pcm_data and src_rate and output_rate and src_rate != output_rate:
                            pcm_data = _resample_pcm16(pcm_data, src_rate, output_rate)

                    try:
                        logger.debug(f"DECODED_CHUNK: fmt={audio_format}, src_rate={src_rate}, channels={channels}, endian={endian}, pcm_len={len(pcm_data)}, is_final={is_final}")
                    except Exception:
                        pass

                    if pcm_data:
                        pcm_accum.extend(pcm_data)
                        if len(pcm_accum) % 2 == 1:
                            pcm_accum.append(0)
                        while len(pcm_accum) >= frame_bytes:
                            yield {'data': bytes(pcm_accum[:frame_bytes]), 'is_final': False}
                            del pcm_accum[:frame_bytes]

                    if is_final:
                        if len(pcm_accum) > 0:
                            yield {'data': bytes(pcm_accum), 'is_final': False}
                            pcm_accum.clear()
                        yield {'data': b'', 'is_final': True}
                        break

            try:
                active = self.hardware.output_stream.is_active()
            except Exception:
                active = None
            logger.info(f"PLAYBACK_LOOP: Starting. Output stream active: {active}")
            logger.info("PLAYBACK: Starting audio_manager.play_audio_stream()")
            await self.audio_manager.play_audio_stream(audio_chunk_generator())
            logger.info("PLAYBACK: Finished audio_manager.play_audio_stream()")

        except Exception as e:
            logger.error(f"Error processing audio stream: {e}", exc_info=True)
        finally:
            # Always reset the playback flag and state
            self._audio_playback_running = False
            self.state = ToyState.IDLE
            if self.led_controller:
                try:
                    await self.led_controller.set_pattern(LEDPattern.IDLE)
                except Exception as e:
                    logger.error(f"Failed to set LED pattern: {e}")

    async def handle_config_update(self, message: Dict[str, Any]):
        config = message.get('config', {})
        logger.info(f"Configuration update: {config}")
        if 'toyId' in config:
            self.config.TOY_ID = config['toyId']

    async def handle_error(self, message: Dict[str, Any]):
        error = message.get('error', 'Unknown error')
        logger.error(f"Server error: {error}")
        self.state = ToyState.ERROR
        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.ERROR)
        await asyncio.sleep(2)
        self.state = ToyState.IDLE
        if self.led_controller:
            await self.led_controller.set_pattern(LEDPattern.IDLE)

    async def handle_toy_state(self, message: Dict[str, Any]):
        state = message.get('state')
        if state:
            logger.info(f"Toy state update: {state}")

    async def handle_audio_ready(self, message: Dict[str, Any]):
        trigger_source = message.get('trigger', 'unknown')
        logger.info(f"AUDIO_READY: Handler triggered from {trigger_source}")
        if not getattr(self, "_audio_playback_running", False):
            queue_size = self.connection.audio_queue.qsize() if hasattr(self.connection, 'audio_queue') else 0
            logger.info(f"Starting playback from audio_ready handler (queue size: {queue_size})")
            asyncio.create_task(self.play_audio_from_queue())
        else:
            logger.debug("Playback already running, ignoring audio_ready")

    async def handle_text_response(self, message: Dict[str, Any]):
        logger.info("HANDLER: handle_text_response called")
        payload = message.get('payload', {})
        text = payload.get('text', '')
        if text:
            logger.info(f"Received text response: {text[:50]}...")
        else:
            logger.warning("Received text_response with empty text")
        
        # Check if we need to reset a stuck playback state
        if getattr(self, "_audio_playback_running", False):
            # Check if audio_manager is actually playing
            if not self.audio_manager.is_playing:
                logger.warning("Playback flag was stuck, resetting it")
                self._audio_playback_running = False
        
        logger.info("TRIGGER: Starting play_audio_from_queue task from text_response")
        if not getattr(self, "_audio_playback_running", False):
            asyncio.create_task(self.play_audio_from_queue())
        else:
            logger.debug("Audio playback already running")

    async def _monitor_audio_queue(self):
        await asyncio.sleep(0.5)
        if getattr(self, "_audio_playback_running", False):
            return
        if self.connection.audio_queue.qsize() > 0:
            logger.info("Audio chunks detected in queue, starting playback")
            await self.play_audio_from_queue()

    async def wake_word_loop(self):
        logger.info("Wake word detection started")
        while True:
            try:
                if self.wake_word_detector and self.state == ToyState.IDLE:
                    detected = await self.wake_word_detector.detect()
                    if detected:
                        logger.info("Wake word detected!")
                        await self.start_recording()
                        await asyncio.sleep(5)
                        if self.is_recording:
                            await self.stop_recording()
                await asyncio.sleep(0.1)
            except Exception as e:
                logger.error(f"Wake word detection error: {e}")
                await asyncio.sleep(1)

    async def run(self):
        logger.info("Starting Pommai client...")
        if not await self.initialize():
            logger.error("Initialization failed")
            return
        try:
            while True:
                if not self.connection.is_connected():
                    if self.state != ToyState.OFFLINE:
                        self.state = ToyState.OFFLINE
                        if self.led_controller:
                            await self.led_controller.set_pattern(LEDPattern.OFFLINE)
                    await asyncio.sleep(5)
                    if await self.connection.connect():
                        self.state = ToyState.IDLE
                        if self.led_controller:
                            await self.led_controller.set_pattern(LEDPattern.IDLE)
                await asyncio.sleep(0.1)
        except KeyboardInterrupt:
            logger.info("Shutting down...")
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
        finally:
            await self.cleanup()

    async def cleanup(self):
        logger.info("Cleaning up...")
        if self.is_recording:
            await self.stop_recording()
        await self.connection.disconnect()
        if self.sync_manager:
            try:
                await self.sync_manager.stop()
            except Exception:
                pass
        if self.button_handler:
            try:
                self.button_handler.cleanup()
            except Exception:
                pass
        if self.led_controller:
            try:
                await self.led_controller.set_pattern(LEDPattern.IDLE)
            except Exception:
                pass
        try:
            await self.audio_manager.cleanup()
            self.hardware.cleanup()
        except Exception:
            pass
        logger.info("Cleanup complete")


async def main():
    config = Config()
    client = PommaiClientFastRTC(config)
    await client.run()


if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="src/scripts/diagnose.sh">
#!/bin/bash
#
# Pommai Diagnostic Script
# Helps diagnose common issues with the Pommai client
#

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}Pommai Diagnostic Tool${NC}"
echo "===================="
echo ""
echo "Running system diagnostics..."
echo ""

# Function to check status
check_status() {
    if [ $1 -eq 0 ]; then
        echo -e "${GREEN}‚úì${NC} $2"
    else
        echo -e "${RED}‚úó${NC} $2"
    fi
}

# System Information
echo -e "${YELLOW}System Information:${NC}"
echo -n "Hostname: "; hostname
echo -n "OS: "; cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2
echo -n "Kernel: "; uname -r
echo -n "Architecture: "; uname -m
echo -n "Memory: "; free -h | grep Mem | awk '{print $2 " total, " $3 " used"}'
echo -n "Disk: "; df -h / | tail -1 | awk '{print $2 " total, " $3 " used (" $5 ")"}'
echo ""

# Check Hardware
echo -e "${YELLOW}Hardware Checks:${NC}"

# Check if running on Raspberry Pi
if grep -q "Raspberry Pi" /proc/cpuinfo; then
    MODEL=$(cat /proc/cpuinfo | grep "Model" | cut -d':' -f2 | xargs)
    check_status 0 "Raspberry Pi detected: $MODEL"
else
    check_status 1 "Not running on Raspberry Pi"
fi

# Check I2C
if lsmod | grep -q i2c_dev; then
    check_status 0 "I2C kernel module loaded"
else
    check_status 1 "I2C kernel module not loaded"
fi

# Check for ReSpeaker
if aplay -l 2>/dev/null | grep -q "seeed"; then
    check_status 0 "ReSpeaker audio device detected"
else
    check_status 1 "ReSpeaker audio device not found"
fi

# Check GPIO access
if [ -e /sys/class/gpio ]; then
    check_status 0 "GPIO interface available"
else
    check_status 1 "GPIO interface not available"
fi

echo ""

# Check Software Dependencies
echo -e "${YELLOW}Software Dependencies:${NC}"

# Python version
if command -v python3 &> /dev/null; then
    PY_VERSION=$(python3 --version 2>&1 | cut -d' ' -f2)
    check_status 0 "Python installed ($PY_VERSION)"
else
    check_status 1 "python3 not found"
fi

# Check for required system packages
PACKAGES=("portaudio19-dev" "libopus0" "sqlite3" "alsa-utils")
for pkg in "${PACKAGES[@]}"; do
    if dpkg -l | grep -q "^ii  $pkg"; then
        check_status 0 "$pkg installed"
    else
        check_status 1 "$pkg not installed"
    fi
done

echo ""

# Check Pommai Installation
echo -e "${YELLOW}Pommai Installation:${NC}"

POMMAI_HOME="/home/pommai"
POMMAI_APP_DIR="$POMMAI_HOME/app"

# Check user exists
if id "pommai" &>/dev/null; then
    check_status 0 "Pommai user exists"
    # Check user groups
    GROUPS=$(groups pommai 2>/dev/null | cut -d':' -f2)
    echo "  User groups:$GROUPS"
else
    check_status 1 "Pommai user not found"
fi

# Check directories
DIRS=("$POMMAI_APP_DIR" "$POMMAI_HOME/models" "$POMMAI_HOME/audio_responses" "/var/log/pommai")
for dir in "${DIRS[@]}"; do
    if [ -d "$dir" ]; then
        check_status 0 "Directory exists: $dir"
    else
        check_status 1 "Directory missing: $dir"
    fi
done

# Check main application file (FastRTC client)
if [ -f "$POMMAI_APP_DIR/pommai_client_fastrtc.py" ]; then
    check_status 0 "FastRTC client found"
elif [ -f "$POMMAI_APP_DIR/pommai_client.py" ]; then
    check_status 0 "Legacy client found"
else
    check_status 1 "Client entrypoint missing"
fi

# Check virtual environment
if [ -d "$POMMAI_APP_DIR/venv" ]; then
    check_status 0 "Python virtual environment exists"
    
    # Check installed packages
    if [ -f "$POMMAI_APP_DIR/venv/bin/pip" ]; then
        echo "  Checking Python packages..."
        REQUIRED_PACKAGES=("websockets" "pyaudio" "RPi.GPIO" "vosk" "aiofiles")
        for pkg in "${REQUIRED_PACKAGES[@]}"; do
            if "$POMMAI_APP_DIR/venv/bin/pip" show $pkg &>/dev/null; then
                echo -e "  ${GREEN}‚úì${NC} $pkg installed"
            else
                echo -e "  ${RED}‚úó${NC} $pkg not installed"
            fi
        done
    fi
else
    check_status 1 "Python virtual environment not found"
fi

# Check Vosk model
if [ -d "$POMMAI_HOME/models/vosk-model-small-en-us-0.15" ]; then
    check_status 0 "Vosk model downloaded"
else
    check_status 1 "Vosk model not found"
fi

echo ""

# Check Configuration
echo -e "${YELLOW}Configuration:${NC}"

if [ -f "$POMMAI_APP_DIR/.env" ]; then
    check_status 0 ".env file exists"
    
    # Load env (no echo of secrets)
    set -a; source "$POMMAI_APP_DIR/.env"; set +a

    # Check FastRTC vars with legacy fallbacks (without showing values)
    if [ -n "$FASTRTC_GATEWAY_URL" ]; then
        check_status 0 "FASTRTC_GATEWAY_URL configured"
    elif [ -n "$CONVEX_URL" ]; then
        echo -e "${YELLOW}Using legacy CONVEX_URL; set FASTRTC_GATEWAY_URL in .env${NC}"
        check_status 0 "CONVEX_URL present (legacy)"
    else
        check_status 1 "FASTRTC_GATEWAY_URL not set"
    fi

    if [ -n "$AUTH_TOKEN" ]; then
        check_status 0 "AUTH_TOKEN configured"
    elif [ -n "$POMMAI_USER_TOKEN" ]; then
        echo -e "${YELLOW}Using legacy POMMAI_USER_TOKEN; set AUTH_TOKEN in .env${NC}"
        check_status 0 "POMMAI_USER_TOKEN present (legacy)"
    else
        check_status 1 "AUTH_TOKEN not set"
    fi

    if [ -n "$TOY_ID" ]; then
        check_status 0 "TOY_ID configured"
    elif [ -n "$POMMAI_TOY_ID" ]; then
        echo -e "${YELLOW}Using legacy POMMAI_TOY_ID; set TOY_ID in .env${NC}"
        check_status 0 "POMMAI_TOY_ID present (legacy)"
    else
        check_status 1 "TOY_ID not set"
    fi
else
    check_status 1 ".env file not found"
fi

echo ""

# Check Service Status
echo -e "${YELLOW}Service Status:${NC}"

if systemctl is-enabled pommai &>/dev/null; then
    check_status 0 "Pommai service is enabled"
else
    check_status 1 "Pommai service is not enabled"
fi

if systemctl is-active --quiet pommai; then
    check_status 0 "Pommai service is running"
    
    # Get service details
    echo "  Service uptime: $(systemctl show pommai --property=ActiveEnterTimestamp | cut -d'=' -f2-)"
    
    # Check recent logs for errors
    ERROR_COUNT=$(journalctl -u pommai --since "1 hour ago" 2>/dev/null | grep -c ERROR || true)
    if [ $ERROR_COUNT -gt 0 ]; then
        echo -e "  ${YELLOW}Warning: $ERROR_COUNT errors in last hour${NC}"
    fi
else
    check_status 1 "Pommai service is not running"
    
    # Show last error if service failed
    if systemctl is-failed --quiet pommai; then
        echo -e "  ${RED}Service failed. Last error:${NC}"
        journalctl -u pommai -n 5 --no-pager | sed 's/^/  /'
    fi
fi

echo ""

# Check Network Connectivity
echo -e "${YELLOW}Network Connectivity:${NC}"

# Check internet connection
if ping -c 1 -W 2 google.com &>/dev/null; then
    check_status 0 "Internet connection available"
else
    check_status 1 "No internet connection"
fi

# Check if we can resolve and reach FastRTC gateway host
EFFECTIVE_WS_URL="${FASTRTC_GATEWAY_URL:-$CONVEX_URL}"
if [ -n "$EFFECTIVE_WS_URL" ]; then
    GATEWAY_HOST=$(echo "$EFFECTIVE_WS_URL" | sed -E 's|^wss?://([^/:]+).*|\1|')
    if [ -n "$GATEWAY_HOST" ]; then
        if host "$GATEWAY_HOST" &>/dev/null; then
            check_status 0 "DNS resolution ok for: $GATEWAY_HOST"
        else
            check_status 1 "Cannot resolve host: $GATEWAY_HOST"
        fi
        if ping -c 1 -W 2 "$GATEWAY_HOST" &>/dev/null; then
            check_status 0 "Gateway reachable: $GATEWAY_HOST"
        else
            check_status 1 "Gateway not reachable: $GATEWAY_HOST"
        fi
    fi
fi

echo ""

# Check Audio System
echo -e "${YELLOW}Audio System:${NC}"

# Check ALSA
if command -v aplay &> /dev/null; then
    check_status 0 "ALSA installed"
    
    # List audio devices
    echo "  Playback devices:"
    aplay -l 2>/dev/null | grep "^card" | sed 's/^/    /'
    
    echo "  Capture devices:"
    arecord -l 2>/dev/null | grep "^card" | sed 's/^/    /'
else
    check_status 1 "ALSA not installed"
fi

echo ""

# Performance Metrics
echo -e "${YELLOW}Current Performance:${NC}"
echo -n "CPU Usage: "
top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1"%"}'

echo -n "Memory Usage: "
free | grep Mem | awk '{print int($3/$2 * 100) "%"}'

echo -n "Temperature: "
if [ -f /sys/class/thermal/thermal_zone0/temp ]; then
    TEMP=$(cat /sys/class/thermal/thermal_zone0/temp)
    echo "$((TEMP/1000))¬∞C"
else
    echo "N/A"
fi

echo ""

# Summary
echo -e "${BLUE}Diagnostic Summary:${NC}"
echo "=================="

# Count issues
ISSUES=0
[ ! -f "$POMMAI_APP_DIR/.env" ] && ((ISSUES++))
[ -z "$AUTH_TOKEN" ] && [ -z "$POMMAI_USER_TOKEN" ] && ((ISSUES++))
[ -z "$TOY_ID" ] && [ -z "$POMMAI_TOY_ID" ] && ((ISSUES++))
systemctl is-active --quiet pommai || ((ISSUES++))

if [ $ISSUES -eq 0 ]; then
    echo -e "${GREEN}All checks passed! System appears to be configured correctly.${NC}"
else
    echo -e "${YELLOW}Found $ISSUES potential issues. Please review the output above.${NC}"
    echo ""
    echo "Common fixes:"
    echo "1. Complete configuration: sudo nano $POMMAI_APP_DIR/.env"
    echo "2. Start service: sudo systemctl start pommai"
    echo "3. Check logs: sudo journalctl -u pommai -f"
    echo "4. Re-run setup: sudo /home/pommai/scripts/setup.sh (if present)"
fi

echo ""
echo "For more help, visit: https://docs.pommai.com/troubleshooting"
</file>

<file path="src/scripts/setup.sh">
#!/bin/bash
#
# Pommai Smart Toy Raspberry Pi Setup Script
# This script sets up the Pommai client on a Raspberry Pi Zero 2W
#

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# Configuration
POMMAI_USER="pommai"
POMMAI_HOME="/home/pommai"
POMMAI_APP_DIR="$POMMAI_HOME/app"
SCRIPTS_DIR="$POMMAI_HOME/scripts"
VOSK_MODEL_DIR="$POMMAI_HOME/models"
AUDIO_RESPONSES_DIR="$POMMAI_HOME/audio_responses"
LOG_DIR="/var/log/pommai"
# Playback profile: 'seeed' (ALSA direct to ReSpeaker) or 'bluealsa' (Bluetooth via BlueALSA)
AUDIO_PLAYBACK_PROFILE=${AUDIO_PLAYBACK_PROFILE:-seeed}
# Raspberry Pi OS Bookworm uses /boot/firmware/config.txt. Fallback to /boot/config.txt when present.
BOOT_CONFIG="/boot/firmware/config.txt"
if [ -f "/boot/config.txt" ]; then
  BOOT_CONFIG="/boot/config.txt"
fi

echo -e "${GREEN}Pommai Smart Toy Setup Script${NC}"
echo "=============================="
echo ""

# Check if running on Raspberry Pi
if ! grep -q "Raspberry Pi" /proc/cpuinfo; then
    echo -e "${YELLOW}Warning: This script is designed for Raspberry Pi${NC}"
    read -p "Continue anyway? (y/N) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi

# Check if running as root
if [[ $EUID -ne 0 ]]; then
   echo -e "${RED}This script must be run as root${NC}" 
   exit 1
fi

echo -e "${GREEN}Step 1: System Updates${NC}"
apt-get update
apt-get upgrade -y

echo -e "${GREEN}Step 2: Installing System Dependencies${NC}"
apt-get install -y \
    python3 \
    python3-venv \
    python3-pip \
    git \
    portaudio19-dev \
    libatlas-base-dev \
    libopus0 \
    libopus-dev \
    sqlite3 \
    wget \
    unzip \
    alsa-utils \
    i2c-tools

echo -e "${GREEN}Step 3: Creating Pommai User${NC}"
if ! id "$POMMAI_USER" &>/dev/null; then
    useradd -m -s /bin/bash $POMMAI_USER
    usermod -aG audio,gpio,i2c,spi $POMMAI_USER
    echo -e "${GREEN}Created user: $POMMAI_USER${NC}"
else
    echo -e "${YELLOW}User $POMMAI_USER already exists${NC}"
fi

echo -e "${GREEN}Step 4: Setting up Directory Structure${NC}"
mkdir -p "$POMMAI_APP_DIR" "$VOSK_MODEL_DIR" "$AUDIO_RESPONSES_DIR" "$SCRIPTS_DIR" "$LOG_DIR" /tmp/pommai

# Set permissions
chown -R $POMMAI_USER:$POMMAI_USER "$POMMAI_HOME"
chown -R $POMMAI_USER:$POMMAI_USER "$LOG_DIR"
chmod 755 "$LOG_DIR"

echo -e "${GREEN}Step 5: Enabling Hardware Interfaces${NC}"
# Enable I2C for ReSpeaker HAT
if ! grep -q "^dtparam=i2c_arm=on" "$BOOT_CONFIG"; then
    echo "dtparam=i2c_arm=on" >> "$BOOT_CONFIG"
    echo -e "${GREEN}Enabled I2C interface${NC}"
fi

# Enable SPI
if ! grep -q "^dtparam=spi=on" "$BOOT_CONFIG"; then
    echo "dtparam=spi=on" >> "$BOOT_CONFIG"
    echo -e "${GREEN}Enabled SPI interface${NC}"
fi

# Add device tree overlay for ReSpeaker
if ! grep -q "^dtoverlay=seeed-2mic-voicecard" "$BOOT_CONFIG"; then
    echo "dtoverlay=seeed-2mic-voicecard" >> "$BOOT_CONFIG"
    echo -e "${GREEN}Added ReSpeaker 2-Mics HAT overlay${NC}"
fi

echo -e "${GREEN}Step 6: Installing ReSpeaker Drivers${NC}"
cd /tmp
if [ ! -d "seeed-voicecard" ]; then
    git clone https://github.com/respeaker/seeed-voicecard.git
    cd seeed-voicecard
    ./install.sh
else
    echo -e "${YELLOW}ReSpeaker drivers already downloaded${NC}"
fi

echo -e "${GREEN}Step 7: Downloading Vosk Model${NC}"
cd "$VOSK_MODEL_DIR"
if [ ! -d "vosk-model-small-en-us-0.15" ]; then
    wget -q https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
    unzip -q vosk-model-small-en-us-0.15.zip
    rm -f vosk-model-small-en-us-0.15.zip
    echo -e "${GREEN}Downloaded Vosk model${NC}"
else
    echo -e "${YELLOW}Vosk model already exists${NC}"
fi

echo -e "${GREEN}Step 8: Setting up Python Virtual Environment${NC}"
cd "$POMMAI_APP_DIR"
sudo -u "$POMMAI_USER" python3 -m venv "$POMMAI_APP_DIR/venv"

echo -e "${GREEN}Step 9: Installing Python Dependencies${NC}"
# Upgrade pip and wheel inside venv (as pommai user)
sudo -u "$POMMAI_USER" "$POMMAI_APP_DIR/venv/bin/pip" install --upgrade pip setuptools wheel

# Install dependencies either from requirements.txt (if present) or a known set
if [ -f "$POMMAI_APP_DIR/requirements.txt" ]; then
  sudo -u "$POMMAI_USER" "$POMMAI_APP_DIR/venv/bin/pip" install -r "$POMMAI_APP_DIR/requirements.txt"
else
  sudo -u "$POMMAI_USER" "$POMMAI_APP_DIR/venv/bin/pip" install \
    websockets==12.0 \
    pyaudio==0.2.14 \
    RPi.GPIO==0.7.1 \
    vosk==0.3.45 \
    opuslib==3.0.1 \
    aiofiles==23.2.1 \
    python-dotenv==1.0.0 \
    aiosqlite==0.19.0 \
    numpy==1.24.3 \
    requests==2.31.0 \
    psutil==5.9.8
fi

echo -e "${GREEN}Step 10: Configuring Audio (ALSA)${NC}"
# Set default audio device
if [ "$AUDIO_PLAYBACK_PROFILE" = "bluealsa" ]; then
  # Route playback to BlueALSA (Bluetooth) and capture to ReSpeaker
  cat > /etc/asound.conf << 'EOF'
pcm.!default {
    type asym
    playback.pcm {
        type plug
        slave.pcm "bluealsa"
    }
    capture.pcm {
        type plug
        slave.pcm "hw:seeed2micvoicec,0"
    }
}

ctl.!default {
    type hw
    card seeed2micvoicec
}
EOF
  echo -e "${YELLOW}Configured BlueALSA for playback; ensure your speaker is paired and set as default sink.${NC}"
else
  # Default: direct ALSA to ReSpeaker
  cat > /etc/asound.conf << 'EOF'
pcm.!default {
    type asym
    playback.pcm {
        type plug
        slave.pcm "hw:seeed2micvoicec,0"
    }
    capture.pcm {
        type plug
        slave.pcm "hw:seeed2micvoicec,0"
    }
}

ctl.!default {
    type hw
    card seeed2micvoicec
}
EOF
fi

# Test audio (non-blocking)
echo -e "${YELLOW}Testing audio setup...${NC}"
if ! timeout 2 speaker-test -t sine -f 1000 -c 2 >/dev/null 2>&1; then
  echo -e "${YELLOW}Audio test did not complete. Verify hardware connections if audio fails later.${NC}"
fi

echo -e "${GREEN}Step 11: Creating Default Audio Responses${NC}"
mkdir -p "$AUDIO_RESPONSES_DIR"
cd "$AUDIO_RESPONSES_DIR"
# Placeholder files (replace with real audio in production)
touch wake_ack.wav toy_switch.wav error.wav offline_mode.wav

echo -e "${GREEN}Step 12: Setting up Environment File${NC}"
cat > "$POMMAI_APP_DIR/.env" << EOF
# Pommai Environment Configuration (FastRTC-first)
FASTRTC_GATEWAY_URL=wss://your-fastrtc-gateway.example.com/ws
AUTH_TOKEN=
DEVICE_ID=
TOY_ID=

VOSK_MODEL_PATH=$VOSK_MODEL_DIR/vosk-model-small-en-us-0.15
CACHE_DB_PATH=/tmp/pommai_cache.db
AUDIO_RESPONSES_PATH=$AUDIO_RESPONSES_DIR
EOF
chown "$POMMAI_USER:$POMMAI_USER" "$POMMAI_APP_DIR/.env"
chmod 600 "$POMMAI_APP_DIR/.env"

echo -e "${GREEN}Step 13: Creating Systemd Service${NC}"
cat > /etc/systemd/system/pommai.service << EOF
[Unit]
Description=Pommai Smart Toy Client
After=network-online.target sound.target
Wants=network-online.target

[Service]
Type=simple
User=$POMMAI_USER
Group=$POMMAI_USER
WorkingDirectory=$POMMAI_APP_DIR
Environment="PATH=$POMMAI_APP_DIR/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Environment="PYTHONPATH=$POMMAI_APP_DIR"
ExecStart=$POMMAI_APP_DIR/venv/bin/python $POMMAI_APP_DIR/pommai_client_fastrtc.py
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal
SyslogIdentifier=pommai

# Security settings
NoNewPrivileges=true
PrivateTmp=false
ProtectHome=false
ProtectSystem=false
ReadWritePaths=$POMMAI_HOME /tmp /var/log/pommai

# Resource limits for Pi Zero 2W
MemoryMax=200M
CPUQuota=60%

[Install]
WantedBy=multi-user.target
EOF

# Reload systemd
systemctl daemon-reload

echo -e "${GREEN}Step 14: Optimizing for Raspberry Pi Zero 2W${NC}"
# Disable unnecessary services
systemctl disable bluetooth || true
systemctl disable avahi-daemon || true
systemctl disable triggerhappy || true

# Configure swap (256MB)
if [ ! -f /swapfile ]; then
    dd if=/dev/zero of=/swapfile bs=1M count=256
    chmod 600 /swapfile
    mkswap /swapfile
    swapon /swapfile
    echo "/swapfile none swap sw 0 0" >> /etc/fstab
    echo -e "${GREEN}Created 256MB swap file${NC}"
fi

# Optimize memory usage
if ! grep -q "vm.swappiness=10" /etc/sysctl.conf; then
  echo "vm.swappiness=10" >> /etc/sysctl.conf
fi
sysctl -p || true

echo -e "${GREEN}Step 15: Setting up Log Rotation${NC}"
cat > /etc/logrotate.d/pommai << EOF
/var/log/pommai/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0644 $POMMAI_USER $POMMAI_USER
    sharedscripts
    postrotate
        systemctl reload pommai >/dev/null 2>&1 || true
    endscript
}
EOF

echo -e "${GREEN}Step 16: Final Setup${NC}"
# If running from repo directory with src/, copy Python sources
if [ -d "src" ]; then
    cp src/*.py "$POMMAI_APP_DIR/" 2>/dev/null || true
    chown -R "$POMMAI_USER:$POMMAI_USER" "$POMMAI_APP_DIR"
    echo -e "${GREEN}Copied application files to $POMMAI_APP_DIR${NC}"
else
    echo -e "${YELLOW}No src/ directory found. Ensure application files are placed in $POMMAI_APP_DIR${NC}"
fi

echo ""
echo -e "${GREEN}Setup Complete!${NC}"
echo "=============================="
echo ""
echo "Next steps:"
echo "1. Edit $POMMAI_APP_DIR/.env with your configuration (set AUTH_TOKEN, FASTRTC_GATEWAY_URL, TOY_ID, DEVICE_ID)"
echo "2. Enable and start the service:"
echo "   sudo systemctl enable pommai"
echo "   sudo systemctl start pommai"
echo "3. Check logs with:"
echo "   sudo journalctl -u pommai -f"
echo ""
echo -e "${YELLOW}Note: A reboot is recommended for hardware changes to take effect${NC}"
echo ""
read -p "Reboot now? (y/N) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    reboot
fi
</file>

<file path="src/scripts/update.sh">
#!/bin/bash
#
# Pommai Client Update Script
# Updates the Pommai client to the latest version
#

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

# Configuration
POMMAI_USER="pommai"
POMMAI_HOME="/home/pommai"
POMMAI_APP_DIR="$POMMAI_HOME/app"
BACKUP_DIR="$POMMAI_HOME/backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

echo -e "${GREEN}Pommai Client Update Script${NC}"
echo "=========================="
echo ""

# Check if running as root
if [[ $EUID -ne 0 ]]; then
   echo -e "${RED}This script must be run as root${NC}" 
   exit 1
fi

# Check if service is running
if systemctl is-active --quiet pommai; then
    SERVICE_WAS_RUNNING=true
    echo -e "${YELLOW}Pommai service is running, will restart after update${NC}"
else
    SERVICE_WAS_RUNNING=false
fi

echo -e "${GREEN}Step 1: Creating Backup${NC}"
mkdir -p $BACKUP_DIR
BACKUP_FILE="$BACKUP_DIR/pommai_backup_$TIMESTAMP.tar.gz"

# Stop service if running
if [ "$SERVICE_WAS_RUNNING" = true ]; then
    echo "Stopping pommai service..."
    systemctl stop pommai
fi

# Create backup
cd $POMMAI_HOME
tar -czf $BACKUP_FILE app/ --exclude='app/venv' --exclude='app/__pycache__' --exclude='app/*.pyc'
echo -e "${GREEN}Backup created: $BACKUP_FILE${NC}"

echo -e "${GREEN}Step 2: Checking for Updates${NC}"
cd /tmp

# If git repo URL is provided as argument, use it
if [ -n "$1" ]; then
    REPO_URL="$1"
else
    REPO_URL="https://github.com/yourusername/pommai.git"
fi

# Clone latest version
if [ -d "pommai_update" ]; then
    rm -rf pommai_update
fi
git clone --depth 1 $REPO_URL pommai_update

echo -e "${GREEN}Step 3: Comparing Versions${NC}"
# Check if there are actual changes
if [ -f "$POMMAI_APP_DIR/pommai_client.py" ] && [ -f "pommai_update/apps/raspberry-pi/src/pommai_client.py" ]; then
    if diff -q "$POMMAI_APP_DIR/pommai_client.py" "pommai_update/apps/raspberry-pi/src/pommai_client.py" >/dev/null; then
        echo -e "${YELLOW}No updates found - client is already up to date${NC}"
        # Cleanup
        rm -rf pommai_update
        
        # Restart service if it was running
        if [ "$SERVICE_WAS_RUNNING" = true ]; then
            systemctl start pommai
        fi
        exit 0
    fi
fi

echo -e "${GREEN}Step 4: Updating Application Files${NC}"
# Update Python files
cp pommai_update/apps/raspberry-pi/src/*.py $POMMAI_APP_DIR/

# Update scripts
if [ -d "pommai_update/apps/raspberry-pi/scripts" ]; then
    cp pommai_update/apps/raspberry-pi/scripts/*.sh $POMMAI_HOME/scripts/
    chmod +x $POMMAI_HOME/scripts/*.sh
fi

# Set correct ownership
chown -R $POMMAI_USER:$POMMAI_USER $POMMAI_APP_DIR

echo -e "${GREEN}Step 5: Updating Dependencies${NC}"
cd $POMMAI_APP_DIR
source venv/bin/activate

# Update pip first
pip install --upgrade pip

# Check if requirements.txt exists and update dependencies
if [ -f "/tmp/pommai_update/apps/raspberry-pi/requirements.txt" ]; then
    echo "Installing updated dependencies..."
    pip install -r /tmp/pommai_update/apps/raspberry-pi/requirements.txt
fi

deactivate

echo -e "${GREEN}Step 6: Updating Configuration${NC}"
# Check for new configuration options
if [ -f "/tmp/pommai_update/apps/raspberry-pi/.env.example" ]; then
    echo -e "${YELLOW}New configuration options may be available${NC}"
    echo "Please review: /tmp/pommai_update/apps/raspberry-pi/.env.example"
    echo "And update your .env file accordingly"
fi

echo -e "${GREEN}Step 7: Database Migration${NC}"
# Run any database migrations
cd $POMMAI_APP_DIR
sudo -u $POMMAI_USER python3 << EOF
import sys
sys.path.insert(0, '.')
from conversation_cache import ConversationCache
import asyncio

async def migrate():
    cache = ConversationCache()
    await cache.initialize()
    print("Database schema updated")

asyncio.run(migrate())
EOF

echo -e "${GREEN}Step 8: Cleaning Up${NC}"
# Remove update files
rm -rf /tmp/pommai_update

# Clear Python cache
find $POMMAI_APP_DIR -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
find $POMMAI_APP_DIR -name "*.pyc" -delete 2>/dev/null || true

echo -e "${GREEN}Step 9: Restarting Service${NC}"
# Reload systemd in case service file was updated
systemctl daemon-reload

# Start service
if [ "$SERVICE_WAS_RUNNING" = true ] || [ "$2" = "--start" ]; then
    systemctl start pommai
    sleep 3
    
    # Check if service started successfully
    if systemctl is-active --quiet pommai; then
        echo -e "${GREEN}Pommai service started successfully${NC}"
    else
        echo -e "${RED}Failed to start pommai service${NC}"
        echo "Check logs with: journalctl -u pommai -n 50"
        exit 1
    fi
fi

echo ""
echo -e "${GREEN}Update Complete!${NC}"
echo "====================="
echo ""
echo "Changes have been applied. To verify:"
echo "1. Check service status: sudo systemctl status pommai"
echo "2. View logs: sudo journalctl -u pommai -f"
echo ""
echo "To rollback if needed:"
echo "1. Stop service: sudo systemctl stop pommai"
echo "2. Restore backup: tar -xzf $BACKUP_FILE -C $POMMAI_HOME"
echo "3. Start service: sudo systemctl start pommai"
echo ""
</file>

<file path="src/sync_manager.py">
#!/usr/bin/env python3
"""
Sync Manager Module for Pommai Smart Toy
Handles background synchronization of cached data to cloud
"""

import asyncio
import logging
import json
import time
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from enum import Enum

from conversation_cache import ConversationCache, SyncStatus, DataType

logger = logging.getLogger(__name__)


class SyncPriority(Enum):
    """Priority levels for sync operations"""
    HIGH = 0      # Safety events, urgent data
    NORMAL = 1    # Regular conversations
    LOW = 2       # Metrics, non-critical data


class SyncManager:
    """Manages background synchronization of cached data to cloud"""
    
    def __init__(self, cache: ConversationCache, connection):
        self.cache = cache
        self.connection = connection
        self.is_running = False
        self.sync_task = None
        self.last_sync_time = datetime.now()
        
        # Sync configuration
        self.sync_interval = 300  # 5 minutes
        self.batch_size = 50
        self.max_retries = 3
        self.retry_delay = 30  # seconds
        
        # Statistics
        self.sync_stats = {
            'successful_syncs': 0,
            'failed_syncs': 0,
            'items_synced': 0,
            'last_error': None
        }
    
    async def start(self):
        """Start the sync manager"""
        if self.is_running:
            logger.warning("Sync manager already running")
            return
        
        self.is_running = True
        self.sync_task = asyncio.create_task(self._sync_loop())
        logger.info("Sync manager started")
    
    async def stop(self):
        """Stop the sync manager"""
        self.is_running = False
        
        if self.sync_task:
            self.sync_task.cancel()
            try:
                await self.sync_task
            except asyncio.CancelledError:
                pass
        
        logger.info("Sync manager stopped")
    
    async def _sync_loop(self):
        """Main sync loop"""
        while self.is_running:
            try:
                # Check if we have network connection
                connected_attr = getattr(self.connection, 'is_connected', None) if self.connection else None
                connected = connected_attr() if callable(connected_attr) else bool(connected_attr)
                if self.connection and connected:
                    await self._perform_sync()
                else:
                    logger.debug("No connection available, skipping sync")
                
                # Wait for next sync interval
                await asyncio.sleep(self.sync_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Sync loop error: {e}")
                self.sync_stats['last_error'] = str(e)
                await asyncio.sleep(self.retry_delay)
    
    async def _perform_sync(self):
        """Perform a sync operation"""
        try:
            logger.info("Starting sync operation")
            start_time = time.time()
            
            # Unified sync using cache.get_unsynced_items()
            synced_count = await self._sync_pending()
            if synced_count:
                self.sync_stats['successful_syncs'] += 1
                self.sync_stats['items_synced'] += synced_count
                self.last_sync_time = datetime.now()
            
            duration = time.time() - start_time
            logger.info(f"Sync completed in {duration:.2f} seconds; items: {synced_count}")
            
        except Exception as e:
            logger.error(f"Sync operation failed: {e}")
            self.sync_stats['failed_syncs'] += 1
            self.sync_stats['last_error'] = str(e)
            raise
    
    async def _sync_pending(self) -> int:
        """Sync pending conversations and offline queue items in a single batch.
        Returns the number of items marked synced on success."""
        items = await self.cache.get_unsynced_items(limit=self.batch_size)
        if not items:
            # Try to sync metrics even if no conversations/offline items
            metrics = await self.cache.get_unsynced_metrics(limit=self.batch_size)
            if not metrics:
                return 0
        else:
            metrics = await self.cache.get_unsynced_metrics(limit=max(0, self.batch_size - len(items)))
        
        # Group items
        conversations = [i['data'] for i in items if i.get('type') == DataType.CONVERSATION.value]
        offline_items = [
            {
                'id': i.get('id'),
                'type': i.get('type'),
                'data': i.get('data'),
                'priority': i.get('priority', 0)
            }
            for i in items if i.get('type') != DataType.CONVERSATION.value
        ]
        
        payload = {
            'type': 'sync_batch',
            'device_id': getattr(getattr(self.connection, 'config', None), 'device_id', None),
            'conversations': conversations,
            'offline': offline_items,
            'metrics': metrics,
        }
        
        # Ensure connectivity
        connected_attr = getattr(self.connection, 'is_connected', None) if self.connection else None
        connected = connected_attr() if callable(connected_attr) else bool(connected_attr)
        if not connected:
            raise RuntimeError('Not connected; cannot sync')
        
        # Send to server; no ack channel is available, so we optimistically mark synced on successful send
        await self.connection.send_message(payload)
        
        # Mark items as synced in cache
        if items:
            await self.cache.mark_synced(items)
        if metrics:
            await self.cache.mark_metrics_synced([m['id'] for m in metrics])
        total = len(items) + len(metrics)
        logger.info(f"Marked {total} items as synced (conversations/offline: {len(items)}, metrics: {len(metrics)})")
        return total
    
    async def force_sync(self):
        """Force an immediate sync"""
        logger.info("Force sync requested")
        
        connected_attr = getattr(self.connection, 'is_connected', None) if self.connection else None
        connected = connected_attr() if callable(connected_attr) else bool(connected_attr)
        if self.connection and connected:
            await self._perform_sync()
        else:
            logger.warning("Cannot force sync - no connection available")
    
    def get_sync_status(self) -> Dict[str, Any]:
        """Get current sync status and statistics"""
        connected_attr = getattr(self.connection, 'is_connected', None) if self.connection else None
        connected = connected_attr() if callable(connected_attr) else bool(connected_attr)
        return {
            'is_running': self.is_running,
            'last_sync_time': self.last_sync_time.isoformat(),
            'next_sync_time': (self.last_sync_time + timedelta(seconds=self.sync_interval)).isoformat(),
            'statistics': self.sync_stats,
            'connection_available': connected
        }
    
    async def sync_toy_configuration(self, toy_id: str):
        """Request and cache the latest toy configuration"""
        try:
            await self.connection.send_message({
                'type': 'get_toy_config',
                'toyId': toy_id
            })
            # Without a generic message queue, we rely on server pushing config_update
            # which the main client handles; return True to indicate request was sent.
            logger.info(f"Requested toy configuration for {toy_id}")
            return True
        except Exception as e:
            logger.error(f"Error syncing toy configuration: {e}")
            return False
</file>

<file path="src/wake_word_detector.py">
#!/usr/bin/env python3
"""
Wake Word Detection Module for Pommai Smart Toy
Implements offline wake word detection using Vosk and processes basic offline commands
"""

import asyncio
import json
import logging
import os
import time
import collections
import wave
import random
from typing import Optional, Callable, Dict, Any, List
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

import numpy as np
from vosk import Model, KaldiRecognizer

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SafetyLevel(Enum):
    """Offline safety level enforcement"""
    STRICT = "strict"      # For kids under 8
    MODERATE = "moderate"  # For kids 8-12
    RELAXED = "relaxed"    # For teens 13+
    CUSTOM = "custom"      # Parent-defined rules


@dataclass
class WakeWordConfig:
    """Configuration for wake word detection"""
    model_path: str = "/opt/pommai/models/vosk-model-small-en-us"
    sample_rate: int = 16000
    chunk_size: int = 512  # Smaller chunks for lower latency
    
    # Wake word settings
    wake_words: List[str] = None
    default_wake_word: str = "hey pommai"
    alternative_wake_words: List[str] = None
    
    # Detection settings
    sensitivity: float = 0.7
    cooldown_seconds: float = 2.0
    buffer_seconds: float = 3.0
    
    # Safety settings
    safety_level: SafetyLevel = SafetyLevel.STRICT
    max_consecutive_unknown: int = 5
    
    def __post_init__(self):
        """Initialize wake words list"""
        if self.wake_words is None:
            self.wake_words = [self.default_wake_word, "pommai"]
        if self.alternative_wake_words is None:
            self.alternative_wake_words = ["hey buddy", "hello pommai"]


class OfflineCommands:
    """Pre-approved offline commands with safe responses"""
    
    COMMANDS = {
        'greeting': {
            'triggers': ['hello', 'hi', 'hey', 'good morning', 'good night'],
            'responses': [
                "Hi there! I'm so happy to see you!",
                "Hello my friend! How are you today?",
                "Hey buddy! Ready to have some fun?"
            ],
            'audio_files': ['greeting_1.opus', 'greeting_2.opus', 'greeting_3.opus'],
            'safety_level': 'all'
        },
        
        'sing_song': {
            'triggers': ['sing', 'song', 'music'],
            'responses': [
                "üéµ Twinkle twinkle little star... üéµ",
                "üéµ The wheels on the bus go round and round... üéµ",
                "üéµ If you're happy and you know it, clap your hands! üéµ"
            ],
            'audio_files': ['twinkle_star.opus', 'wheels_bus.opus', 'happy_clap.opus'],
            'safety_level': 'all'
        },
        
        'tell_joke': {
            'triggers': ['joke', 'funny', 'laugh'],
            'responses': [
                "Why did the teddy bear say no to dessert? Because she was stuffed!",
                "What do you call a dinosaur that crashes his car? Tyrannosaurus Wrecks!",
                "Why can't a bicycle stand up by itself? It's two tired!"
            ],
            'audio_files': ['joke_1.opus', 'joke_2.opus', 'joke_3.opus'],
            'safety_level': 'all'
        },
        
        'goodnight': {
            'triggers': ['goodnight', 'bedtime', 'sleep', 'tired'],
            'responses': [
                "Sweet dreams, my friend! Sleep tight!",
                "Goodnight! I'll be here when you wake up!",
                "Time for bed! Dream of wonderful adventures!"
            ],
            'audio_files': ['goodnight_1.opus', 'goodnight_2.opus', 'goodnight_3.opus'],
            'safety_level': 'all'
        },
        
        'love_response': {
            'triggers': ['love you', 'like you', 'best friend'],
            'responses': [
                "I love you too, buddy! You're the best!",
                "You're my favorite friend in the whole world!",
                "Aww, that makes me so happy! Big hugs!"
            ],
            'audio_files': ['love_1.opus', 'love_2.opus', 'love_3.opus'],
            'safety_level': 'all'
        },
        
        'need_help': {
            'triggers': ['help', 'hurt', 'scared', 'emergency'],
            'responses': [
                "If you need help, please talk to a grown-up right away!",
                "Let's find a parent or teacher to help you!",
                "Grown-ups are great at helping! Let's go find one!"
            ],
            'audio_files': ['help_1.opus', 'help_2.opus', 'help_3.opus'],
            'safety_level': 'all'
        },
        
        'play_game': {
            'triggers': ['play', 'game', 'bored'],
            'responses': [
                "Let's play when we're connected! For now, how about we sing a song?",
                "I need internet to play games, but we can tell jokes!",
                "Games need internet, but I can tell you a story!"
            ],
            'audio_files': ['play_offline_1.opus', 'play_offline_2.opus'],
            'safety_level': 'all'
        }
    }
    
    # Blocked topics for safety
    BLOCKED_TOPICS = {
        'violence': ['fight', 'hit', 'punch', 'weapon', 'gun', 'kill', 'hurt', 'attack'],
        'scary': ['monster', 'ghost', 'nightmare', 'afraid', 'horror', 'scary', 'fear'],
        'inappropriate': ['bad word', 'curse', 'swear', 'stupid', 'shut up'],
        'personal_info': ['address', 'phone', 'school name', 'last name', 'password'],
        'dangerous': ['fire', 'knife', 'poison', 'drug', 'medicine', 'dangerous'],
        'adult_topics': ['alcohol', 'smoking', 'dating', 'kiss', 'marry']
    }
    
    @classmethod
    def get_safe_redirect(cls, category: str) -> str:
        """Get safe redirect response for blocked topics"""
        redirects = {
            'violence': "I only know about fun and happy things! Let's talk about something nice!",
            'scary': "Let's think about happy things instead! What makes you smile?",
            'inappropriate': "Let's use kind words! Can you tell me about your favorite toy?",
            'personal_info': "Let's keep that information safe with your parents!",
            'dangerous': "Safety first! Let's talk to a grown-up about that.",
            'adult_topics': "That's a grown-up topic! How about we sing a song instead?"
        }
        return redirects.get(category, "Let's talk about something else! What's your favorite color?")


class WakeWordDetector:
    """Offline wake word detection and command processing using Vosk"""
    
    def __init__(self, config: Optional[WakeWordConfig] = None):
        self.config = config or WakeWordConfig()
        self.is_active = False
        self.wake_word_callback: Optional[Callable] = None
        self.command_callback: Optional[Callable] = None
        
        # Audio buffer for continuous detection
        self.audio_buffer = collections.deque(
            maxlen=int(self.config.buffer_seconds * self.config.sample_rate / self.config.chunk_size)
        )
        
        # State tracking
        self.last_wake_time = 0
        self.consecutive_unknown = 0
        self.safety_violations = []
        
        # Initialize Vosk
        self._initialize_vosk()
        
    def _initialize_vosk(self):
        """Initialize Vosk model and recognizer"""
        try:
            # Check if model exists
            if not os.path.exists(self.config.model_path):
                raise FileNotFoundError(f"Vosk model not found at {self.config.model_path}")
            
            logger.info(f"Loading Vosk model from {self.config.model_path}")
            self.model = Model(self.config.model_path)
            
            # Create recognizer with limited vocabulary for efficiency
            wake_word_grammar = self._create_wake_word_grammar()
            self.wake_recognizer = KaldiRecognizer(
                self.model,
                self.config.sample_rate,
                wake_word_grammar
            )
            
            # Create full recognizer for command processing
            self.command_recognizer = KaldiRecognizer(
                self.model,
                self.config.sample_rate
            )
            
            # Enable word timestamps
            self.command_recognizer.SetWords(True)
            
            logger.info("Vosk initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize Vosk: {e}")
            raise
    
    def _create_wake_word_grammar(self) -> str:
        """Create grammar for wake word detection"""
        # Include wake words and common false trigger prevention
        wake_words = self.config.wake_words + self.config.alternative_wake_words
        grammar_list = wake_words + ["[unk]"]
        return json.dumps(grammar_list)
    
    async def start_detection(self, 
                            wake_callback: Optional[Callable] = None,
                            command_callback: Optional[Callable] = None):
        """Start continuous wake word detection"""
        self.is_active = True
        self.wake_word_callback = wake_callback
        self.command_callback = command_callback
        
        logger.info(f"Started wake word detection (listening for: {self.config.wake_words})")
        
        # Start detection loop
        asyncio.create_task(self._detection_loop())
    
    async def _detection_loop(self):
        """Main detection loop"""
        while self.is_active:
            try:
                # This will be called with audio chunks from the hardware
                await asyncio.sleep(0.01)  # Placeholder for actual audio processing
                
            except Exception as e:
                logger.error(f"Detection loop error: {e}")
                await asyncio.sleep(0.1)
    
    async def process_audio_chunk(self, audio_data: bytes) -> Optional[Dict[str, Any]]:
        """
        Process audio chunk for wake word detection
        
        Args:
            audio_data: Raw PCM audio data
            
        Returns:
            Detection result or None
        """
        # Add to buffer
        self.audio_buffer.append(audio_data)
        
        # Check if in cooldown
        if time.time() - self.last_wake_time < self.config.cooldown_seconds:
            return None
        
        # Process with wake word recognizer
        if self.wake_recognizer.AcceptWaveform(audio_data):
            result = json.loads(self.wake_recognizer.Result())
            text = result.get('text', '').lower()
            
            # Check for wake word
            for wake_word in self.config.wake_words:
                if wake_word.lower() in text:
                    logger.info(f"Wake word detected: '{text}'")
                    
                    # Update state
                    self.last_wake_time = time.time()
                    self.wake_recognizer.Reset()
                    
                    # Trigger callback
                    if self.wake_word_callback:
                        await self.wake_word_callback()
                    
                    return {
                        'type': 'wake_word',
                        'text': text,
                        'timestamp': self.last_wake_time
                    }
        
        # Also check partial results for responsiveness
        else:
            partial = json.loads(self.wake_recognizer.PartialResult())
            partial_text = partial.get('partial', '').lower()
            
            # Quick check for wake word in partial
            for wake_word in self.config.wake_words:
                if wake_word.lower() in partial_text:
                    logger.debug(f"Potential wake word in partial: '{partial_text}'")
        
        return None
    
    async def process_command(self, audio_data: bytes) -> Dict[str, Any]:
        """
        Process audio for offline command recognition
        
        Args:
            audio_data: Complete audio segment after wake word
            
        Returns:
            Command result with response
        """
        # Reset recognizer for fresh recognition
        self.command_recognizer.Reset()
        
        # Process audio
        self.command_recognizer.AcceptWaveform(audio_data)
        result = json.loads(self.command_recognizer.FinalResult())
        
        text = result.get('text', '').lower()
        confidence = result.get('confidence', 0)
        
        logger.info(f"Command recognition: '{text}' (confidence: {confidence})")
        
        # Check safety first
        safety_result = self._check_safety(text)
        if safety_result['blocked']:
            self._track_safety_violation(safety_result['category'], text)
            return {
                'command': 'blocked',
                'text': text,
                'response': safety_result['response'],
                'audio_file': f"safety/{safety_result['category']}_redirect.opus",
                'blocked': True,
                'category': safety_result['category']
            }
        
        # Try to match offline command
        command_result = self._match_offline_command(text)
        
        if command_result:
            self.consecutive_unknown = 0
            return {
                'command': command_result['command'],
                'text': text,
                'response': command_result['response'],
                'audio_file': command_result['audio_file'],
                'confidence': confidence
            }
        else:
            # Handle unknown command
            self.consecutive_unknown += 1
            
            if self.consecutive_unknown >= self.config.max_consecutive_unknown:
                response = "I'm having trouble understanding. Let's try again when we have internet!"
                audio_file = "redirects/need_internet.opus"
            else:
                response = "I need internet to understand that! Can we try something else?"
                audio_file = "redirects/try_something_else.opus"
            
            return {
                'command': 'unknown',
                'text': text,
                'response': response,
                'audio_file': audio_file,
                'confidence': confidence
            }
    
    def _check_safety(self, text: str) -> Dict[str, Any]:
        """Check text for blocked topics"""
        text_lower = text.lower()
        
        for category, keywords in OfflineCommands.BLOCKED_TOPICS.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return {
                        'blocked': True,
                        'category': category,
                        'response': OfflineCommands.get_safe_redirect(category)
                    }
        
        return {'blocked': False}
    
    def _match_offline_command(self, text: str) -> Optional[Dict[str, Any]]:
        """Match text to offline command"""
        text_lower = text.lower()
        
        for command_name, config in OfflineCommands.COMMANDS.items():
            for trigger in config['triggers']:
                if trigger in text_lower:
                    # Check safety level
                    if config['safety_level'] != 'all' and \
                       config['safety_level'] != self.config.safety_level.value:
                        continue
                    
                    # Select random response
                    response = random.choice(config['responses'])
                    audio_file = None
                    
                    if 'audio_files' in config and config['audio_files']:
                        audio_file = f"responses/{random.choice(config['audio_files'])}"
                    
                    return {
                        'command': command_name,
                        'response': response,
                        'audio_file': audio_file
                    }
        
        return None
    
    def _track_safety_violation(self, category: str, content: str):
        """Track safety violations for parent review"""
        violation = {
            'timestamp': time.time(),
            'category': category,
            'content': content
        }
        self.safety_violations.append(violation)
        
        # Check if too many violations
        recent_violations = [
            v for v in self.safety_violations 
            if time.time() - v['timestamp'] < 300  # Last 5 minutes
        ]
        
        if len(recent_violations) >= 3:
            logger.warning(f"Multiple safety violations detected: {len(recent_violations)}")
            # This would trigger safety lockdown in the main client
    
    def stop_detection(self):
        """Stop wake word detection"""
        self.is_active = False
        logger.info("Wake word detection stopped")
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get detection statistics"""
        return {
            'is_active': self.is_active,
            'last_wake_time': self.last_wake_time,
            'consecutive_unknown': self.consecutive_unknown,
            'safety_violations': len(self.safety_violations),
            'buffer_size': len(self.audio_buffer)
        }
    
    def cleanup(self):
        """Clean up resources"""
        self.stop_detection()
        self.audio_buffer.clear()
        self.safety_violations.clear()
        logger.info("Wake word detector cleaned up")


class OfflineVoiceProcessor:
    """Complete offline voice processing pipeline"""
    
    def __init__(self, hardware_controller, audio_stream_manager):
        self.hardware = hardware_controller
        self.audio_manager = audio_stream_manager
        
        # Initialize wake word detector
        self.wake_detector = WakeWordDetector()
        
        # State tracking
        self.is_listening_for_command = False
        self.command_audio_buffer = []
        
    async def start(self):
        """Start offline voice processing"""
        # Set up callbacks
        await self.wake_detector.start_detection(
            wake_callback=self._on_wake_word_detected,
            command_callback=self._on_command_processed
        )
        
        # Start audio processing loop
        asyncio.create_task(self._audio_processing_loop())
        
        logger.info("Offline voice processor started")
    
    async def _audio_processing_loop(self):
        """Process audio from hardware"""
        while True:
            try:
                # Read audio chunk from hardware
                audio_chunk = self.hardware.input_stream.read(
                    self.wake_detector.config.chunk_size,
                    exception_on_overflow=False
                )
                
                if self.is_listening_for_command:
                    # Collect audio for command processing
                    self.command_audio_buffer.append(audio_chunk)
                    
                    # Stop after 3 seconds
                    if len(self.command_audio_buffer) * self.wake_detector.config.chunk_size / \
                       self.wake_detector.config.sample_rate > 3.0:
                        await self._process_collected_command()
                else:
                    # Process for wake word
                    await self.wake_detector.process_audio_chunk(audio_chunk)
                
                # Small delay to prevent CPU overload
                await asyncio.sleep(0.001)
                
            except Exception as e:
                logger.error(f"Audio processing error: {e}")
                await asyncio.sleep(0.1)
    
    async def _on_wake_word_detected(self):
        """Handle wake word detection"""
        logger.info("Wake word detected, listening for command...")
        
        # Visual feedback
        await self.hardware.led_controller.set_pattern(LEDPattern.LISTENING)
        
        # Audio feedback
        await self.hardware.play_sound("wake_acknowledged.opus")
        
        # Start collecting command audio
        self.is_listening_for_command = True
        self.command_audio_buffer = []
    
    async def _process_collected_command(self):
        """Process collected command audio"""
        self.is_listening_for_command = False
        
        # Combine audio chunks
        command_audio = b''.join(self.command_audio_buffer)
        
        # Process command
        result = await self.wake_detector.process_command(command_audio)
        
        # Handle result
        await self._on_command_processed(result)
    
    async def _on_command_processed(self, result: Dict[str, Any]):
        """Handle processed command"""
        logger.info(f"Command processed: {result['command']}")
        
        # Visual feedback
        if result.get('blocked'):
            await self.hardware.led_controller.set_pattern(LEDPattern.ERROR)
        else:
            await self.hardware.led_controller.set_pattern(LEDPattern.PROCESSING)
        
        # Play response
        if result.get('audio_file'):
            audio_path = f"/opt/pommai/audio/{result['audio_file']}"
            if os.path.exists(audio_path):
                await self.hardware.play_sound(result['audio_file'])
            else:
                # Fallback to TTS or default response
                logger.warning(f"Audio file not found: {audio_path}")
        
        # Return to idle
        await asyncio.sleep(1.0)
        await self.hardware.led_controller.set_pattern(LEDPattern.IDLE)
    
    def stop(self):
        """Stop offline voice processing"""
        self.wake_detector.stop_detection()
        logger.info("Offline voice processor stopped")


# Test functions
if __name__ == "__main__":
    import pyaudio
    
    async def test_wake_word_detector():
        """Test wake word detection functionality"""
        logger.info("Testing wake word detector...")
        
        # Create test config
        config = WakeWordConfig(
            model_path="/opt/pommai/models/vosk-model-small-en-us",
            wake_words=["hey pommai", "pommai"],
            safety_level=SafetyLevel.STRICT
        )
        
        # Create detector
        detector = WakeWordDetector(config)
        
        # Test safety checking
        logger.info("\nTesting safety checking...")
        test_inputs = [
            "Hello pommai",
            "Tell me about guns",
            "I'm scared of monsters",
            "What's your phone number?",
            "I love you",
            "Let's play a game"
        ]
        
        for text in test_inputs:
            safety_result = detector._check_safety(text)
            logger.info(f"Input: '{text}' -> Blocked: {safety_result['blocked']}")
        
        # Test command matching
        logger.info("\nTesting command matching...")
        test_commands = [
            "Hello there",
            "Sing a song",
            "Tell me a joke",
            "Goodnight pommai",
            "I need help",
            "What's the weather?"
        ]
        
        for text in test_commands:
            match_result = detector._match_offline_command(text)
            if match_result:
                logger.info(f"Command: '{text}' -> Matched: {match_result['command']}")
            else:
                logger.info(f"Command: '{text}' -> No match")
        
        # Test with real audio if available
        try:
            audio = pyaudio.PyAudio()
            
            # Create test audio stream
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                input=True,
                frames_per_buffer=512
            )
            
            logger.info("\nTesting with audio input (5 seconds)...")
            
            async def audio_callback():
                logger.info("Wake word detected!")
            
            await detector.start_detection(wake_callback=audio_callback)
            
            # Process audio for 5 seconds
            start_time = time.time()
            while time.time() - start_time < 5:
                data = stream.read(512, exception_on_overflow=False)
                await detector.process_audio_chunk(data)
                await asyncio.sleep(0.01)
            
            stream.stop_stream()
            stream.close()
            audio.terminate()
            
        except Exception as e:
            logger.warning(f"Audio test skipped: {e}")
        
        # Get statistics
        stats = detector.get_statistics()
        logger.info(f"\nDetector statistics: {stats}")
        
        # Cleanup
        detector.cleanup()
        logger.info("\nWake word detector test completed!")
    
    # Run test
    asyncio.run(test_wake_word_detector())
</file>

</files>
